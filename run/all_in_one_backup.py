#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
All-in-One: MP4 -> Voice Only -> Text (VI/CN) -> Translate -> Rewrite -> TTS -> Drive
T·∫•t c·∫£ trong m·ªôt script duy nh·∫•t

        Lu·ªìng x·ª≠ l√Ω ho√†n ch·ªânh:
        1. T·∫£i video MP4 t·ª´ Google Drive
        2. T√°ch voice t·ª´ video (lo·∫°i b·ªè background music)
        3. Upload voice only l√™n Google Drive
        4. Chuy·ªÉn ƒë·ªïi voice -> Text b·∫±ng Deepgram API (h·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Trung) v·ªõi timeline
        5. N·∫øu ph√°t hi·ªán ti·∫øng Trung: t·ª± ƒë·ªông d·ªãch sang ti·∫øng Vi·ªát
        6. Upload text g·ªëc (ho·∫∑c ƒë√£ d·ªãch) l√™n Google Drive
        7. Vi·∫øt l·∫°i text b·∫±ng Gemini API (c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß: 5 ti√™u ƒë·ªÅ + n·ªôi dung + captions + CTA)
        8. Upload text ƒë√£ vi·∫øt l·∫°i l√™n Google Drive
        9. T·∫°o text kh√¥ng c√≥ timeline (ch·ªâ n·ªôi dung ch√≠nh)
        10. T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA (kh√¥ng c√≥ icon)
        11. C·∫≠p nh·∫≠t k·∫øt qu·∫£ l√™n Google Sheets (2 c·ªôt m·ªõi: Text no timeline + G·ª£i √Ω ti√™u ƒë·ªÅ)

T√≠nh nƒÉng m·ªõi:
- T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ (ti·∫øng Vi·ªát/ti·∫øng Trung)
- D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát t·ª± ƒë·ªông
- H·ªó tr·ª£ x·ª≠ l√Ω nhi·ªÅu video c√πng l√∫c
- C·∫≠p nh·∫≠t k·∫øt qu·∫£ l√™n Google Sheets
- Timeline trong text extraction (gi√¢y 1-3: xin ch√†o... gi√¢y 4-9: gi·ªõi thi·ªáu...)
- Vi·∫øt l·∫°i text v·ªõi c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß: 5 ti√™u ƒë·ªÅ + n·ªôi dung timeline + captions + CTA
- T·∫°o text kh√¥ng c√≥ timeline (ch·ªâ n·ªôi dung ch√≠nh, chia ƒëo·∫°n r√µ r√†ng)
- T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA ri√™ng bi·ªát (kh√¥ng c√≥ icon)

T√°c gi·∫£: AI Assistant
Ng√†y t·∫°o: 2024
"""

import os
import sys
import logging
import tempfile
import shutil
import subprocess
import requests
import json
import re
import signal
import atexit
import time
from typing import List, Dict, Tuple
from datetime import datetime, timedelta

# Google API imports
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from googleapiclient.errors import HttpError

# Import VideoStatusChecker
from video_checker import VideoStatusChecker

# Import TokenCalculator
from token_calculator import TokenCalculator

# Configuration
SCOPES = [
    'https://www.googleapis.com/auth/drive.file',
    'https://www.googleapis.com/auth/drive.readonly',
    'https://www.googleapis.com/auth/spreadsheets'
]

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('all_in_one.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class AllInOneProcessor:
    """
    L·ªõp x·ª≠ l√Ω t·∫•t c·∫£ trong m·ªôt: Video -> Voice Only -> Text -> Rewrite -> TTS -> Drive
    
    Ch·ª©c nƒÉng ch√≠nh:
    - X√°c th·ª±c v·ªõi Google Drive API
    - T·∫£i video t·ª´ Google Drive
    - T√°ch voice t·ª´ video (lo·∫°i b·ªè background music)
    - Chuy·ªÉn ƒë·ªïi voice th√†nh text b·∫±ng Deepgram (h·ªó tr·ª£ ti·∫øng Vi·ªát v√† ti·∫øng Trung) v·ªõi timeline
    - D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát
    - Vi·∫øt l·∫°i text b·∫±ng Gemini (c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß: 5 ti√™u ƒë·ªÅ + n·ªôi dung timeline + captions + CTA)
    - T·∫°o text kh√¥ng c√≥ timeline (ch·ªâ n·ªôi dung ch√≠nh, chia ƒëo·∫°n r√µ r√†ng)
    - T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA ri√™ng bi·ªát (kh√¥ng c√≥ icon)
    - Upload t·∫•t c·∫£ file l√™n Google Drive
    - C·∫≠p nh·∫≠t k·∫øt qu·∫£ l√™n Google Sheets (2 c·ªôt m·ªõi: Text no timeline + G·ª£i √Ω ti√™u ƒë·ªÅ)
    """
    
    def __init__(self):
        # ƒêƒÉng k√Ω signal handler ƒë·ªÉ x·ª≠ l√Ω d·ª´ng an to√†n
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        atexit.register(self.cleanup)
        
        # Flag ƒë·ªÉ ki·ªÉm tra xem c√≥ ƒëang d·ª´ng kh√¥ng
        self._shutdown_requested = False
        
        """
        Kh·ªüi t·∫°o processor v·ªõi c√°c API keys v√† services
        """
        
        # API Keys ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh s·∫µn
        self.deepgram_api_key = '62577e5f53dd9757f0e88250e7326f78281bfa5b'  # Deepgram API key
        # self.gemini_api_key = 'AIzaSyAYJxS00MlUoO4E3RBIms2D26hoDgOHRRo'  # Gemini API key (C≈® - ƒê√É COMMENT)
        #api3: AIzaSyDv15UVxgZBUJCDNBU946zEJ03W1y4wp58
        # api1: AIzaSyCNdaVmt9KwMN0mEfSSEQ37oG8U5T088JU (Project c≈©)
        # api2: AIzaSyA_SI7BvZlJGFHKNI4OF4JTvOlcs1mC7Mw (Project hi·ªán t·∫°i)
        self.gemini_api_key = 'AIzaSyBpKnhnU1pgjcDZ5LAYoNIGdf6v9Vg5_Kk'  # Gemini API key (M·ªöI)
        
        logger.info(f"üîë S·ª≠ d·ª•ng Gemini API key: {self.gemini_api_key[:20]}...")
        
        # Deepgram TTS API key (c√πng v·ªõi STT) - ƒê√É COMMENT
        # self.deepgram_tts_api_key = 'bb69898295e896c0123d4cdd01a43fdcb78b7b4b'
        
        # Google Sheets ID - Thay ƒë·ªïi n·∫øu c·∫ßn
        self.spreadsheet_id = '1y4Gmc58DCRmnyO9qNlSBklkvebL5mY9gLlOqcP91Epg'
        self.sheet_name = 'Mp3 to text'  # T√™n sheet ch√≠nh x√°c theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
        
        # API Rate Limiting v√† Monitoring
        self.api_call_count = {
            'deepgram': 0,
            'gemini': 0,
            'google_drive': 0,
            'google_sheets': 0
        }
        self.api_last_call_time = {
            'deepgram': datetime.now(),
            'gemini': datetime.now(),
            'google_drive': datetime.now(),
            'google_sheets': datetime.now()
        }
        self.api_delays = {
            'deepgram': 2,  # 2 gi√¢y gi·ªØa c√°c calls
            'gemini': 3,    # 3 gi√¢y gi·ªØa c√°c calls
            'google_drive': 1,  # 1 gi√¢y gi·ªØa c√°c calls
            'google_sheets': 1  # 1 gi√¢y gi·ªØa c√°c calls
        }
        self.video_delay = 8  # 8 gi√¢y gi·ªØa c√°c video
        
        # Kh·ªüi t·∫°o Token Calculator
        self.token_calculator = TokenCalculator()
        
        # Th·ª≠ v·ªõi t√™n sheet kh√°c n·∫øu l·ªói
        # C√≥ th·ªÉ t√™n sheet c√≥ kho·∫£ng tr·∫Øng, s·∫Ω th·ª≠ v·ªõi t√™n kh√°c n·∫øu l·ªói
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        # Ho·∫∑c c√≥ th·ªÉ t√™n sheet l√† "Mp3 to text" ho·∫∑c "mp3 to text"
        
        # Sheet IDs ƒë·ªÉ tr√°nh l·ªói parse range v·ªõi t√™n c√≥ kho·∫£ng tr·∫Øng
        self.main_sheet_id = 0  # Sheet "Mp3 to text" - gid=0
        self.prompt_sheet_id = 695659214  # Sheet "Prompt" - gid=695659214
        
        # Kh·ªüi t·∫°o c√°c bi·∫øn ch√≠nh
        self.creds = None  # Google OAuth credentials
        self.drive_service = None  # Google Drive service
        self.sheets_service = None  # Google Sheets service
        self.temp_dir = tempfile.mkdtemp()  # Th∆∞ m·ª•c t·∫°m ƒë·ªÉ l∆∞u file
        
        # Kh·ªüi t·∫°o Google API services
        self._authenticate_google_apis()
        
        # Kh·ªüi t·∫°o VideoStatusChecker sau khi c√≥ services
        try:
            self.video_checker = VideoStatusChecker(
                self.drive_service, 
                self.sheets_service,
                self.spreadsheet_id,
                self.sheet_name
            )
            logger.info("‚úÖ VideoStatusChecker ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
        except Exception as e:
            logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o VideoStatusChecker: {str(e)}")
            self.video_checker = None
        
    def _signal_handler(self, signum, frame):
        """
        Signal handler ƒë·ªÉ x·ª≠ l√Ω d·ª´ng an to√†n
        """
        logger.info(f"üõë Nh·∫≠n t√≠n hi·ªáu d·ª´ng (signal {signum})")
        logger.info("üîÑ ƒêang d·ª´ng ch∆∞∆°ng tr√¨nh an to√†n...")
        self._shutdown_requested = True
        self.cleanup()
        logger.info("‚úÖ ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh an to√†n")
        sys.exit(0)
        
    def _authenticate_google_apis(self):
        """
        X√°c th·ª±c v·ªõi Google APIs s·ª≠ d·ª•ng OAuth 2.0
        
        Quy tr√¨nh:
        1. Ki·ªÉm tra token ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥
        2. N·∫øu token h·∫øt h·∫°n th√¨ refresh
        3. N·∫øu kh√¥ng c√≥ token th√¨ t·∫°o m·ªõi qua OAuth flow
        4. L∆∞u token ƒë·ªÉ s·ª≠ d·ª•ng l·∫ßn sau
        """
        try:
            # B∆∞·ªõc 1: Ki·ªÉm tra token ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥
            token_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'token.json')
            if os.path.exists(token_path):
                self.creds = Credentials.from_authorized_user_file(token_path, SCOPES)
                logger.info("ƒê√£ t√¨m th·∫•y token ƒë√£ l∆∞u")
            
            # B∆∞·ªõc 2: Ki·ªÉm tra token c√≥ h·ª£p l·ªá kh√¥ng
            if not self.creds or not self.creds.valid:
                if self.creds and self.creds.expired and self.creds.refresh_token:
                    # Token h·∫øt h·∫°n nh∆∞ng c√≥ refresh token -> refresh
                    logger.info("Token h·∫øt h·∫°n, ƒëang refresh...")
                    self.creds.refresh(Request())
                else:
                    # Kh√¥ng c√≥ token ho·∫∑c kh√¥ng refresh ƒë∆∞·ª£c -> t·∫°o m·ªõi
                    logger.info("T·∫°o x√°c th·ª±c OAuth m·ªõi...")
                    client_secrets_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 
                                                     'client_secret_978352364973-qoautr8eke7219mroqstbch3mehnt42r.apps.googleusercontent.com.json')  # Client ID m·ªõi
                    flow = InstalledAppFlow.from_client_secrets_file(client_secrets_path, SCOPES)
                    self.creds = flow.run_local_server(port=0)
                
                # B∆∞·ªõc 3: L∆∞u token ƒë·ªÉ s·ª≠ d·ª•ng l·∫ßn sau
                token_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'token.json')
                with open(token_path, 'w') as token:
                    token.write(self.creds.to_json())
                logger.info("ƒê√£ l∆∞u token m·ªõi")
            
            # B∆∞·ªõc 4: Kh·ªüi t·∫°o Google Drive service
            self.drive_service = build('drive', 'v3', credentials=self.creds)
            
            # B∆∞·ªõc 5: Kh·ªüi t·∫°o Google Sheets service
            self.sheets_service = build('sheets', 'v4', credentials=self.creds)
            
            logger.info("‚úÖ X√°c th·ª±c Google APIs th√†nh c√¥ng (OAuth)")
            logger.info("‚úÖ Google Drive service ƒë√£ s·∫µn s√†ng")
            logger.info("‚úÖ Google Sheets service ƒë√£ s·∫µn s√†ng")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói x√°c th·ª±c Google APIs: {str(e)}")
            raise

    def _wait_for_api_rate_limit(self, api_name: str):
        """
        ƒê·ª£i ƒë·ªÉ tu√¢n th·ªß rate limiting cho API
        """
        current_time = datetime.now()
        last_call_time = self.api_last_call_time[api_name]
        delay_required = self.api_delays[api_name]
        
        time_since_last_call = (current_time - last_call_time).total_seconds()
        
        if time_since_last_call < delay_required:
            wait_time = delay_required - time_since_last_call
            logger.info(f"‚è≥ ƒê·ª£i {wait_time:.1f}s ƒë·ªÉ tu√¢n th·ªß rate limit cho {api_name}")
            time.sleep(wait_time)
        
        self.api_last_call_time[api_name] = datetime.now()
        self.api_call_count[api_name] += 1

    def _log_api_usage(self):
        """
        Log t·ªïng s·ªë API calls ƒë√£ th·ª±c hi·ªán
        """
        total_calls = sum(self.api_call_count.values())
        logger.info(f"üìä API Usage Summary:")
        logger.info(f"  - Deepgram: {self.api_call_count['deepgram']} calls")
        logger.info(f"  - Gemini: {self.api_call_count['gemini']} calls")
        logger.info(f"  - Google Drive: {self.api_call_count['google_drive']} calls")
        logger.info(f"  - Google Sheets: {self.api_call_count['google_sheets']} calls")
        logger.info(f"  - Total: {total_calls} calls")

    def detect_chinese_characters(self, text: str) -> bool:
        """
        Ph√°t hi·ªán xem text c√≥ ch·ª©a k√Ω t·ª± ti·∫øng Trung kh√¥ng
        
        Args:
            text: Text c·∫ßn ki·ªÉm tra
            
        Returns:
            True n·∫øu c√≥ k√Ω t·ª± ti·∫øng Trung, False n·∫øu kh√¥ng
        """
        # Unicode ranges cho k√Ω t·ª± ti·∫øng Trung
        chinese_ranges = [
            (0x4E00, 0x9FFF),   # CJK Unified Ideographs
            (0x3400, 0x4DBF),   # CJK Unified Ideographs Extension A
            (0x20000, 0x2A6DF), # CJK Unified Ideographs Extension B
            (0x2A700, 0x2B73F), # CJK Unified Ideographs Extension C
            (0x2B740, 0x2B81F), # CJK Unified Ideographs Extension D
            (0x2B820, 0x2CEAF), # CJK Unified Ideographs Extension E
        ]
        
        for char in text:
            char_code = ord(char)
            for start, end in chinese_ranges:
                if start <= char_code <= end:
                    return True
        return False

    def extract_text_with_language_detection(self, audio_path: str, output_name: str) -> Tuple[str, str, bool]:
        """
        Chuy·ªÉn ƒë·ªïi MP3 th√†nh text v·ªõi ph√°t hi·ªán ng√¥n ng·ªØ
        ∆Øu ti√™n ti·∫øng Trung tr∆∞·ªõc, sau ƒë√≥ m·ªõi ti·∫øng Vi·ªát
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file MP3
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            Tuple (text_path, detected_language, is_chinese)
        """
        try:
            # T·∫°o t√™n file output cho text
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_transcript.txt")
            
            logger.info(f"üìù B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi audio th√†nh text: {os.path.basename(audio_path)}")
            
            # Ki·ªÉm tra file audio c√≥ t·ªìn t·∫°i v√† c√≥ k√≠ch th∆∞·ªõc > 0
            if not os.path.exists(audio_path):
                raise Exception(f"File audio kh√¥ng t·ªìn t·∫°i: {audio_path}")
            
            file_size = os.path.getsize(audio_path)
            if file_size == 0:
                raise Exception(f"File audio r·ªóng: {audio_path}")
            
            logger.info(f"üìä K√≠ch th∆∞·ªõc file audio: {file_size:,} bytes")
            
            # ∆ØU TI√äN TI·∫æNG TRUNG TR∆Ø·ªöC (theo y√™u c·∫ßu c·ªßa user)
            logger.info("üá®üá≥ ∆Øu ti√™n th·ª≠ v·ªõi ti·∫øng Trung tr∆∞·ªõc...")
            transcript_zh, detected_language_zh = self._try_transcription(audio_path, "zh")
            
            # Ki·ªÉm tra k·∫øt qu·∫£ ti·∫øng Trung
            is_chinese = self.detect_chinese_characters(transcript_zh)
            logger.info(f"üá®üá≥ K·∫øt qu·∫£ ti·∫øng Trung: '{transcript_zh[:100]}...' (ƒë·ªô d√†i: {len(transcript_zh)})")
            logger.info(f"üá®üá≥ C√≥ k√Ω t·ª± ti·∫øng Trung: {is_chinese}")
            
            # N·∫øu ti·∫øng Trung c√≥ k·∫øt qu·∫£ t·ªët, s·ª≠ d·ª•ng lu√¥n
            if transcript_zh and len(transcript_zh.strip()) > 10:
                transcript = transcript_zh
                detected_language = detected_language_zh
                logger.info("‚úÖ S·ª≠ d·ª•ng k·∫øt qu·∫£ ti·∫øng Trung")
            else:
                # N·∫øu ti·∫øng Trung kh√¥ng c√≥ k·∫øt qu·∫£, th·ª≠ ti·∫øng Vi·ªát
                logger.info("üáªüá≥ Th·ª≠ v·ªõi ti·∫øng Vi·ªát...")
                transcript_vi, detected_language_vi = self._try_transcription(audio_path, "vi")
                logger.info(f"üáªüá≥ K·∫øt qu·∫£ ti·∫øng Vi·ªát: '{transcript_vi[:100]}...' (ƒë·ªô d√†i: {len(transcript_vi)})")
                
                # So s√°nh v√† ch·ªçn k·∫øt qu·∫£ t·ªët h∆°n
                if len(transcript_vi) > len(transcript_zh):
                    transcript = transcript_vi
                    detected_language = detected_language_vi
                    is_chinese = False
                    logger.info("‚úÖ S·ª≠ d·ª•ng k·∫øt qu·∫£ ti·∫øng Vi·ªát")
                else:
                    transcript = transcript_zh
                    detected_language = detected_language_zh
                    logger.info("‚úÖ Gi·ªØ k·∫øt qu·∫£ ti·∫øng Trung")
            
            # Ki·ªÉm tra k·∫øt qu·∫£ cu·ªëi c√πng
            if not transcript or len(transcript.strip()) == 0:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ transcript n√†o ƒë∆∞·ª£c t·∫°o!")
                transcript = "Kh√¥ng th·ªÉ nh·∫≠n d·∫°ng gi·ªçng n√≥i t·ª´ audio"
            
            # L∆∞u transcript v√†o file text
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(transcript)
            
            # Track token usage cho Deepgram (∆∞·ªõc t√≠nh th·ªùi l∆∞·ª£ng audio)
            try:
                import subprocess
                # L·∫•y th·ªùi l∆∞·ª£ng audio b·∫±ng ffprobe
                cmd = [
                    os.path.join(os.path.dirname(os.path.dirname(__file__)), "tools", "ffprobe.exe"),
                    "-v", "quiet",
                    "-show_entries", "format=duration",
                    "-of", "csv=p=0",
                    audio_path
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                if result.returncode == 0:
                    duration = float(result.stdout.strip())
                    self.token_calculator.track_api_call(
                        operation="speech_to_text",
                        audio_duration=duration,
                        api_type="deepgram"
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y th·ªùi l∆∞·ª£ng audio: {str(e)}")
            
            logger.info(f"‚úÖ Chuy·ªÉn ƒë·ªïi text th√†nh c√¥ng!")
            logger.info(f"üìÅ File text: {output_path}")
            logger.info(f"üìù ƒê·ªô d√†i text: {len(transcript)} k√Ω t·ª±")
            logger.info(f"üåê Ng√¥n ng·ªØ ph√°t hi·ªán: {detected_language}")
            logger.info(f"üá®üá≥ L√† ti·∫øng Trung: {is_chinese}")
            logger.info(f"üìÑ N·ªôi dung: {transcript[:200]}...")
            
            return output_path, detected_language, is_chinese
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi audio th√†nh text: {str(e)}")
            raise

    def _try_transcription(self, audio_path: str, language: str) -> Tuple[str, str]:
        """
        Th·ª≠ chuy·ªÉn ƒë·ªïi audio th√†nh text v·ªõi ng√¥n ng·ªØ c·ª• th·ªÉ v√† timeline
        C·∫£i thi·ªán logic ƒë·ªÉ tƒÉng kh·∫£ nƒÉng l·∫•y ƒë∆∞·ª£c timeline
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            language: Ng√¥n ng·ªØ ("vi" ho·∫∑c "zh")
            
        Returns:
            Tuple (transcript_with_timeline, detected_language)
        """
        try:
            # B∆∞·ªõc 1: Preprocess audio ƒë·ªÉ t·ªëi ∆∞u cho timeline
            processed_audio_path = self._preprocess_audio_for_timeline(audio_path)
            
            # B∆∞·ªõc 2: G·ª≠i audio ƒë√£ x·ª≠ l√Ω ƒë·∫øn Deepgram
            with open(processed_audio_path, 'rb') as audio_file:
                url = "https://api.deepgram.com/v1/listen"
                headers = {
                    "Authorization": f"Token {self.deepgram_api_key}",
                    "Content-Type": "audio/mpeg"
                }
                
                # C·∫£i thi·ªán tham s·ªë cho Deepgram API ƒë·ªÉ tƒÉng kh·∫£ nƒÉng l·∫•y timeline
                params = {
                    "model": "nova-2",
                    "language": language,
                    "punctuate": "true",
                    "utterances": "true",
                    "diarize": "true",
                    "timestamps": "true",  # Th√™m timestamps ƒë·ªÉ l·∫•y timeline
                    "smart_format": "true",  # Th√™m smart format
                    "filler_words": "false",  # Lo·∫°i b·ªè filler words
                    "profanity_filter": "false",  # Kh√¥ng filter profanity
                    "redact": "false",  # Kh√¥ng redact
                    "search": None,  # Kh√¥ng search
                    "replace": None,  # Kh√¥ng replace
                    "callback": None,  # Kh√¥ng callback
                    "keywords": None,  # Kh√¥ng keywords
                    "interim_results": "false",  # Kh√¥ng interim results
                    "endpointing": "true",  # B·∫≠t endpointing
                    "vad_turnoff": "500",  # VAD turnoff 500ms
                    "encoding": "linear16",  # Encoding
                    "channels": "1",  # Mono channel
                    "sample_rate": "16000"  # Sample rate 16kHz
                }
                
                logger.info(f"üîÑ ƒêang g·ª≠i request ƒë·∫øn Deepgram API v·ªõi ng√¥n ng·ªØ: {language} v√† timeline")
                logger.info(f"üìä Tham s·ªë t·ªëi ∆∞u cho timeline: {params}")
                
                # Rate limiting cho Deepgram API
                self._wait_for_api_rate_limit('deepgram')
                
                response = requests.post(url, headers=headers, params=params, data=audio_file, timeout=600)
                
                logger.info(f"üì° Response status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    logger.info(f"üìÑ Response keys: {list(result.keys())}")
                    
                    if 'results' in result:
                        logger.info(f"üìä Results keys: {list(result['results'].keys())}")
                        
                        if 'channels' in result['results']:
                            channels = result['results']['channels']
                            logger.info(f"üéµ S·ªë channels: {len(channels)}")
                            
                            if len(channels) > 0:
                                channel = channels[0]
                                logger.info(f"üéµ Channel keys: {list(channel.keys())}")
                                
                                if 'alternatives' in channel:
                                    alternatives = channel['alternatives']
                                    logger.info(f"üìù S·ªë alternatives: {len(alternatives)}")
                                    
                                    if len(alternatives) > 0:
                                        alt = alternatives[0]
                                        logger.info(f"üìù Alternative keys: {list(alt.keys())}")
                                        
                                        # C·∫£i thi·ªán logic x·ª≠ l√Ω transcript v·ªõi timeline
                                        if 'transcript' in alt and 'words' in alt:
                                            transcript = alt['transcript']
                                            words = alt['words']
                                            
                                            # Log chi ti·∫øt v·ªÅ words data
                                            logger.info(f"üìä S·ªë words c√≥ timestamps: {len(words)}")
                                            if words:
                                                logger.info(f"üìä Word ƒë·∫ßu ti√™n: {words[0]}")
                                                logger.info(f"üìä Word cu·ªëi c√πng: {words[-1]}")
                                            
                                            # T·∫°o transcript v·ªõi timeline
                                            transcript_with_timeline = self._format_transcript_with_timeline(words, transcript)
                                            
                                            logger.info(f"‚úÖ Transcript v·ªõi timeline v√† ng√¥n ng·ªØ {language}: '{transcript_with_timeline[:100]}...'")
                                            return transcript_with_timeline, language
                                        elif 'transcript' in alt:
                                            # Fallback n·∫øu kh√¥ng c√≥ words (timeline)
                                            transcript = alt['transcript']
                                            logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ words data cho timeline v·ªõi ng√¥n ng·ªØ {language}")
                                            
                                            # Th·ª≠ t·∫°o timeline th·ªß c√¥ng
                                            try:
                                                # L·∫•y ƒë·ªô d√†i audio t·ª´ response n·∫øu c√≥
                                                audio_duration = None
                                                if 'metadata' in result and 'duration' in result['metadata']:
                                                    audio_duration = float(result['metadata']['duration'])
                                                    logger.info(f"üìä ƒê·ªô d√†i audio t·ª´ metadata: {audio_duration} gi√¢y")
                                                
                                                transcript_with_manual_timeline = self._create_manual_timeline(transcript, audio_duration)
                                                logger.info(f"‚úÖ ƒê√£ t·∫°o timeline th·ªß c√¥ng v·ªõi ng√¥n ng·ªØ {language}: '{transcript_with_manual_timeline[:100]}...'")
                                                return transcript_with_manual_timeline, language
                                            except Exception as e:
                                                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o timeline th·ªß c√¥ng: {str(e)}")
                                                logger.info(f"‚úÖ S·ª≠ d·ª•ng transcript kh√¥ng c√≥ timeline v·ªõi ng√¥n ng·ªØ {language}: '{transcript[:100]}...'")
                                                return transcript, language
                                        else:
                                            logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ transcript trong alternative cho ng√¥n ng·ªØ {language}")
                                    else:
                                        logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ alternatives cho ng√¥n ng·ªØ {language}")
                                else:
                                    logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ alternatives trong channel cho ng√¥n ng·ªØ {language}")
                            else:
                                logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ channels cho ng√¥n ng·ªØ {language}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ channels trong results cho ng√¥n ng·ªØ {language}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Kh√¥ng c√≥ results trong response cho ng√¥n ng·ªØ {language}")
                        logger.info(f"üìÑ Full response: {result}")
                    
                    # N·∫øu kh√¥ng c√≥ transcript, tr·∫£ v·ªÅ chu·ªói r·ªóng
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ tr√≠ch xu·∫•t transcript cho ng√¥n ng·ªØ {language}")
                    return "", language
                else:
                    logger.error(f"‚ùå Deepgram API l·ªói: {response.status_code} - {response.text}")
                    return "", language
                    
        except Exception as e:
            logger.error(f"‚ùå L·ªói transcription v·ªõi ng√¥n ng·ªØ {language}: {str(e)}")
            return "", language
        finally:
            # Cleanup: X√≥a file audio ƒë√£ x·ª≠ l√Ω n·∫øu kh√°c v·ªõi file g·ªëc
            try:
                if processed_audio_path != audio_path and os.path.exists(processed_audio_path):
                    os.remove(processed_audio_path)
                    logger.info(f"üßπ ƒê√£ x√≥a file audio ƒë√£ x·ª≠ l√Ω: {os.path.basename(processed_audio_path)}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x√≥a file audio ƒë√£ x·ª≠ l√Ω: {str(e)}")

    def _format_transcript_with_timeline(self, words: List[Dict], transcript: str) -> str:
        """
        Format transcript v·ªõi timeline t·ª´ words data c·ªßa Deepgram
        C·∫£i thi·ªán logic ƒë·ªÉ t·∫°o timeline ch√≠nh x√°c h∆°n
        
        Args:
            words: Danh s√°ch words t·ª´ Deepgram API v·ªõi timestamps
            transcript: Transcript g·ªëc
            
        Returns:
            Transcript ƒë√£ format v·ªõi timeline
        """
        try:
            if not words:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ words data ƒë·ªÉ t·∫°o timeline")
                return transcript
            
            logger.info(f"üìä S·ªë words c√≥ timestamps: {len(words)}")
            
            # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng words data
            valid_words = []
            for word_data in words:
                word = word_data.get('word', '').strip()
                start_time = word_data.get('start', 0)
                end_time = word_data.get('end', 0)
                
                # Ch·ªâ l·∫•y words c√≥ ƒë·∫ßy ƒë·ªß th√¥ng tin
                if word and start_time is not None and end_time is not None:
                    valid_words.append({
                        'word': word,
                        'start': float(start_time),
                        'end': float(end_time)
                    })
            
            logger.info(f"üìä S·ªë words h·ª£p l·ªá: {len(valid_words)}")
            
            if not valid_words:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ words h·ª£p l·ªá ƒë·ªÉ t·∫°o timeline")
                return transcript
            
            # C·∫£i thi·ªán logic nh√≥m words theo kho·∫£ng th·ªùi gian
            timeline_segments = []
            current_segment = []
            current_start = None
            current_end = None
            
            # Ng∆∞·ª°ng th·ªùi gian ƒë·ªÉ t·∫°o segment m·ªõi (c·∫£i thi·ªán ƒë·ªô nh·∫≠n di·ªán)
            time_threshold = 1.0  # Gi·∫£m xu·ªëng 1.0 gi√¢y ƒë·ªÉ t·∫°o nhi·ªÅu segment h∆°n
            
            for word_data in valid_words:
                word = word_data['word']
                start_time = word_data['start']
                end_time = word_data['end']
                
                # B·∫Øt ƒë·∫ßu segment m·ªõi n·∫øu:
                # 1. Ch∆∞a c√≥ segment n√†o
                # 2. Kho·∫£ng c√°ch th·ªùi gian > threshold
                # 3. Segment hi·ªán t·∫°i ƒë√£ qu√° d√†i (> 10 gi√¢y)
                segment_duration = 0
                if current_start is not None and current_end is not None:
                    segment_duration = current_end - current_start
                
                if (current_start is None or 
                    (current_end is not None and start_time - current_end > time_threshold) or 
                    segment_duration > 6.0):  # Gi·∫£m xu·ªëng 6 gi√¢y ƒë·ªÉ t·∫°o segment nh·ªè h∆°n
                    
                    # L∆∞u segment tr∆∞·ªõc ƒë√≥ n·∫øu c√≥ n·ªôi dung
                    if current_segment and current_start is not None and current_end is not None:
                        segment_text = ' '.join(current_segment)
                        # Gi·∫£m y√™u c·∫ßu t·ª´ 3 t·ª´ xu·ªëng 1 t·ª´ ƒë·ªÉ kh√¥ng b·ªè s√≥t
                        if len(segment_text.strip()) > 0:
                            timeline_segments.append({
                                'start': current_start,
                                'end': current_end,
                                'text': segment_text
                            })
                    
                    # B·∫Øt ƒë·∫ßu segment m·ªõi
                    current_segment = [word]
                    current_start = start_time
                    current_end = end_time
                else:
                    current_segment.append(word)
                    current_end = end_time  # C·∫≠p nh·∫≠t end time li√™n t·ª•c
            
            # Th√™m segment cu·ªëi c√πng
            if current_segment and current_start is not None and current_end is not None:
                segment_text = ' '.join(current_segment)
                # Gi·∫£m y√™u c·∫ßu t·ª´ 3 t·ª´ xu·ªëng 1 t·ª´ ƒë·ªÉ kh√¥ng b·ªè s√≥t
                if len(segment_text.strip()) > 0:
                    timeline_segments.append({
                        'start': current_start,
                        'end': current_end,
                        'text': segment_text
                    })
            
            # Format th√†nh text v·ªõi timeline
            formatted_text = f"=== TRANSCRIPT V·ªöI TIMELINE ===\n\n"
            
            for i, segment in enumerate(timeline_segments, 1):
                start_sec = int(segment['start'])
                end_sec = int(segment['end'])
                text = segment['text'].strip()
                
                # Ch·ªâ th√™m segment n·∫øu c√≥ n·ªôi dung (gi·∫£m y√™u c·∫ßu)
                if text and len(text.strip()) > 0:
                    formatted_text += f"(Gi√¢y {start_sec}-{end_sec}) {text}\n\n"
            
            # Th√™m transcript g·ªëc ·ªü cu·ªëi ƒë·ªÉ tham kh·∫£o
            formatted_text += f"=== TRANSCRIPT G·ªêC ===\n{transcript}\n"
            
            # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ timeline, t·∫°o timeline th·ªß c√¥ng
            if len(timeline_segments) == 0:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ timeline t·ª´ Deepgram, t·∫°o timeline th·ªß c√¥ng...")
                manual_timeline = self._create_manual_timeline(transcript)
                if manual_timeline:
                    formatted_text = f"=== TRANSCRIPT V·ªöI TIMELINE (TH·ª¶ C√îNG) ===\n\n{manual_timeline}\n\n{formatted_text}"
            
            logger.info(f"‚úÖ ƒê√£ t·∫°o transcript v·ªõi {len(timeline_segments)} segments timeline")
            logger.info(f"üìä Timeline segments: {[(s['start'], s['end']) for s in timeline_segments]}")
            return formatted_text
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format timeline: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return transcript

    def _preprocess_audio_for_timeline(self, audio_path: str) -> str:
        """
        X·ª≠ l√Ω audio ƒë·ªÉ tƒÉng kh·∫£ nƒÉng nh·∫≠n di·ªán timeline
        C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng audio tr∆∞·ªõc khi g·ª≠i ƒë·∫øn Deepgram
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio g·ªëc
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio ƒë√£ x·ª≠ l√Ω
        """
        try:
            import subprocess
            import os
            
            # T·∫°o t√™n file output
            base_name = os.path.splitext(audio_path)[0]
            processed_audio_path = f"{base_name}_processed_for_timeline.wav"
            
            logger.info(f"üîß ƒêang x·ª≠ l√Ω audio ƒë·ªÉ t·ªëi ∆∞u cho timeline: {os.path.basename(audio_path)}")
            
            # S·ª≠ d·ª•ng FFmpeg ƒë·ªÉ c·∫£i thi·ªán audio
            # 1. Chuy·ªÉn sang WAV format (Deepgram ∆∞a th√≠ch)
            # 2. Mono channel (1 k√™nh)
            # 3. Sample rate 16kHz
            # 4. Gi·∫£m ti·∫øng ·ªìn
            # 5. TƒÉng ƒë·ªô r√µ c·ªßa gi·ªçng n√≥i
            
            # T√¨m ƒë∆∞·ªùng d·∫´n FFmpeg
            ffmpeg_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'tools', 'ffmpeg.exe')
            if not os.path.exists(ffmpeg_path):
                # Th·ª≠ t√¨m trong PATH
                import shutil
                ffmpeg_path = shutil.which('ffmpeg')
                if not ffmpeg_path:
                    logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y FFmpeg, s·ª≠ d·ª•ng audio g·ªëc")
                    return audio_path
            
            cmd = [
                ffmpeg_path, '-y',  # Overwrite output file
                '-i', audio_path,  # Input file
                '-ac', '1',  # Mono channel
                '-ar', '16000',  # Sample rate 16kHz
                '-af', 'highpass=f=200,lowpass=f=3000,volume=1.5',  # Audio filters
                '-c:a', 'pcm_s16le',  # PCM 16-bit
                processed_audio_path
            ]
            
            logger.info(f"üîß FFmpeg command: {' '.join(cmd)}")
            
            # Ch·∫°y FFmpeg
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                logger.info(f"‚úÖ ƒê√£ x·ª≠ l√Ω audio th√†nh c√¥ng: {os.path.basename(processed_audio_path)}")
                return processed_audio_path
            else:
                logger.warning(f"‚ö†Ô∏è FFmpeg l·ªói: {result.stderr}")
                logger.info(f"üìù S·ª≠ d·ª•ng audio g·ªëc: {os.path.basename(audio_path)}")
                return audio_path
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω audio: {str(e)}")
            logger.info(f"üìù S·ª≠ d·ª•ng audio g·ªëc: {os.path.basename(audio_path)}")
            return audio_path

    def _create_manual_timeline(self, transcript: str, audio_duration: float = None) -> str:
        """
        T·∫°o timeline th·ªß c√¥ng khi kh√¥ng c√≥ words data t·ª´ Deepgram
        
        Args:
            transcript: Transcript g·ªëc
            audio_duration: ƒê·ªô d√†i audio (gi√¢y), n·∫øu kh√¥ng c√≥ s·∫Ω ∆∞·ªõc t√≠nh
            
        Returns:
            Transcript v·ªõi timeline th·ªß c√¥ng
        """
        try:
            if not transcript or len(transcript.strip()) == 0:
                return transcript
            
            # ∆Ø·ªõc t√≠nh ƒë·ªô d√†i audio n·∫øu kh√¥ng c√≥
            if audio_duration is None:
                # ∆Ø·ªõc t√≠nh d·ª±a tr√™n s·ªë t·ª´ (ƒëi·ªÅu ch·ªânh theo ng·ªØ c·∫£nh)
                word_count = len(transcript.split())
                # ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô n√≥i: 120-180 t·ª´/ph√∫t t√πy ng·ªØ c·∫£nh
                words_per_minute = 150  # M·∫∑c ƒë·ªãnh
                if word_count < 50:
                    words_per_minute = 120  # N√≥i ch·∫≠m h∆°n cho ƒëo·∫°n ng·∫Øn
                elif word_count > 200:
                    words_per_minute = 180  # N√≥i nhanh h∆°n cho ƒëo·∫°n d√†i
                
                audio_duration = (word_count / words_per_minute) * 60  # Chuy·ªÉn sang gi√¢y
                logger.info(f"üìä ∆Ø·ªõc t√≠nh ƒë·ªô d√†i audio: {audio_duration:.1f} gi√¢y t·ª´ {word_count} t·ª´ (t·ªëc ƒë·ªô {words_per_minute} t·ª´/ph√∫t)")
            
            # Chia transcript th√†nh c√°c c√¢u (h·ªó tr·ª£ c·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Trung)
            # D·∫•u c√¢u ti·∫øng Vi·ªát: .!?
            # D·∫•u c√¢u ti·∫øng Trung: „ÄÇÔºÅÔºü
            sentences = re.split(r'[.!?„ÄÇÔºÅÔºü]+', transcript)
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if not sentences:
                return transcript
            
            # T√≠nh th·ªùi gian cho m·ªói c√¢u
            total_sentences = len(sentences)
            time_per_sentence = audio_duration / total_sentences
            
            # T·∫°o timeline th·ªß c√¥ng
            formatted_text = f"=== TRANSCRIPT V·ªöI TIMELINE (TH·ª¶ C√îNG) ===\n\n"
            
            current_time = 0
            for i, sentence in enumerate(sentences):
                if not sentence:
                    continue
                
                # T√≠nh th·ªùi gian cho c√¢u n√†y
                sentence_duration = time_per_sentence
                if i == total_sentences - 1:
                    # C√¢u cu·ªëi c√πng l·∫•y h·∫øt th·ªùi gian c√≤n l·∫°i
                    sentence_duration = audio_duration - current_time
                
                end_time = current_time + sentence_duration
                
                # Format timeline
                start_sec = int(current_time)
                end_sec = int(end_time)
                
                formatted_text += f"(Gi√¢y {start_sec}-{end_sec}) {sentence}.\n\n"
                
                current_time = end_time
            
            # Th√™m transcript g·ªëc
            formatted_text += f"=== TRANSCRIPT G·ªêC ===\n{transcript}\n"
            
            logger.info(f"‚úÖ ƒê√£ t·∫°o timeline th·ªß c√¥ng v·ªõi {len(sentences)} c√¢u")
            return formatted_text
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o timeline th·ªß c√¥ng: {str(e)}")
            return transcript

    def translate_chinese_to_vietnamese(self, text_path: str, output_name: str) -> str:
        """
        D·ªãch text ti·∫øng Trung sang ti·∫øng Vi·ªát b·∫±ng Gemini API v·ªõi batch processing t·ªëi ∆∞u

T·ªëi ∆∞u h√≥a:
1. Batch processing - d·ªãch to√†n b·ªô text trong 1 l·∫ßn thay v√¨ t·ª´ng c√¢u
2. Rate limiting - tu√¢n th·ªß delay gi·ªØa c√°c API calls
3. Monitoring - theo d√µi s·ªë l∆∞·ª£ng API calls

Args:
    text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ti·∫øng Trung
    output_name: T√™n file output (kh√¥ng c√≥ extension)

Returns:
    ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ d·ªãch
        """
        try:
            # T·∫°o t√™n file output cho text ƒë√£ d·ªãch
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_translated.txt")
            
            logger.info(f"üîÑ ƒêang d·ªãch text ti·∫øng Trung sang ti·∫øng Vi·ªát (batch processing): {os.path.basename(text_path)}")
            
            # ƒê·ªçc text ti·∫øng Trung t·ª´ file
            with open(text_path, 'r', encoding='utf-8') as f:
                chinese_text = f.read()
            
            # Rate limiting cho Gemini API
            self._wait_for_api_rate_limit('gemini')
            
            # D·ªãch to√†n b·ªô text trong 1 l·∫ßn (batch processing)
            final_translation = self._translate_batch_with_timeline(chinese_text)
            
            # Track token usage cho translation
            self.token_calculator.track_api_call(
                operation="translate_chinese_to_vietnamese",
                input_text=chinese_text,
                output_text=final_translation,
                api_type="gemini"
            )
            
            # L∆∞u text ƒë√£ d·ªãch v√†o file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(final_translation)
            
            logger.info(f"‚úÖ D·ªãch text th√†nh c√¥ng (batch processing)!")
            logger.info(f"üìÅ File: {output_path}")
            logger.info(f"üìù ƒê·ªô d√†i text: {len(final_translation)} k√Ω t·ª±")
            logger.info(f"üìÑ N·ªôi dung: {final_translation[:200]}...")
            
            return output_path
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói d·ªãch text: {str(e)}")
            raise

    def _translate_batch_with_timeline(self, chinese_text: str) -> str:
        """
        D·ªãch to√†n b·ªô text ti·∫øng Trung sang ti·∫øng Vi·ªát trong 1 l·∫ßn (batch processing)
        
        Args:
            chinese_text: Text ti·∫øng Trung c·∫ßn d·ªãch
            
        Returns:
            Text ƒë√£ d·ªãch sang ti·∫øng Vi·ªát
        """
        try:
            # Chu·∫©n b·ªã request ƒë·∫øn Gemini API
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
            
            # L·∫•y b·∫£ng thu·∫≠t ng·ªØ
            terminology = self._get_terminology_table()
            
            # Prompt t·ªëi ∆∞u cho batch processing
            prompt = f"""
            === D·ªäCH THU·∫¨T BATCH - TRUNG SANG VI·ªÜT ===
            
            {terminology}
            
            === Y√äU C·∫¶U D·ªäCH THU·∫¨T ===
            1. D·ªãch to√†n b·ªô vƒÉn b·∫£n ti·∫øng Trung sang ti·∫øng Vi·ªát
            2. Gi·ªØ nguy√™n timeline format: (Gi√¢y X-Y: n·ªôi dung)
            3. S·ª≠ d·ª•ng thu·∫≠t ng·ªØ chuy√™n ng√†nh t·ª´ b·∫£ng tr√™n
            4. D·ªãch s√°t nghƒ©a, t·ª± nhi√™n, d·ªÖ hi·ªÉu
            5. Gi·ªØ tone chuy√™n nghi·ªáp, ph√π h·ª£p n·ªôi dung n·ªôi th·∫•t/ki·∫øn tr√∫c
            6. B·∫£o to√†n c·∫•u tr√∫c v√† format g·ªëc
            
            === VƒÇN B·∫¢N C·∫¶N D·ªäCH ===
            {chinese_text}
            
            === K·∫æT QU·∫¢ D·ªäCH ===
            """
            
            data = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.1,        # Th·∫•p ƒë·ªÉ ·ªïn ƒë·ªãnh
                    "topP": 0.3,              # Th·∫•p ƒë·ªÉ t·∫≠p trung
                    "topK": 1,                # Ch·ªçn k·∫øt qu·∫£ t·ªëi ∆∞u
                    "maxOutputTokens": 20000  # TƒÉng gi·ªõi h·∫°n cho batch
                }
            }
            
            # G·ª≠i request v·ªõi retry logic
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = requests.post(url, json=data, timeout=180)
                    
                    if response.status_code == 200:
                        result = response.json()
                        translated_text = result['candidates'][0]['content']['parts'][0]['text'].strip()
                        logger.info(f"‚úÖ Batch translation th√†nh c√¥ng!")
                        return translated_text
                        
                    elif response.status_code == 429:  # Rate limit
                        wait_time = (2 ** attempt) * 5  # Exponential backoff v·ªõi base 5s
                        logger.warning(f"‚ö†Ô∏è Rate limit, ƒë·ª£i {wait_time}s tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                        time.sleep(wait_time)
                        continue
                        
                    else:
                        logger.warning(f"‚ö†Ô∏è L·ªói API: {response.status_code}")
                        if attempt == max_retries - 1:
                            logger.error(f"‚ùå Kh√¥ng th·ªÉ d·ªãch sau {max_retries} l·∫ßn th·ª≠")
                            return chinese_text  # Tr·∫£ v·ªÅ text g·ªëc
                        time.sleep(2)
                        continue
                        
                except requests.exceptions.Timeout:
                    logger.warning(f"‚ö†Ô∏è Timeout, th·ª≠ l·∫°i l·∫ßn {attempt + 1}/{max_retries}")
                    if attempt == max_retries - 1:
                        return chinese_text
                    time.sleep(3)
                    continue
                    
        except Exception as e:
            logger.error(f"‚ùå L·ªói batch translation: {str(e)}")
            return chinese_text

    def _prepare_sentences_with_context(self, text: str) -> List[Tuple[str, str]]:
        """
        Chu·∫©n b·ªã vƒÉn b·∫£n ƒë·ªÉ d·ªãch - ƒê∆†N GI·∫¢N H√ìA: D·ªãch nguy√™n b·∫£n s√°t nghƒ©a
        
        Args:
            text: VƒÉn b·∫£n ti·∫øng Trung g·ªëc
            
        Returns:
            List c√°c tuple (vƒÉn b·∫£n, ng·ªØ c·∫£nh)
        """
        try:
            # Kh√¥ng t√°ch c√¢u, ch·ªâ tr·∫£ v·ªÅ vƒÉn b·∫£n nguy√™n b·∫£n
            return [(text, "", True)]  # True = c√≥ th·ªÉ c√≥ timeline
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói chu·∫©n b·ªã vƒÉn b·∫£n: {str(e)}")
            return [(text, "", True)]

    def _get_terminology_table(self) -> str:
        """
        T·∫°o b·∫£ng thu·∫≠t ng·ªØ chuy√™n ng√†nh Trung-Vi·ªát
        
        Returns:
            B·∫£ng thu·∫≠t ng·ªØ d·∫°ng string
        """
        # B·∫£ng thu·∫≠t ng·ªØ chuy√™n ng√†nh - c√≥ th·ªÉ m·ªü r·ªông theo nhu c·∫ßu
        terminology = """
=== B·∫¢NG THU·∫¨T NG·ªÆ CHUY√äN NG√ÄNH (TRUNG ‚Üí VI·ªÜT) ===

# Thu·∫≠t ng·ªØ x√¢y d·ª±ng / thi·∫øt k·∫ø:
ËÆæËÆ° = thi·∫øt k·∫ø
Âª∫Á≠ë = ki·∫øn tr√∫c
ÊñΩÂ∑• = thi c√¥ng
Ë£Ö‰øÆ = ho√†n thi·ªán n·ªôi th·∫•t / trang tr√≠ n·ªôi th·∫•t
ÊùêÊñô = v·∫≠t li·ªáu
ÁªìÊûÑ = k·∫øt c·∫•u
Á©∫Èó¥ = kh√¥ng gian
Â∏ÉÂ±Ä = b·ªë c·ª•c
È£éÊ†º = phong c√°ch
ÊñπÊ°à = ph∆∞∆°ng √°n
ÈááÂÖâ = l·∫•y s√°ng / chi·∫øu s√°ng t·ª± nhi√™n
ÈöîÊñ≠ = v√°ch ngƒÉn
ÊâøÈáçÂ¢ô = t∆∞·ªùng ch·ªãu l·ª±c
ÈùûÊâøÈáçÂ¢ô = t∆∞·ªùng kh√¥ng ch·ªãu l·ª±c
ÂêäÈ°∂ = tr·∫ßn th·∫£ / tr·∫ßn trang tr√≠
Âú∞Êùø = s√†n nh√†
Â¢ôÈù¢ = t∆∞·ªùng
Áì∑Á†ñ = g·∫°ch men
Êú®È•∞Èù¢ = ·ªëp g·ªó
Êä§Â¢ôÊùø = ·ªëp t∆∞·ªùng

# Thu·∫≠t ng·ªØ ph√≤ng / khu v·ª±c:
ÁéÑÂÖ≥ = khu v·ª±c l·ªëi v√†o nh√†
ÂÆ¢ÂéÖ = ph√≤ng kh√°ch
È§êÂéÖ = ph√≤ng ƒÉn
ÂçßÂÆ§ = ph√≤ng ng·ªß
‰∏ªÂçß = ph√≤ng ng·ªß ch√≠nh
Ê¨°Âçß = ph√≤ng ng·ªß ph·ª•
Âé®Êàø = b·∫øp
ÂºÄÊîæÂºèÂé®Êàø = b·∫øp m·ªü
Èò≥Âè∞ = ban c√¥ng
È£òÁ™ó = b·ªá c·ª≠a s·ªï
‰π¶Êàø = ph√≤ng l√†m vi·ªác / ph√≤ng ƒë·ªçc s√°ch
Âç´ÁîüÈó¥ = nh√† v·ªá sinh / ph√≤ng t·∫Øm
Êµ¥ÂÆ§ = ph√≤ng t·∫Øm

# Thu·∫≠t ng·ªØ t·ªß / ƒë·ªì n·ªôi th·∫•t (PH√ÇN BI·ªÜT R√ï):
ÈûãÊüú = t·ªß gi√†y (KH√îNG ph·∫£i nh√† kho)
ÂÇ®Áâ©Êüú = t·ªß ƒë·ª±ng ƒë·ªì
Ë°£Êüú = t·ªß qu·∫ßn √°o
‰π¶Êüú = t·ªß s√°ch
ÁîµËßÜÊüú = t·ªß tivi
Â∫äÂ§¥Êüú = t·ªß ƒë·∫ßu gi∆∞·ªùng
È§êËæπÊüú = t·ªß tr∆∞ng b√†y
Â±ïÁ§∫Êüú = t·ªß tr∆∞ng b√†y
Êî∂Á∫≥Êüú = t·ªß c·∫•t tr·ªØ

# Thu·∫≠t ng·ªØ th√¥ng d·ª•ng:
Êàë‰ª¨ = ch√∫ng t√¥i
ÊÇ® = b·∫°n / √¥ng / b√†
Ëøô‰∏™ = c√°i n√†y
ÈÇ£‰∏™ = c√°i kia
ÂèØ‰ª• = c√≥ th·ªÉ
ÈúÄË¶Å = c·∫ßn
Â∫îËØ• = n√™n
ÂøÖÈ°ª = ph·∫£i
Âª∫ËÆÆ = ƒë·ªÅ xu·∫•t
ËÄÉËôë = c√¢n nh·∫Øc

# Thu·∫≠t ng·ªØ ƒë√°nh gi√°:
ÂæàÂ•Ω = r·∫•t t·ªët
‰∏çÈîô = kh√¥ng t·ªá
‰∏ÄËà¨ = b√¨nh th∆∞·ªùng
Â∑Æ = k√©m
‰ºòÁßÄ = xu·∫•t s·∫Øc
ÂÆûÁî® = ti·ªán d·ª•ng
ÁæéËßÇ = th·∫©m m·ªπ / ƒë·∫πp m·∫Øt
ËàíÈÄÇ = tho·∫£i m√°i

# Thu·∫≠t ng·ªØ th·ªùi gian:
Áé∞Âú® = b√¢y gi·ªù
‰ª•Ââç = tr∆∞·ªõc ƒë√¢y
‰ª•Âêé = sau n√†y
È©¨‰∏ä = ngay l·∫≠p t·ª©c
ÊÖ¢ÊÖ¢ = t·ª´ t·ª´

# Thu·∫≠t ng·ªØ s·ªë l∆∞·ª£ng:
‰∏Ä‰∫õ = m·ªôt s·ªë
ÂæàÂ§ö = nhi·ªÅu
ÂÖ®ÈÉ® = t·∫•t c·∫£
ÈÉ®ÂàÜ = m·ªôt ph·∫ßn
Â§ßÁ∫¶ = kho·∫£ng

# Thu·∫≠t ng·ªØ phong c√°ch h√¥:
Â∏àÂÇÖ = th·∫ßy / ch√∫ (ng∆∞·ªùi c√≥ kinh nghi·ªám, th·ª£)
ËÄÅÊùø = √¥ng ch·ªß
ÂÆ¢Êà∑ = kh√°ch h√†ng
ÊúãÂèã = b·∫°n b√®
ÂÆ∂‰∫∫ = gia ƒë√¨nh
"""

        return terminology

    def _translate_single_sentence(self, sentence: str, context: str) -> str:
        """
        D·ªãch m·ªôt c√¢u v·ªõi ng·ªØ c·∫£nh v√† b·∫£ng thu·∫≠t ng·ªØ
        
        Args:
            sentence: C√¢u c·∫ßn d·ªãch
            context: Ng·ªØ c·∫£nh (50-300 k√Ω t·ª± tr∆∞·ªõc ƒë√≥)
            
        Returns:
            C√¢u ƒë√£ d·ªãch
        """
        try:
            # Chu·∫©n b·ªã request ƒë·∫øn Gemini API
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
            
            # L·∫•y b·∫£ng thu·∫≠t ng·ªØ
            terminology = self._get_terminology_table()
            
            # Prompt chi ti·∫øt cho d·ªãch s√°t nghƒ©a
            prompt = f"""

=== H∆Ø·ªöNG D·∫™N D·ªäCH S√ÅT NGHƒ®A ===

B·∫°n l√† bi√™n d·ªãch vi√™n chuy√™n nghi·ªáp, chuy√™n d·ªãch c√°c t√†i li·ªáu v√† video ti·∫øng Trung sang ti·∫øng Vi·ªát, ƒë·∫∑c bi·ªát trong lƒ©nh v·ª±c n·ªôi th·∫•t v√† ki·∫øn tr√∫c.

{terminology}

=== QUY T·∫ÆC D·ªäCH C·∫¢I THI·ªÜN ===
1. **PH√ÇN T√çCH B·ªêI C·∫¢NH TR∆Ø·ªöC KHI D·ªäCH**: Hi·ªÉu r√µ ng·ªØ c·∫£nh video (thi·∫øt k·∫ø n·ªôi th·∫•t, t·ªß gi√†y, ph√≤ng kh√°ch, b·∫øp...)
2. **∆Øu ti√™n ch√≠nh x√°c**: D·ªãch s√°t nghƒ©a, ƒë·∫£m b·∫£o gi·ªØ nguy√™n th√¥ng tin g·ªëc, kh√¥ng th√™m √Ω t∆∞·ªüng ngo√†i vƒÉn b·∫£n.
3. **T√¥n tr·ªçng b·∫£ng thu·∫≠t ng·ªØ**: S·ª≠ d·ª•ng ƒë√∫ng nghƒ©a ƒë√£ ƒë·ªãnh trong b·∫£ng thu·∫≠t ng·ªØ, ƒë·∫∑c bi·ªát c√°c thu·∫≠t ng·ªØ n·ªôi th·∫•t.
4. **PH√ÇN BI·ªÜT T·ª™ NG·ªÆ T∆Ø∆†NG T·ª∞**: 
   - ÈûãÊüú (xi√© gu√¨) = t·ªß gi√†y (KH√îNG ph·∫£i nh√† kho)
   - ÂÇ®Áâ©Êüú (ch«î w√π gu√¨) = t·ªß ƒë·ª±ng ƒë·ªì
   - ÁéÑÂÖ≥ (xu√°n guƒÅn) = khu v·ª±c l·ªëi v√†o nh√†
   - ÂÆ¢ÂéÖ (k√® tƒ´ng) = ph√≤ng kh√°ch
   - Âé®Êàø (ch√∫ f√°ng) = b·∫øp
5. **Kh√¥ng d·ªãch t√™n ri√™ng**: Gi·ªØ nguy√™n t√™n ng∆∞·ªùi, ƒë·ªãa danh, th∆∞∆°ng hi·ªáu.
6. **Gi·ªØ phong c√°ch h√¥**: Duy tr√¨ c√°ch x∆∞ng h√¥ v√† gi·ªçng ƒëi·ªáu ph√π h·ª£p v·ªõi ng·ªØ c·∫£nh.
7. **Gi·ªØ nguy√™n b·ªë c·ª•c v√† √Ω**: D·ªãch nguy√™n vƒÉn theo c√¢u v√† ƒëo·∫°n, kh√¥ng g·ªôp ho·∫∑c t√°ch n·∫øu kh√¥ng c·∫ßn thi·∫øt.
8. **T·ª± nhi√™n & d·ªÖ hi·ªÉu**: Chuy·ªÉn c√°c t·ª´ H√°n Vi·ªát √≠t th√¥ng d·ª•ng sang t·ª´ thu·∫ßn Vi·ªát.

=== VƒÇN B·∫¢N C·∫¶N D·ªäCH ===
{sentence}

=== Y√äU C·∫¶U ===
- Ch·ªâ tr·∫£ v·ªÅ b·∫£n d·ªãch ti·∫øng Vi·ªát, kh√¥ng k√®m gi·∫£i th√≠ch.
- Gi·ªØ nguy√™n c·∫•u tr√∫c ƒëo·∫°n v√† c√¢u.
- S·ª≠ d·ª•ng ti·∫øng Vi·ªát m·∫°ch l·∫°c, t·ª± nhi√™n v√† chuy√™n nghi·ªáp.
- D·ªãch s√°t nghƒ©a nh·∫•t c√≥ th·ªÉ.
- ƒê·∫∂C BI·ªÜT CH√ö √ù: Ph√¢n bi·ªát r√µ t·ªß gi√†y, t·ªß ƒë·ª±ng ƒë·ªì, nh√† kho, khu v·ª±c l·ªëi v√†o...
"""

            
            # Tham s·ªë √≠t bay b·ªïng cho ƒë·ªô ch√≠nh x√°c cao
            data = {
    "contents": [
        {
            "parts": [
                {
                    "text": prompt
                }
            ]
        }
    ],
    "generationConfig": {
        "temperature": 0.1,   # √çt s√°ng t·∫°o, s√°t nghƒ©a
        "topP": 0.3,          # T·∫≠p trung v√†o t·ª´/c·ª•m ph√π h·ª£p nh·∫•t
        "topK": 1,            # Ch·ªçn k·∫øt qu·∫£ t·ªëi ∆∞u
        "maxOutputTokens": 15000  # TƒÉng gi·ªõi h·∫°n n·∫øu vƒÉn b·∫£n d√†i
    }
            }
            
            # G·ª≠i request ƒë·∫øn Gemini API v·ªõi retry
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = requests.post(url, json=data, timeout=120)
                    
                    if response.status_code == 200:
                        result = response.json()
                        translated_sentence = result['candidates'][0]['content']['parts'][0]['text'].strip()
                        return translated_sentence
                    elif response.status_code == 429:  # Rate limit
                        logger.warning(f"‚ö†Ô∏è Rate limit, th·ª≠ l·∫°i l·∫ßn {attempt + 1}/{max_retries}")
                        time.sleep(2 ** attempt)  # Exponential backoff
                        continue
                    else:
                        logger.warning(f"‚ö†Ô∏è L·ªói API cho c√¢u: {sentence[:50]}...")
                        logger.warning(f"‚ö†Ô∏è Status code: {response.status_code}")
                        logger.warning(f"‚ö†Ô∏è Response: {response.text[:200]}...")
                        if attempt == max_retries - 1:  # L·∫ßn cu·ªëi
                            return sentence  # Tr·∫£ v·ªÅ c√¢u g·ªëc n·∫øu l·ªói
                        time.sleep(1)
                        continue
                        
                except requests.exceptions.Timeout:
                    logger.warning(f"‚ö†Ô∏è Timeout, th·ª≠ l·∫°i l·∫ßn {attempt + 1}/{max_retries}")
                    if attempt == max_retries - 1:
                        return sentence
                    time.sleep(1)
                    continue
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói d·ªãch c√¢u: {str(e)}")
            logger.error(f"‚ùå C√¢u g·ªëc: {sentence[:100]}...")
            return sentence  # Tr·∫£ v·ªÅ c√¢u g·ªëc n·∫øu l·ªói

    def _translate_sentence_with_timeline(self, text: str, context: str) -> str:
        """
        D·ªãch vƒÉn b·∫£n ti·∫øng Trung c√≥ timeline sang ti·∫øng Vi·ªát
        ƒê∆†N GI·∫¢N H√ìA: D·ªãch nguy√™n b·∫£n s√°t nghƒ©a, b·∫£o to√†n timeline
        
        Args:
            text: VƒÉn b·∫£n ti·∫øng Trung c√≥ timeline c·∫ßn d·ªãch
            context: Ng·ªØ c·∫£nh (kh√¥ng s·ª≠ d·ª•ng)
            
        Returns:
            VƒÉn b·∫£n ƒë√£ d·ªãch sang ti·∫øng Vi·ªát v·ªõi timeline ƒë∆∞·ª£c b·∫£o to√†n
        """
        try:
            import re
            
            # B∆∞·ªõc 1: T√°ch t·∫•t c·∫£ timeline v√† n·ªôi dung
            timeline_pattern = r'\(Gi√¢y\s+\d+-\d+\)'
            timeline_matches = list(re.finditer(timeline_pattern, text))
            
            if not timeline_matches:
                # Kh√¥ng c√≥ timeline, d·ªãch to√†n b·ªô vƒÉn b·∫£n
                return self._translate_single_sentence(text, context)
            
            logger.info(f"üìä T√¨m th·∫•y {len(timeline_matches)} timeline trong vƒÉn b·∫£n")
            
            # B∆∞·ªõc 2: T√°ch vƒÉn b·∫£n th√†nh c√°c ph·∫ßn
            parts = re.split(timeline_pattern, text)
            timelines = [match.group(0) for match in timeline_matches]
            
            # B∆∞·ªõc 3: D·ªãch t·ª´ng ph·∫ßn n·ªôi dung v√† gh√©p l·∫°i v·ªõi timeline
            translated_parts = []
            
            # Ph·∫ßn ƒë·∫ßu (tr∆∞·ªõc timeline ƒë·∫ßu ti√™n)
            if parts[0].strip():
                translated_first_part = self._translate_single_sentence(parts[0].strip(), context)
                if translated_first_part:
                    translated_parts.append(translated_first_part)
            
            # C√°c ph·∫ßn c√≥ timeline
            for i, (part, timeline) in enumerate(zip(parts[1:], timelines)):
                if part.strip():
                    translated_part = self._translate_single_sentence(part.strip(), context)
                    translated_parts.append(f"{timeline} {translated_part}")
                else:
                    translated_parts.append(timeline)
            
            # B∆∞·ªõc 4: Gh√©p l·∫°i th√†nh vƒÉn b·∫£n ho√†n ch·ªânh
            final_text = ' '.join(translated_parts)
            
            logger.info(f"üìä K·∫øt qu·∫£ d·ªãch c√≥ timeline: {len(timeline_matches)} segments")
            return final_text
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói d·ªãch vƒÉn b·∫£n c√≥ timeline: {str(e)}")
            return text  # Tr·∫£ v·ªÅ vƒÉn b·∫£n g·ªëc n·∫øu l·ªói

    def _qa_fidelity_check(self, original_text: str, translated_text: str) -> str:
        """
        QA trung th√†nh - ki·ªÉm tra v√† s·ª≠a l·ªói d·ªãch
        
        Args:
            original_text: VƒÉn b·∫£n ti·∫øng Trung g·ªëc
            translated_text: VƒÉn b·∫£n ti·∫øng Vi·ªát ƒë√£ d·ªãch
            
        Returns:
            VƒÉn b·∫£n ƒë√£ s·ª≠a l·ªói
        """
        try:
            # Chu·∫©n b·ªã request ƒë·∫øn Gemini API
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
            
            prompt = f"""
            === QA TRUNG TH√ÄNH - KI·ªÇM TRA D·ªäCH THU·∫¨T ===
            
            B·∫°n l√† chuy√™n gia ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªãch thu·∫≠t. Nhi·ªám v·ª•: So s√°nh vƒÉn b·∫£n g·ªëc v√† b·∫£n d·ªãch, t√¨m l·ªói v√† s·ª≠a.
            
            === VƒÇN B·∫¢N G·ªêC (TI·∫æNG TRUNG) ===
            {original_text}
            
            === B·∫¢N D·ªäCH (TI·∫æNG VI·ªÜT) ===
            {translated_text}
            
            === Y√äU C·∫¶U KI·ªÇM TRA ===
            1. **Thi·∫øu**: N·ªôi dung g·ªëc c√≥ nh∆∞ng d·ªãch thi·∫øu
            2. **Th·ª´a**: N·ªôi dung d·ªãch c√≥ nh∆∞ng g·ªëc kh√¥ng c√≥
            3. **Sai**: D·ªãch sai √Ω nghƒ©a ho·∫∑c thu·∫≠t ng·ªØ
            4. **T√™n ri√™ng**: C√≥ d·ªãch nh·∫ßm t√™n ri√™ng kh√¥ng
            5. **Ng·ªØ c·∫£nh**: C√≥ ph√π h·ª£p v·ªõi ng·ªØ c·∫£nh kh√¥ng
            
            === H∆Ø·ªöNG D·∫™N S·ª¨A ===
            - Li·ªát k√™ c√°c l·ªói t√¨m th·∫•y
            - ƒê∆∞a ra b·∫£n d·ªãch ƒë√£ s·ª≠a
            - Gi·ªØ nguy√™n c·∫•u tr√∫c v√† timeline
            - Ch·ªâ s·ª≠a l·ªói, kh√¥ng thay ƒë·ªïi n·ªôi dung ƒë√∫ng
            
            === ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI ===
            L·ªñI T√åM TH·∫§Y:
            [Li·ªát k√™ c√°c l·ªói]
            
            B·∫¢N D·ªäCH ƒê√É S·ª¨A:
            [B·∫£n d·ªãch ho√†n ch·ªânh ƒë√£ s·ª≠a l·ªói]
            """
            
            data = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.1,
                    "topP": 0.3,
                    "topK": 1,
                    "maxOutputTokens": 2000
                }
            }
            
            # G·ª≠i request ƒë·∫øn Gemini API
            response = requests.post(url, json=data, timeout=180)
            
            if response.status_code == 200:
                result = response.json()
                qa_result = result['candidates'][0]['content']['parts'][0]['text']
                
                # Tr√≠ch xu·∫•t b·∫£n d·ªãch ƒë√£ s·ª≠a t·ª´ k·∫øt qu·∫£ QA
                if "B·∫¢N D·ªäCH ƒê√É S·ª¨A:" in qa_result:
                    parts = qa_result.split("B·∫¢N D·ªäCH ƒê√É S·ª¨A:")
                    if len(parts) > 1:
                        corrected_translation = parts[1].strip()
                        logger.info("‚úÖ QA trung th√†nh ho√†n t·∫•t - ƒë√£ s·ª≠a l·ªói")
                        return corrected_translation
                
                # N·∫øu kh√¥ng t√¨m th·∫•y ph·∫ßn s·ª≠a, tr·∫£ v·ªÅ b·∫£n d·ªãch g·ªëc
                logger.info("‚ÑπÔ∏è QA trung th√†nh - kh√¥ng t√¨m th·∫•y l·ªói c·∫ßn s·ª≠a")
                return translated_text
            else:
                logger.warning("‚ö†Ô∏è QA trung th√†nh th·∫•t b·∫°i - gi·ªØ nguy√™n b·∫£n d·ªãch g·ªëc")
                return translated_text
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói QA trung th√†nh: {str(e)}")
            return translated_text  # Tr·∫£ v·ªÅ b·∫£n d·ªãch g·ªëc n·∫øu l·ªói

    def _qa_fidelity_check_with_timeline(self, original_text: str, translated_text: str) -> str:
        """
        QA trung th√†nh v·ªõi b·∫£o to√†n timeline - ki·ªÉm tra v√† s·ª≠a l·ªói d·ªãch
        C·∫¢I THI·ªÜN: ƒê·∫∑c bi·ªát ch√∫ √Ω b·∫£o to√†n timeline
        
        Args:
            original_text: VƒÉn b·∫£n ti·∫øng Trung g·ªëc
            translated_text: VƒÉn b·∫£n ti·∫øng Vi·ªát ƒë√£ d·ªãch
            
        Returns:
            VƒÉn b·∫£n ƒë√£ s·ª≠a l·ªói v·ªõi timeline ƒë∆∞·ª£c b·∫£o to√†n
        """
        try:
            import re
            
            # B∆∞·ªõc 1: Ki·ªÉm tra timeline trong vƒÉn b·∫£n g·ªëc
            timeline_pattern = r'\(Gi√¢y\s+\d+-\d+\)'
            original_timelines = re.findall(timeline_pattern, original_text)
            translated_timelines = re.findall(timeline_pattern, translated_text)
            
            logger.info(f"üìä Timeline trong vƒÉn b·∫£n g·ªëc: {len(original_timelines)}")
            logger.info(f"üìä Timeline trong vƒÉn b·∫£n d·ªãch: {len(translated_timelines)}")
            
            # B∆∞·ªõc 2: N·∫øu thi·∫øu timeline, th√™m l·∫°i
            if len(original_timelines) > len(translated_timelines):
                logger.warning("‚ö†Ô∏è Ph√°t hi·ªán thi·∫øu timeline, ƒëang kh√¥i ph·ª•c...")
                
                # T√°ch vƒÉn b·∫£n th√†nh c√°c ph·∫ßn c√≥ timeline
                parts = re.split(timeline_pattern, original_text)
                timelines = re.findall(timeline_pattern, original_text)
                
                # Gh√©p l·∫°i v·ªõi timeline
                restored_text = ""
                for i, (part, timeline) in enumerate(zip(parts[1:], timelines)):  # B·ªè qua ph·∫ßn ƒë·∫ßu
                    # D·ªãch ph·∫ßn n·ªôi dung
                    if part.strip():
                        translated_part = self._translate_single_sentence(part.strip(), "")
                    else:
                        translated_part = ""
                    
                    # Gh√©p timeline + n·ªôi dung ƒë√£ d·ªãch
                    restored_text += f"{timeline} {translated_part}\n\n"
                
                logger.info("‚úÖ ƒê√£ kh√¥i ph·ª•c timeline th√†nh c√¥ng")
                return restored_text.strip()
            
            # B∆∞·ªõc 3: QA b√¨nh th∆∞·ªùng n·∫øu timeline ƒë√£ ƒë·∫ßy ƒë·ªß
            return self._qa_fidelity_check(original_text, translated_text)
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói QA v·ªõi timeline: {str(e)}")
            return translated_text  # Tr·∫£ v·ªÅ b·∫£n d·ªãch g·ªëc n·∫øu l·ªói
    
    def find_video_in_folder(self, folder_id: str, video_name: str = "video1.mp4") -> Dict:
        """
        T√¨m video trong Google Drive folder
        
        Args:
            folder_id: ID c·ªßa folder tr√™n Google Drive
            video_name: T√™n file video c·∫ßn t√¨m
            
        Returns:
            Dict ch·ª©a th√¥ng tin video ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        try:
            # T·∫°o query ƒë·ªÉ t√¨m file trong folder
            query = f"'{folder_id}' in parents and name='{video_name}'"
            
            # G·ªçi Google Drive API ƒë·ªÉ t√¨m file
            results = self.drive_service.files().list(
                q=query,
                fields="files(id,name,size,mimeType)",
                orderBy="name"
            ).execute()
            
            files = results.get('files', [])
            
            # Ki·ªÉm tra k·∫øt qu·∫£
            if not files:
                logger.warning(f"‚ùå Kh√¥ng t√¨m th·∫•y video {video_name} trong folder {folder_id}")
                return None
            
            # L·∫•y th√¥ng tin video ƒë·∫ßu ti√™n t√¨m th·∫•y
            video_info = files[0]
            logger.info(f"‚úÖ T√¨m th·∫•y video: {video_info['name']} (ID: {video_info['id']}, Size: {video_info.get('size', 'Unknown')} bytes)")
            
            return video_info
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t√¨m video: {str(e)}")
            return None
    
    def get_all_videos_in_folder(self, folder_id: str) -> List[Dict]:
        """
        L·∫•y t·∫•t c·∫£ video trong Google Drive folder
        
        Args:
            folder_id: ID c·ªßa folder tr√™n Google Drive
            
        Returns:
            List ch·ª©a th√¥ng tin t·∫•t c·∫£ video
        """
        try:
            # T·∫°o query ƒë·ªÉ t√¨m t·∫•t c·∫£ file video trong folder
            query = f"'{folder_id}' in parents and (mimeType contains 'video/' or name contains '.mp4' or name contains '.avi' or name contains '.mov')"
            
            logger.info(f"üîç T√¨m ki·∫øm video trong folder ID: {folder_id}")
            logger.info(f"üîç Query: {query}")
            
            # G·ªçi Google Drive API ƒë·ªÉ t√¨m file
            results = self.drive_service.files().list(
                q=query,
                fields="files(id,name,size,mimeType,trashed)",
                orderBy="name"
            ).execute()
            
            files = results.get('files', [])
            logger.info(f"üìÑ T·ªïng s·ªë file t√¨m th·∫•y: {len(files)}")
            
            # Hi·ªÉn th·ªã t·∫•t c·∫£ file ƒë·ªÉ debug
            for i, file in enumerate(files):
                name = file.get('name', 'Unknown')
                mime_type = file.get('mimeType', 'Unknown')
                size = file.get('size', 'Unknown')
                trashed = file.get('trashed', False)
                logger.info(f"  {i+1}. {name} (MIME: {mime_type}, Size: {size}, Trashed: {trashed})")
            
            # L·ªçc ch·ªâ l·∫•y file video (kh√¥ng b·ªã x√≥a)
            video_files = []
            for file in files:
                name = file.get('name', '').lower()
                mime_type = file.get('mimeType', '')
                trashed = file.get('trashed', False)
                
                # B·ªè qua file ƒë√£ b·ªã x√≥a
                if trashed:
                    logger.info(f"‚è≠Ô∏è B·ªè qua file ƒë√£ x√≥a: {file.get('name', 'Unknown')}")
                    continue
                
                # Ki·ªÉm tra c√≥ ph·∫£i file video kh√¥ng
                if (mime_type.startswith('video/') or 
                    name.endswith('.mp4') or 
                    name.endswith('.avi') or 
                    name.endswith('.mov') or
                    name.endswith('.mkv')):
                    video_files.append(file)
                    logger.info(f"‚úÖ Th√™m video: {file.get('name', 'Unknown')}")
                else:
                    logger.info(f"‚è≠Ô∏è B·ªè qua file kh√¥ng ph·∫£i video: {file.get('name', 'Unknown')} (MIME: {mime_type})")
            
            logger.info(f"üìÅ T√¨m th·∫•y {len(video_files)} video trong folder")
            for video in video_files:
                logger.info(f"  - {video['name']} (ID: {video['id']}, Size: {video.get('size', 'Unknown')} bytes)")
            
            return video_files
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói l·∫•y danh s√°ch video: {str(e)}")
            return []
    
    def download_video(self, file_id: str, video_name: str) -> str:
        """
        T·∫£i video t·ª´ Google Drive v·ªÅ m√°y local
        
        Args:
            file_id: ID c·ªßa file tr√™n Google Drive
            video_name: T√™n file ƒë·ªÉ l∆∞u
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video ƒë√£ t·∫£i
        """
        try:
            # T·∫°o th∆∞ m·ª•c t·∫°m n·∫øu ch∆∞a c√≥
            if not self.temp_dir:
                self.temp_dir = tempfile.mkdtemp()
                logger.info(f"ƒê√£ t·∫°o th∆∞ m·ª•c t·∫°m: {self.temp_dir}")
            
            # ƒê∆∞·ªùng d·∫´n file video s·∫Ω l∆∞u
            video_path = os.path.join(self.temp_dir, f"{video_name}")
            
            logger.info(f"üîÑ ƒêang t·∫£i video: {video_name}")
            
            # T·∫£i file t·ª´ Google Drive
            request = self.drive_service.files().get_media(fileId=file_id)
            with open(video_path, 'wb') as f:
                downloader = MediaIoBaseDownload(f, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                    if status:
                        logger.info(f"üì• T·∫£i: {int(status.progress() * 100)}%")
            
            logger.info(f"‚úÖ T·∫£i video th√†nh c√¥ng: {video_path}")
            return video_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫£i video: {str(e)}")
            raise
    
    def convert_to_mp3(self, video_path: str, output_name: str) -> str:
        """
        Chuy·ªÉn ƒë·ªïi video th√†nh MP3 b·∫±ng FFmpeg
        
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file MP3 ƒë√£ t·∫°o
        """
        try:
            # T·∫°o t√™n file MP3 output
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}.mp3")
            
            logger.info(f"üîÑ ƒêang t√°ch audio t·ª´: {os.path.basename(video_path)}")
            
            # L·ªánh FFmpeg ƒë·ªÉ chuy·ªÉn ƒë·ªïi video th√†nh MP3
            cmd = [
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "tools", "ffmpeg.exe"),  # ƒê∆∞·ªùng d·∫´n FFmpeg
                "-i", video_path,  # Input file
                "-vn",  # Kh√¥ng c√≥ video
                "-acodec", "mp3",  # Codec audio MP3
                "-ab", "192k",  # Bitrate 192k
                "-ar", "44100",  # Sample rate 44.1kHz
                "-y",  # Ghi ƒë√® file n·∫øu t·ªìn t·∫°i
                output_path  # Output file
            ]
            
            # Ch·∫°y l·ªánh FFmpeg
            logger.info("ƒêang ch·∫°y FFmpeg...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
            
            # Ki·ªÉm tra k·∫øt qu·∫£
            if result.returncode == 0:
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    logger.info(f"‚úÖ T√°ch MP3 th√†nh c√¥ng!")
                    logger.info(f"üìÅ File: {output_path}")
                    logger.info(f"üìä K√≠ch th∆∞·ªõc: {file_size:,} bytes")
                    return output_path
                else:
                    raise Exception("Kh√¥ng t·∫°o ƒë∆∞·ª£c file MP3")
            else:
                raise Exception(f"FFmpeg l·ªói: {result.stderr}")
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi video: {str(e)}")
            raise
    
    def extract_voice_only(self, video_path: str, output_name: str) -> str:
        """
        T√°ch voice t·ª´ video, lo·∫°i b·ªè background music
        
        S·ª≠ d·ª•ng FFmpeg v·ªõi filter n√¢ng cao ƒë·ªÉ:
        1. T√°ch voice kh·ªèi background music
        2. S·ª≠ d·ª•ng filter ph·ª©c t·∫°p ƒë·ªÉ nh·∫≠n di·ªán voice
        3. T·ªëi ∆∞u ch·∫•t l∆∞·ª£ng voice cho text recognition
        
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file MP3 ch·ªâ c√≥ voice
        """
        try:
            # T·∫°o t√™n file voice output
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_voice_only.mp3")
            
            logger.info(f"üé§ ƒêang t√°ch voice t·ª´: {os.path.basename(video_path)}")
            logger.info("üîß S·ª≠ d·ª•ng filter n√¢ng cao ƒë·ªÉ lo·∫°i b·ªè background music...")
            
            # L·ªánh FFmpeg n√¢ng cao ƒë·ªÉ t√°ch voice
            # S·ª≠ d·ª•ng filter ph·ª©c t·∫°p h∆°n ƒë·ªÉ nh·∫≠n di·ªán v√† t√°ch voice
            cmd = [
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "tools", "ffmpeg.exe"),  # ƒê∆∞·ªùng d·∫´n FFmpeg
                "-i", video_path,  # Input file
                "-vn",  # Kh√¥ng c√≥ video
                "-af", "highpass=f=150,lowpass=f=4000,volume=2.0,anlmdn=s=7:p=0.002:r=0.01",  # Filter n√¢ng cao
                "-acodec", "mp3",  # Codec audio MP3
                "-ab", "192k",  # Bitrate cao h∆°n cho ch·∫•t l∆∞·ª£ng t·ªët
                "-ar", "44100",  # Sample rate cao h∆°n
                "-ac", "1",  # Mono channel cho voice
                "-y",  # Ghi ƒë√® file n·∫øu t·ªìn t·∫°i
                output_path  # Output file
            ]
            
            # Ch·∫°y l·ªánh FFmpeg
            logger.info("ƒêang ch·∫°y FFmpeg v·ªõi voice filter n√¢ng cao...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # Timeout d√†i h∆°n
            
            # Ki·ªÉm tra k·∫øt qu·∫£
            if result.returncode == 0:
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    logger.info(f"‚úÖ T√°ch voice th√†nh c√¥ng!")
                    logger.info(f"üìÅ File voice: {output_path}")
                    logger.info(f"üìä K√≠ch th∆∞·ªõc: {file_size:,} bytes")
                    return output_path
                else:
                    raise Exception("Kh√¥ng t·∫°o ƒë∆∞·ª£c file voice")
            else:
                # N·∫øu filter ph·ª©c t·∫°p th·∫•t b·∫°i, th·ª≠ filter ƒë∆°n gi·∫£n h∆°n
                logger.warning("‚ö†Ô∏è Filter ph·ª©c t·∫°p th·∫•t b·∫°i, th·ª≠ filter ƒë∆°n gi·∫£n...")
                return self._extract_voice_simple(video_path, output_name)
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói t√°ch voice: {str(e)}")
            # Fallback v·ªÅ ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n
            return self._extract_voice_simple(video_path, output_name)
    
    def _extract_voice_simple(self, video_path: str, output_name: str) -> str:
        """
        Ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n ƒë·ªÉ t√°ch voice (fallback)
        
        S·ª≠ d·ª•ng filter c∆° b·∫£n ƒë·ªÉ t√°ch voice:
        - Highpass filter: lo·∫°i b·ªè t·∫ßn s·ªë th·∫•p (bass)
        - Lowpass filter: lo·∫°i b·ªè t·∫ßn s·ªë cao (treble)
        - Volume boost: tƒÉng √¢m l∆∞·ª£ng voice
        """
        try:
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_voice_simple.mp3")
            
            logger.info("üîÑ Th·ª≠ ph∆∞∆°ng ph√°p t√°ch voice ƒë∆°n gi·∫£n...")
            
            # L·ªánh FFmpeg ƒë∆°n gi·∫£n ƒë·ªÉ t√°ch voice
            cmd = [
                os.path.join(os.path.dirname(os.path.dirname(__file__)), "tools", "ffmpeg.exe"),
                "-i", video_path,
                "-vn",
                "-af", "highpass=f=300,lowpass=f=2000,volume=2.0",  # Filter ƒë∆°n gi·∫£n
                "-acodec", "mp3",
                "-ab", "96k",  # Bitrate th·∫•p cho voice
                "-ar", "16000",  # Sample rate th·∫•p
                "-ac", "1",  # Mono
                "-y",
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                logger.info(f"‚úÖ T√°ch voice ƒë∆°n gi·∫£n th√†nh c√¥ng!")
                logger.info(f"üìÅ File: {output_path}")
                logger.info(f"üìä K√≠ch th∆∞·ªõc: {file_size:,} bytes")
                return output_path
            else:
                raise Exception(f"FFmpeg l·ªói: {result.stderr}")
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói t√°ch voice ƒë∆°n gi·∫£n: {str(e)}")
            raise
    
    def mp3_to_text(self, audio_path: str, output_name: str) -> str:
        """
        Chuy·ªÉn ƒë·ªïi MP3 th√†nh text b·∫±ng Deepgram API (Legacy method - kept for compatibility)
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file MP3
            output_name: T√™n file output (kh√¥ng c√≥ extension)
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ t·∫°o
        """
        try:
            # S·ª≠ d·ª•ng method m·ªõi v·ªõi language detection
            text_path, _, _ = self.extract_text_with_language_detection(audio_path, output_name)
            return text_path
        except Exception as e:
            logger.error(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi audio th√†nh text: {str(e)}")
            raise
    
    def _retry_with_different_model(self, audio_path: str, output_name: str) -> str:
        """
        Th·ª≠ l·∫°i v·ªõi model kh√°c n·∫øu model ƒë·∫ßu ti√™n th·∫•t b·∫°i
        """
        try:
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_transcript_retry.txt")
            
            logger.info("üîÑ Th·ª≠ l·∫°i v·ªõi model kh√°c...")
            
            with open(audio_path, 'rb') as audio_file:
                url = "https://api.deepgram.com/v1/listen"
                headers = {
                    "Authorization": f"Token {self.deepgram_api_key}",
                    "Content-Type": "audio/mpeg"
                }
                
                # Th·ª≠ v·ªõi model c≈© h∆°n
                params = {
                    "model": "enhanced",
                    "language": "vi",
                    "punctuate": "true"
                }
                
                response = requests.post(url, headers=headers, params=params, data=audio_file, timeout=600)
                
                if response.status_code == 200:
                    result = response.json()
                    transcript = result['results']['channels'][0]['alternatives'][0]['transcript']
                    
                    if transcript and transcript.strip():
                        with open(output_path, 'w', encoding='utf-8') as f:
                            f.write(transcript)
                        
                        logger.info(f"‚úÖ Th·ª≠ l·∫°i th√†nh c√¥ng v·ªõi model kh√°c!")
                        logger.info(f"üìù ƒê·ªô d√†i text: {len(transcript)} k√Ω t·ª±")
                        
                        return output_path
                    else:
                        raise Exception("Transcript v·∫´n r·ªóng")
                else:
                    raise Exception(f"Retry failed: {response.status_code}")
                    
        except Exception as e:
            logger.error(f"‚ùå Th·ª≠ l·∫°i c≈©ng th·∫•t b·∫°i: {str(e)}")
            raise
    
    def rewrite_text(self, text_path: str, output_name: str) -> str:
        """
        Vi·∫øt l·∫°i text b·∫±ng Gemini API d·ª±a tr√™n prompt t·ª´ Google Sheets
        
        T·∫°o n·ªôi dung M·ªöI HO√ÄN TO√ÄN d·ª±a tr√™n:
        1. Prompt template t·ª´ Google Sheets
        2. N·ªôi dung g·ªëc ƒë·ªÉ tham kh·∫£o ch·ªß ƒë·ªÅ
        3. Y√™u c·∫ßu vi·∫øt l·∫°i theo phong c√°ch TikTok
        
        Args:
            text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text g·ªëc
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ vi·∫øt l·∫°i (n·ªôi dung m·ªõi ho√†n to√†n)
        """
        try:
            # T·∫°o t√™n file output cho text ƒë√£ vi·∫øt l·∫°i
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_rewritten.txt")
            
            logger.info(f"üîÑ ƒêang vi·∫øt l·∫°i text (n·ªôi dung m·ªõi): {os.path.basename(text_path)}")
            
            # ƒê·ªçc text g·ªëc t·ª´ file
            with open(text_path, 'r', encoding='utf-8') as f:
                original_text = f.read()
            
            # Chu·∫©n b·ªã request ƒë·∫øn Gemini API
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
            
            # ƒê·ªçc prompt template t·ª´ Google Sheets
            prompt_template = self.get_prompt_from_sheets()
            
            # Prompt ƒë·ªÉ vi·∫øt l·∫°i text theo y√™u c·∫ßu t·ª´ Google Sheets v·ªõi gi·ªçng vƒÉn mi·ªÅn B·∫Øc
            prompt = f"""
            === H∆Ø·ªöNG D·∫™N VI·∫æT L·∫†I N·ªòI DUNG M·ªöI ===
            
            B·∫°n l√† chuy√™n gia vi·∫øt n·ªôi dung TikTok chuy√™n nghi·ªáp. Nhi·ªám v·ª•: Vi·∫øt l·∫°i n·ªôi dung M·ªöI HO√ÄN TO√ÄN nh∆∞ng B√ÅM CH·∫∂T TIMELINE c·ªßa n·ªôi dung g·ªëc.
            
            === PROMPT TEMPLATE T·ª™ GOOGLE SHEETS (C·∫¨P NH·∫¨T M·ªöI) ===
            {prompt_template}
            
            === Y√äU C·∫¶U QUAN TR·ªåNG ===
            - TUY·ªÜT ƒê·ªêI TU√ÇN TH·ª¶ prompt template t·ª´ Google Sheets
            - S·ª≠ d·ª•ng ƒë√∫ng b·ªë c·ª•c, phong c√°ch, v√† y√™u c·∫ßu t·ª´ prompt template
            - Kh√¥ng b·ªè qua b·∫•t k·ª≥ ph·∫ßn n√†o trong prompt template
            - ƒê·∫£m b·∫£o ti√™u ƒë·ªÅ, caption, CTA theo ƒë√∫ng format t·ª´ prompt template
            - **GI·ªÆ GI·ªåNG VƒÇN TH√ÇN THI·ªÜN:** S·ª≠ d·ª•ng x∆∞ng h√¥ "em - b√°c" v·ª´a ph·∫£i ƒë·ªÉ t·∫°o s·ª± g·∫ßn g≈©i, kh√¥ng l·∫°m d·ª•ng
            - **CHIA NH·ªé √ù, D·ªÑ NGHE, D·ªÑ NH·ªö:** Chia n·ªôi dung th√†nh c√°c √Ω nh·ªè, r√µ r√†ng, d·ªÖ hi·ªÉu
            - **H·∫†N CH·∫æ X∆ØNG H√î:** Thay v√¨ "em l√†m... em thi·∫øt k·∫ø...", d√πng "m√¨nh b·ªë tr√≠ th·∫ø n√†y... th·ª≠ l√†m th·∫ø kia..."
            - **KH√îNG T·∫†O C√ÇU D·∫™N:** B·∫Øt ƒë·∫ßu n·ªôi dung ch√≠nh tr·ª±c ti·∫øp v·ªõi timeline, kh√¥ng c√≥ c√¢u d·∫´n m·ªü ƒë·∫ßu
            - **B·ªé HO√ÄN TO√ÄN CH√ÄO H·ªéI:** Kh√¥ng d√πng "Ch√†o c√°c b√°c", "Em ch√†o b√°c", "Xin ch√†o" - b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi n·ªôi dung
            - **CH·ªà MI√äU T·∫¢ H√ÄNH ƒê·ªòNG:** T·∫≠p trung v√†o nh·ªØng g√¨ ƒëang di·ªÖn ra trong video
            - **C·∫§M TUY·ªÜT ƒê·ªêI C√ÇU D·∫™N:** Kh√¥ng vi·∫øt c√¢u d·∫´n tr∆∞·ªõc timeline, b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi "(Gi√¢y 0-8)"
            - **CH·ªà C√ì TIMELINE:** N·ªôi dung ch√≠nh ch·ªâ c√≥ c√°c ƒëo·∫°n timeline, kh√¥ng c√≥ g√¨ kh√°c
            - **KH√îNG S·ª¨ D·ª§NG D·∫§U () "":** Ch·ªâ d√πng c√°c d·∫•u c√¢u b√¨nh th∆∞·ªùng, kh√¥ng d√πng d·∫•u ngo·∫∑c ƒë∆°n, ngo·∫∑c k√©p
            - **B·ªé D·∫§U ...:** Vi·∫øt li·ªÅn m·∫°ch, kh√¥ng d√πng d·∫•u ba ch·∫•m
            - **CHIA √ù R√ï R√ÄNG:** N·ªôi dung vi·∫øt l·∫°i chia √Ω r√µ r√†ng h∆°n k√®m icon
            - **ICON üëâ K·∫æT H·ª¢P N·ªòI DUNG:** Icon üëâ ph·∫£i k·∫øt h·ª£p tr·ª±c ti·∫øp v·ªõi n·ªôi dung, kh√¥ng ph·∫£i ch·ªâ l√† ƒë·ªÅ m·ª•c ri√™ng bi·ªát
            - **V√ç D·ª§ ƒê√öNG:** "üëâ B√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng ƒë·ªÉ treo qu·∫ßn √°o..."
            - **V√ç D·ª§ SAI:** "üëâ B√™n ph·∫£i\nB√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng..." (b·ªã th·ª´a)
            - **T√ÅCH BI·ªÜT N·ªòI DUNG:** CAPTION G·ª¢I √ù V√Ä CTA KH√îNG ƒê∆Ø·ª¢C XU·∫§T HI·ªÜN TRONG N·ªòI DUNG CH√çNH
            - **CH·ªà N·ªòI DUNG TIMELINE:** C·ªôt Text c·∫£i ti·∫øn ch·ªâ ch·ª©a n·ªôi dung ch√≠nh v·ªõi timeline, kh√¥ng c√≥ caption, CTA
            
            === N·ªòI DUNG G·ªêC ƒê·ªÇ THAM KH·∫¢O CH·ª¶ ƒê·ªÄ ===
            {original_text}
            
            === L∆ØU √ù QUAN TR·ªåNG V·ªÄ N·ªòI DUNG CH√çNH ===
            - **TUY·ªÜT ƒê·ªêI KH√îNG T·∫†O C√ÇU D·∫™N:** Kh√¥ng vi·∫øt c√¢u d·∫´n m·ªü ƒë·∫ßu nh∆∞ "Nhi·ªÅu b√°c c·ª© nghƒ©...", "H√¥m nay em s·∫Ω chia s·∫ª..."
            - **B·∫ÆT ƒê·∫¶U TR·ª∞C TI·∫æP V·ªöI TIMELINE:** N·ªôi dung ch√≠nh ph·∫£i b·∫Øt ƒë·∫ßu ngay v·ªõi "(Gi√¢y 0-8) ..."
            - **GI·ªÆ GI·ªåNG VƒÇN TH√ÇN THI·ªÜN:** S·ª≠ d·ª•ng x∆∞ng h√¥ "em - b√°c" v·ª´a ph·∫£i ƒë·ªÉ t·∫°o s·ª± g·∫ßn g≈©i, kh√¥ng l·∫°m d·ª•ng
            - **CHIA NH·ªé √ù, D·ªÑ NGHE, D·ªÑ NH·ªö:** Chia n·ªôi dung th√†nh c√°c √Ω nh·ªè, r√µ r√†ng, d·ªÖ hi·ªÉu
            - **H·∫†N CH·∫æ X∆ØNG H√î:** Thay v√¨ "em l√†m... em thi·∫øt k·∫ø...", d√πng "m√¨nh b·ªë tr√≠ th·∫ø n√†y... th·ª≠ l√†m th·∫ø kia..."
            - **CH·ªà MI√äU T·∫¢ H√ÄNH ƒê·ªòNG:** T·∫≠p trung v√†o nh·ªØng g√¨ ƒëang di·ªÖn ra trong video
            - **V√ç D·ª§ ƒê√öNG:** "(Gi√¢y 0-8) Nhi·ªÅu nh√† ƒë·ªÉ t·ªß gi√†y h·ªü, hai b√™n c√≥ khe th·ª´a kh√≥ x·ª≠ l√Ω..."
            - **V√ç D·ª§ SAI:** "(Gi√¢y 0-8) Ch√†o c√°c b√°c, h√¥m nay em s·∫Ω chia s·∫ª m·ªôt gi·∫£i ph√°p..."
            - **B·∫ÆT BU·ªòC:** N·ªôi dung ch√≠nh ch·ªâ c√≥ timeline, kh√¥ng c√≥ c√¢u d·∫´n tr∆∞·ªõc timeline
            - **C·∫§M TUY·ªÜT ƒê·ªêI:** Kh√¥ng vi·∫øt c√¢u d·∫´n tr∆∞·ªõc "(Gi√¢y 0-8)"
            - **C·∫§M TUY·ªÜT ƒê·ªêI CH√ÄO H·ªéI:** Kh√¥ng d√πng "Ch√†o c√°c b√°c", "Em ch√†o b√°c", "Xin ch√†o" - b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi n·ªôi dung
            - **C·∫§M TUY·ªÜT ƒê·ªêI C√ÇU D·∫™N:** Kh√¥ng vi·∫øt c√¢u d·∫´n tr∆∞·ªõc timeline, b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi "(Gi√¢y 0-8)"
            - **CH·ªà C√ì TIMELINE:** N·ªôi dung ch√≠nh ch·ªâ c√≥ c√°c ƒëo·∫°n timeline, kh√¥ng c√≥ g√¨ kh√°c
            - **KH√îNG S·ª¨ D·ª§NG D·∫§U () "":** Ch·ªâ d√πng c√°c d·∫•u c√¢u b√¨nh th∆∞·ªùng, kh√¥ng d√πng d·∫•u ngo·∫∑c ƒë∆°n, ngo·∫∑c k√©p
            - **B·ªé D·∫§U ...:** Vi·∫øt li·ªÅn m·∫°ch, kh√¥ng d√πng d·∫•u ba ch·∫•m
            - **CHIA √ù R√ï R√ÄNG:** N·ªôi dung vi·∫øt l·∫°i chia √Ω r√µ r√†ng h∆°n k√®m icon
            - **ICON üëâ K·∫æT H·ª¢P N·ªòI DUNG:** Icon üëâ ph·∫£i k·∫øt h·ª£p tr·ª±c ti·∫øp v·ªõi n·ªôi dung, kh√¥ng ph·∫£i ch·ªâ l√† ƒë·ªÅ m·ª•c ri√™ng bi·ªát
            - **V√ç D·ª§ ƒê√öNG:** "üëâ B√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng ƒë·ªÉ treo qu·∫ßn √°o..."
            - **V√ç D·ª§ SAI:** "üëâ B√™n ph·∫£i\nB√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng..." (b·ªã th·ª´a)
            - **T√ÅCH BI·ªÜT N·ªòI DUNG:** CAPTION G·ª¢I √ù V√Ä CTA KH√îNG ƒê∆Ø·ª¢C XU·∫§T HI·ªÜN TRONG N·ªòI DUNG CH√çNH
            - **CH·ªà N·ªòI DUNG TIMELINE:** C·ªôt Text c·∫£i ti·∫øn ch·ªâ ch·ª©a n·ªôi dung ch√≠nh v·ªõi timeline, kh√¥ng c√≥ caption, CTA
            
            === Y√äU C·∫¶U QUAN TR·ªåNG ===
            
            üö´ **T·ª™ C·∫§M TUY·ªÜT ƒê·ªêI KH√îNG ƒê∆Ø·ª¢C S·ª¨ D·ª§NG:**
            - **"m√°ch n∆∞·ªõc"** - Thay b·∫±ng "chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω"
            - **"hack"** - Thay b·∫±ng "b√≠ quy·∫øt", "m·∫πo", "c√°ch", "ph∆∞∆°ng ph√°p"
            - **"t·ª± h√†o"** - Thay b·∫±ng "hi·ªán ƒë·∫°i", "ti√™n ti·∫øn", "t·ªëi ∆∞u"
            - **"c·∫£ th·∫ø gi·ªõi"** - Thay b·∫±ng "hi·ªáu qu·∫£", "chuy√™n nghi·ªáp"
            - **"tuy·ªát v·ªùi"** - Thay b·∫±ng "xu·∫•t s·∫Øc", "v∆∞·ª£t tr·ªôi"
            - **"ƒë·ªôc ƒë√°o"** - Thay b·∫±ng "ƒë·∫∑c bi·ªát", "n·ªïi b·∫≠t"
            
            ‚úÖ **T·ª™ THAY TH·∫æ N√äN D√ôNG:**
            - Thay "m√°ch n∆∞·ªõc" b·∫±ng: "chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω"
            - Thay "hack" b·∫±ng: "b√≠ quy·∫øt", "m·∫πo", "c√°ch", "ph∆∞∆°ng ph√°p"
            - Thay "t·ª± h√†o" b·∫±ng: "hi·ªán ƒë·∫°i", "ti√™n ti·∫øn", "t·ªëi ∆∞u"
            
            üéØ **T·∫†O N·ªòI DUNG M·ªöI HO√ÄN TO√ÄN - PH·∫¢I HAY H∆†N B·∫¢N G·ªêC:**
            - KH√îNG copy n·ªôi dung g·ªëc - VI·∫æT M·ªöI HO√ÄN TO√ÄN
            - Ch·ªâ l·∫•y √Ω t∆∞·ªüng ch·ªß ƒë·ªÅ ƒë·ªÉ vi·∫øt m·ªõi, s√°ng t·∫°o h∆°n
            - T·∫°o ra text ho√†n to√†n kh√°c bi·ªát, h·∫•p d·∫´n h∆°n, hay h∆°n b·∫£n g·ªëc
            - **S√ÅNG T·∫†O T·ª™ NG·ªÆ:** D√πng t·ª´ ng·ªØ m·ªõi, c√°ch di·ªÖn ƒë·∫°t m·ªõi, kh√¥ng l·∫∑p l·∫°i b·∫£n g·ªëc
            - **TH√äM GI√Å TR·ªä:** B·ªï sung th√¥ng tin h·ªØu √≠ch, m·∫πo hay, kinh nghi·ªám th·ª±c t·∫ø
            - **ƒê·ªò D√ÄI PH√ô H·ª¢P:** Vi·∫øt v·ªõi ƒë·ªô d√†i t∆∞∆°ng ƒë∆∞∆°ng ho·∫∑c ng·∫Øn h∆°n n·ªôi dung g·ªëc, kh√¥ng vi·∫øt qu√° d√†i
            - **KI·ªÇM SO√ÅT ƒê·ªò D√ÄI:** M·ªói ƒëo·∫°n timeline n√™n c√≥ ƒë·ªô d√†i t∆∞∆°ng ƒë∆∞∆°ng v·ªõi n·ªôi dung g·ªëc, kh√¥ng m·ªü r·ªông qu√° nhi·ªÅu
            - **V√ç D·ª§ ƒê·ªò D√ÄI:**
              * N·ªôi dung g·ªëc: "(Gi√¢y 0-8) T·ªß gi√†y nh·ªè, kh√≥ x·ª≠ l√Ω"
              * ‚úÖ ƒê√öNG: "(Gi√¢y 0-8) T·ªß gi√†y nh·ªè g·ªçn, kh√≥ b·ªë tr√≠ ƒë·ªì ƒë·∫°c"
              * ‚ùå SAI: "(Gi√¢y 0-8) T·ªß gi√†y nh·ªè g·ªçn n√†y th·ª±c s·ª± r·∫•t kh√≥ ƒë·ªÉ x·ª≠ l√Ω v√† b·ªë tr√≠ ƒë·ªì ƒë·∫°c m·ªôt c√°ch h·ª£p l√Ω, ƒë·∫∑c bi·ªát l√† khi c√≥ nhi·ªÅu lo·∫°i gi√†y kh√°c nhau c·∫ßn s·∫Øp x·∫øp"
            - **T·ª∞ NHI√äN, D·ªÑ HI·ªÇU:** Vi·∫øt nh∆∞ ƒëang chia s·∫ª th·ª±c t·∫ø, kh√¥ng qu√° ti√™u chu·∫©n
            - **TR√ÅNH C√ÇU C·ª§T NGHƒ®A:** ƒê·∫£m b·∫£o c√¢u c√≥ nghƒ©a r√µ r√†ng, kh√¥ng b·ªã c·ª•t
            - **TUY·ªÜT ƒê·ªêI KH√îNG VI·∫æT Y H·ªÜT B·∫¢N G·ªêC:** N·∫øu vi·∫øt y h·ªát th√¨ kh√¥ng c√≥ gi√° tr·ªã
            
            ‚è∞ **B√ÅM CH·∫∂T TIMELINE - KH√îNG THAY ƒê·ªîI:**
            - **TIMELINE PH·∫¢I GI·ªÆ NGUY√äN 100%:** N·∫øu g·ªëc "(Gi√¢y 1-3) xin ch√†o" th√¨ m·ªõi ph·∫£i "(Gi√¢y 1-3) [n·ªôi dung m·ªõi]"
            - **KH√îNG THAY ƒê·ªîI TH·ªúI GIAN:** Gi·ªØ nguy√™n s·ªë gi√¢y, kh√¥ng th√™m/b·ªõt
            - **KH√îNG THAY ƒê·ªîI C·∫§U TR√öC:** Gi·ªØ nguy√™n format "(Gi√¢y X-Y) n·ªôi dung"
            - **CH·ªà VI·∫æT L·∫†I N·ªòI DUNG:** Thay ƒë·ªïi n·ªôi dung b√™n trong timeline, kh√¥ng ƒë·ª•ng ƒë·∫øn timeline
            
           
            üìù **√ÅP D·ª§NG PROMPT TEMPLATE:**
            - Tu√¢n th·ªß ƒë√∫ng y√™u c·∫ßu t·ª´ Google Sheets
            - √Åp d·ª•ng b·ªë c·ª•c v√† phong c√°ch ƒë√£ ƒë·ªãnh nghƒ©a
            -N·ªôi dung m·ªõi ph·∫£i hay v√† c√≥ s·ª± kh√°c bi·ªát v·ªõi n·ªôi dung c≈©
        -ƒê·ªô d√†i ph√π h·ª£p: Vi·∫øt v·ªõi ƒë·ªô d√†i t∆∞∆°ng ƒë∆∞∆°ng ho·∫∑c ng·∫Øn h∆°n n·ªôi dung g·ªëc, kh√¥ng vi·∫øt qu√° d√†i
            - S·ª≠ d·ª•ng c√°c m·∫´u CTA v√† caption g·ª£i √Ω
            - N·ªôi dung ti·∫øng vi·ªát ho√†n to√†n kh√¥ng s∆∞r d·ª•ng ti·∫øng anh
            
            üé® **PHONG C√ÅCH VI·∫æT - T·ª∞ NHI√äN V√Ä D·ªÑ HI·ªÇU:**
            - **VƒÉn phong chia s·∫ª tr·ª±c ti·∫øp:** Nh∆∞ ƒëang t∆∞ v·∫•n th·∫≠t, kh√¥ng kh√¥ khan hay nh·∫°t nh·∫Ωo
            - **T·ª´ ng·ªØ sinh ƒë·ªông:** D√πng t·ª´ c√≥ c·∫£m x√∫c, t·∫°o h·ª©ng th√∫ thay v√¨ t·ª´ kh√¥ khan
            - **T·ª± nhi√™n, d·ªÖ hi·ªÉu:** Vi·∫øt nh∆∞ ƒëang chia s·∫ª th·ª±c t·∫ø, kh√¥ng qu√° ti√™u chu·∫©n
            - **Tr√°nh c√¢u c·ª•t nghƒ©a:** ƒê·∫£m b·∫£o c√¢u c√≥ nghƒ©a r√µ r√†ng, kh√¥ng b·ªã c·ª•t
            - **ƒê·ªò D√ÄI V·ª™A PH·∫¢I:** Vi·∫øt ng·∫Øn g·ªçn, s√∫c t√≠ch, kh√¥ng qu√° d√†i so v·ªõi n·ªôi dung g·ªëc
            - **X∆∞ng h√¥ th√¢n thi·ªán:** "em - b√°c" ch·ªâ d√πng cho c√¢u d·∫´n (2 c√¢u ng·∫Øn g·ªçn), kh√¥ng d√πng trong n·ªôi dung ch√≠nh
            - **T·ª´ n·ªëi t·ª± nhi√™n:** "m√†", "ƒë·∫•y", "n√®", "·∫°", "nh·ªâ", "th·∫ø", "ƒê·ª´ng qu√™n", "ƒê·∫∑c bi·ªát l√†", "B√™n c·∫°nh ƒë√≥", "Ngo√†i ra", "B√¢y gi·ªù"
            - **T·ª™ N·ªêI LINH HO·∫†T:** D√πng t·ª´ n·ªëi ph·∫£i linh ho·∫°t, kh√¥ng l·∫∑p l·∫°i t·ª´ ƒë√£ c√≥ trong n·ªôi dung, b·ªè d·∫•u ph·∫©y ƒë·ªÉ k·∫øt h·ª£p t·ª± nhi√™n
            - **TR√ÅNH L·∫∂P T·ª™:** Kh√¥ng d√πng t·ª´ n·ªëi c√≥ ch·ª©a t·ª´ ƒë√£ c√≥ trong n·ªôi dung (v√≠ d·ª•: n·ªôi dung c√≥ "B√™n ph·∫£i" th√¨ kh√¥ng d√πng "B√™n c·∫°nh ƒë√≥")
            - **V√ç D·ª§ ƒê√öNG:** "üëâ B√™n ph·∫£i t·ªß m√¨nh thi·∫øt k·∫ø hai t·∫ßng..." (kh√¥ng l·∫∑p t·ª´, k·∫øt h·ª£p t·ª± nhi√™n)
            - **V√ç D·ª§ SAI:** "üëâ B√™n c·∫°nh ƒë√≥, B√™n ph·∫£i t·ªß, m√¨nh thi·∫øt k·∫ø..." (l·∫∑p t·ª´ "B√™n")
            - **V√ç D·ª§ SAI:** "üëâ B√™n c·∫°nh ƒë√≥, B√™n ph·∫£i t·ªß, m√¨nh thi·∫øt k·∫ø hai t·∫ßng... B√™n c·∫°nh ƒë√≥, m√¨nh l·∫Øp th√™m..." (l·∫∑p t·ª´ n·ªëi)
            - **V√ç D·ª§ C·ª§ TH·ªÇ:**
              * ‚ùå SAI: "üëâ B√™n c·∫°nh ƒë√≥, B√™n ph·∫£i t·ªß, m√¨nh thi·∫øt k·∫ø hai t·∫ßng... B√™n c·∫°nh ƒë√≥, m√¨nh l·∫Øp th√™m t·ªß b√™n c·∫°nh..." (l·∫∑p t·ª´ "B√™n")
              * ‚úÖ ƒê√öNG: "üëâ B√™n ph·∫£i t·ªß thi·∫øt k·∫ø hai t·∫ßng ƒë·ªÉ treo qu·∫ßn √°o, t·∫ßng tr√™n treo √°o kho√°c, t·∫ßng d∆∞·ªõi treo ƒë·ªì m·∫∑c ·ªü nh√†. Ngo√†i ra l·∫Øp th√™m t·ªß b√™n c·∫°nh v√† chia th√†nh ba ngƒÉn k√©o l·ªõn ƒë·ªÉ ƒë·ª±ng ƒë·ªì l√≥t, qu·∫ßn t·∫•t, r·∫•t ti·ªán l·ª£i."
            - **C√ÅCH S·ª¨ D·ª§NG LINH HO·∫†T:** 
              * N·∫øu n·ªôi dung c√≥ "B√™n ph·∫£i" ‚Üí d√πng "Ngo√†i ra", "ƒê·∫∑c bi·ªát l√†", "ƒê·ª´ng qu√™n"
              * N·∫øu n·ªôi dung c√≥ "B√™n tr√°i" ‚Üí d√πng "B√™n c·∫°nh ƒë√≥", "Ngo√†i ra", "ƒê·∫∑c bi·ªát l√†"
              * N·∫øu n·ªôi dung c√≥ "B√™n tr√™n" ‚Üí d√πng "B√™n c·∫°nh ƒë√≥", "Ngo√†i ra", "ƒê·ª´ng qu√™n"
              * Lu√¥n ki·ªÉm tra t·ª´ trong n·ªôi dung tr∆∞·ªõc khi ch·ªçn t·ª´ n·ªëi
            - **Bi·ªÉu c·∫£m sinh ƒë·ªông:** "hay ho", "tuy·ªát v·ªùi", "ch·∫Øc ch·∫Øn", "ƒë·∫£m b·∫£o"
            - **CHUY√äN NGHI·ªÜP:** D√πng t·ª´ ng·ªØ chuy√™n ng√†nh n·ªôi th·∫•t, ki·∫øn tr√∫c
            - **TR√ÅNH T·ª™ SU·ªíNG S√É:** Kh√¥ng d√πng "x∆∞a r·ªìi di·ªÖm ∆°i", "hot hit", "qu√° ƒë√£"
            - **TR√ÅNH T·ª™ S√ÅO R·ªñNG:** Kh√¥ng d√πng "m√°ch n∆∞·ªõc", "t·ª± h√†o", "c·∫£ th·∫ø gi·ªõi", "tuy·ªát v·ªùi", "ƒë·ªôc ƒë√°o"
            - **C√ÇU D·∫™N T·ª∞ NHI√äN:** Ph·∫£i n√™u ƒë√∫ng m·ª•c ƒë√≠ch v√† gi√° tr·ªã th·ª±c t·∫ø c·ªßa n·ªôi dung
            - **V√ç D·ª§ C√ÇU D·∫™N:**
              * ‚úÖ ƒê√öNG: "T·ªß qu·∫ßn √°o nh·ªè m√† bi·∫øt c√°ch b·ªë tr√≠ th√¨ c√≥ th·ªÉ ch·ª©a ƒë∆∞·ª£c nhi·ªÅu ƒë·ªì h∆°n b√°c nghƒ©. Em s·∫Ω chia s·∫ª c√°ch s·∫Øp x·∫øp hi·ªáu qu·∫£."
              * ‚úÖ ƒê√öNG: "T·ªß gi√†y nh·ªè kh√≥ b·ªë tr√≠ ƒë·ªì ƒë·∫°c. B√°c th·ª≠ c√°ch n√†y xem."
              * ‚ùå SAI: "C√°c b√°c ƒëang ƒëau ƒë·∫ßu v√¨ t·ªß qu·∫ßn √°o ch·∫≠t ch·ªôi? ƒê·ª´ng lo, em chia s·∫ª cho c√°c b√°c c√°ch hi·ªáu qu·∫£ nh·∫•t!"
            - **C√ÅCH VI·∫æT C√ÇU D·∫™N:**
              * Ch·ªâ 2 c√¢u ng·∫Øn g·ªçn, ƒë√∫ng tr·ªçng t√¢m
              * C√¢u 1: N√™u v·∫•n ƒë·ªÅ th·ª±c t·∫ø + c√≥ x∆∞ng h√¥ "b√°c"
              * C√¢u 2: G·ª£i √Ω gi·∫£i ph√°p + c√≥ x∆∞ng h√¥ "b√°c"
              * T·ª± nhi√™n, kh√¥ng c∆∞·ªùng ƒëi·ªáu: Tr√°nh "ƒëau ƒë·∫ßu", "chia s·∫ª", "t·ª± h√†o"
            - **GI·ªåNG VƒÇN N·ªòI DUNG CH√çNH:**
              * D√πng gi·ªçng ·∫©n danh trung t√≠nh, kh√¥ng x∆∞ng h√¥ "em", "b√°c", "m√¨nh"
              * V√≠ d·ª•: "B√™n ph·∫£i t·ªß thi·∫øt k·∫ø hai t·∫ßng" thay v√¨ "B√™n ph·∫£i t·ªß m√¨nh thi·∫øt k·∫ø hai t·∫ßng"
              * V√≠ d·ª•: "L·∫Øp th√™m k·ªá ƒëa nƒÉng" thay v√¨ "M√¨nh l·∫Øp th√™m k·ªá ƒëa nƒÉng"
              * V√≠ d·ª•: "Chia th√†nh ba ngƒÉn k√©o" thay v√¨ "Em chia th√†nh ba ngƒÉn k√©o"
            - **THAY TH·∫æ B·∫∞NG:** "hi·ªán ƒë·∫°i", "ti√™n ti·∫øn", "t·ªëi ∆∞u", "chuy√™n nghi·ªáp", "chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω"
            
            üé¨ **MI√äU T·∫¢ H√ÄNH ƒê·ªòNG TRONG VIDEO:**
            - **T·∫≠p trung v√†o h√†nh ƒë·ªông c·ª• th·ªÉ:** Mi√™u t·∫£ nh·ªØng g√¨ ƒëang di·ªÖn ra trong video
            - **S·ª≠ d·ª•ng ƒë·ªông t·ª´ h√†nh ƒë·ªông:** "chia t·ªß", "l·∫Øp th√™m", "b√†y bi·ªán", "ph√¢n lo·∫°i"
            - **Mi√™u t·∫£ quy tr√¨nh t·ª´ng b∆∞·ªõc:** "ƒê·∫ßu ti√™n...", "B√™n c·∫°nh ƒë√≥...", "Ngo√†i ra...", "ƒê·∫∑c bi·ªát l√†...", "ƒê·ª´ng qu√™n..."
            - **Nh·∫•n m·∫°nh k·∫øt qu·∫£:** "v·ª´a ƒë·∫πp m·∫Øt l·∫°i ti·ªán d·ª•ng", "qu√° ti·ªán l·ª£i lu√¥n"
            - **T·∫°o c·∫£m gi√°c tr·ª±c quan:** Ng∆∞·ªùi xem c√≥ th·ªÉ h√¨nh dung ƒë∆∞·ª£c h√†nh ƒë·ªông ƒëang di·ªÖn ra
            - **GI·ªÆ GI·ªåNG VƒÇN TH√ÇN THI·ªÜN:** S·ª≠ d·ª•ng x∆∞ng h√¥ "em - b√°c" v·ª´a ph·∫£i ƒë·ªÉ t·∫°o s·ª± g·∫ßn g≈©i, kh√¥ng l·∫°m d·ª•ng
            - **CHIA NH·ªé √ù, D·ªÑ NGHE, D·ªÑ NH·ªö:** Chia n·ªôi dung th√†nh c√°c √Ω nh·ªè, r√µ r√†ng, d·ªÖ hi·ªÉu
            - **H·∫†N CH·∫æ X∆ØNG H√î:** Thay v√¨ "em l√†m... em thi·∫øt k·∫ø...", d√πng "m√¨nh b·ªë tr√≠ th·∫ø n√†y... th·ª≠ l√†m th·∫ø kia..."
            - **B·ªé HO√ÄN TO√ÄN CH√ÄO H·ªéI:** Kh√¥ng d√πng "Ch√†o c√°c b√°c", "Em ch√†o b√°c", "Xin ch√†o" - b·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi n·ªôi dung
            - **V√ç D·ª§ ƒê√öNG:** "Nhi·ªÅu nh√† ƒë·ªÉ t·ªß gi√†y h·ªü, hai b√™n c√≥ khe th·ª´a kh√≥ x·ª≠ l√Ω, l·∫°i c√≤n v∆∞·ªõng c·ª≠a b·∫øp ch·ªâ m·ªü ƒë∆∞·ª£c m·ªôt c√°nh."
            - **V√ç D·ª§ SAI:** "Ch√†o c√°c b√°c, h√¥m nay em s·∫Ω chia s·∫ª m·ªôt gi·∫£i ph√°p t·ªëi ∆∞u cho khu v·ª±c s·∫£nh ƒë√≥n kh√°ch..."
            
            üó£Ô∏è **ƒê·∫∂C ƒêI·ªÇM GI·ªåNG VƒÇN CHUY√äN NGHI·ªÜP:**
            - D√πng "gi·∫£i ph√°p t·ªëi ∆∞u" thay v√¨ "m·∫πo hay ho"
            - D√πng "ƒë·∫£m b·∫£o hi·ªáu qu·∫£" thay v√¨ "ch·∫Øc ch·∫Øn s·∫Ω"
            - D√πng "xu·∫•t s·∫Øc" thay v√¨ "tuy·ªát v·ªùi"
            - D√πng "v∆∞·ª£t tr·ªôi" thay v√¨ "kh√°c h·∫≥n"
            - D√πng "cam k·∫øt" thay v√¨ "ƒë·∫£m b·∫£o"
            - D√πng "t·ªëi ∆∞u h√≥a" thay v√¨ "c·ª±c k·ª≥ hi·ªáu qu·∫£"
            - D√πng "thi·∫øt k·∫ø hi·ªán ƒë·∫°i" thay v√¨ "hot hit"
            - D√πng "phong c√°ch ti√™n ti·∫øn" thay v√¨ "x∆∞a r·ªìi di·ªÖm ∆°i"
            - D√πng "chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω" thay v√¨ "m√°ch n∆∞·ªõc"
            
            === QUY T·∫ÆC TIMELINE B·∫ÆT BU·ªòC ===
            1. **T√åM TIMELINE:** X√°c ƒë·ªãnh t·∫•t c·∫£ c√°c ƒëo·∫°n c√≥ format "(Gi√¢y X-Y)"
            2. **GI·ªÆ NGUY√äN:** Kh√¥ng thay ƒë·ªïi s·ªë gi√¢y, kh√¥ng thay ƒë·ªïi format
            3. **VI·∫æT L·∫†I N·ªòI DUNG:** Ch·ªâ thay ƒë·ªïi n·ªôi dung b√™n trong timeline v·ªõi gi·ªçng vƒÉn t·ª± nhi√™n hay h∆°n
            4. **KI·ªÇM TRA:** ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng timeline v√† th·ªùi gian gi·ªëng h·ªát g·ªëc
            5. **GI·ªÆ GI·ªåNG VƒÇN TH√ÇN THI·ªÜN:** S·ª≠ d·ª•ng x∆∞ng h√¥ "em - b√°c" v·ª´a ph·∫£i ƒë·ªÉ t·∫°o s·ª± g·∫ßn g≈©i, kh√¥ng l·∫°m d·ª•ng
            6. **CHIA NH·ªé √ù, D·ªÑ NGHE, D·ªÑ NH·ªö:** Chia n·ªôi dung th√†nh c√°c √Ω nh·ªè, r√µ r√†ng, d·ªÖ hi·ªÉu
            7. **H·∫†N CH·∫æ X∆ØNG H√î:** Thay v√¨ "em l√†m... em thi·∫øt k·∫ø...", d√πng "m√¨nh b·ªë tr√≠ th·∫ø n√†y... th·ª≠ l√†m th·∫ø kia..."
            8. **KH√îNG C√ÇU D·∫™N:** B·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp v·ªõi timeline ƒë·∫ßu ti√™n, kh√¥ng c√≥ c√¢u d·∫´n m·ªü ƒë·∫ßu
            
            === NGUY√äN T·∫ÆC VI·∫æT HAY H∆†N ===
            üî• **TR√ÅNH NH·ªÆNG ƒêI·ªÄU N√ÄY:**
            - VƒÉn nh·∫°t nh·∫Ωo: "ƒêi·ªÅu n√†y r·∫•t t·ªët" ‚Üí "C√°i n√†y tuy·ªát v·ªùi lu√¥n"
            - **VI·∫æT Y H·ªÜT B·∫¢N G·ªêC:** Copy nguy√™n vƒÉn b·∫£n g·ªëc - KH√îNG C√ì GI√Å TR·ªä
            - **THI·∫æU S√ÅNG T·∫†O:** Ch·ªâ thay ƒë·ªïi v√†i t·ª´, kh√¥ng t·∫°o gi√° tr·ªã m·ªõi
            - **KH√îNG TH√äM GI√Å TR·ªä:** Kh√¥ng b·ªï sung th√¥ng tin h·ªØu √≠ch m·ªõi
            # - VƒÉn k·ªÉ chuy·ªán: "C√≥ m·ªôt c√°ch ƒë·ªÉ..." ‚Üí "Em s·∫Ω ch·ªâ b√°c c√°ch..." - ƒê√É COMMENT
            - T·ª´ kh√¥ khan: "ph∆∞∆°ng ph√°p" ‚Üí "m·∫πo hay ho"
            - Thi·∫øu c·∫£m x√∫c: "c√≥ th·ªÉ l√†m" ‚Üí "ch·∫Øc ch·∫Øn l√†m ƒë∆∞·ª£c"
            - Mi√™u t·∫£ chung chung: "L√†m c√°i n√†y" ‚Üí "Chia t·ªß th√†nh hai ph·∫ßn tr√™n d∆∞·ªõi"
            - Ch√†o h·ªèi x∆∞ng h√¥: "Ch√†o c√°c b√°c, em s·∫Ω chia s·∫ª..." ‚Üí "Nhi·ªÅu nh√† ƒë·ªÉ t·ªß gi√†y h·ªü..."
            
            ‚ú® **√ÅP D·ª§NG NH·ªÆNG ƒêI·ªÄU N√ÄY:**
            - **S√ÅNG T·∫†O HO√ÄN TO√ÄN:** Vi·∫øt m·ªõi ho√†n to√†n, kh√¥ng copy b·∫£n g·ªëc
            - **TH√äM GI√Å TR·ªä M·ªöI:** B·ªï sung th√¥ng tin h·ªØu √≠ch, m·∫πo hay, kinh nghi·ªám th·ª±c t·∫ø
            - **T·ª™ NG·ªÆ M·ªöI:** D√πng c√°ch di·ªÖn ƒë·∫°t m·ªõi, kh√¥ng l·∫∑p l·∫°i b·∫£n g·ªëc
            - **PH·∫¢I HAY H∆†N B·∫¢N G·ªêC:** N·ªôi dung m·ªõi ph·∫£i c√≥ gi√° tr·ªã cao h∆°n
            - D√πng t·ª´ c√≥ nƒÉng l∆∞·ª£ng: "c·ª±c k·ª≥", "si√™u", "tuy·ªát v·ªùi", "hay ho"
            - T·∫°o s·ª± t·ª± tin: "ch·∫Øc ch·∫Øn", "ƒë·∫£m b·∫£o", "100%"
            - G√¢y t√≤ m√≤: "m·∫πo n√†y", "b√≠ quy·∫øt", "chi√™u hay"
            # - T∆∞∆°ng t√°c tr·ª±c ti·∫øp: "b√°c th·ª≠ xem", "em ch·ªâ b√°c" - ƒê√É COMMENT
            - Mi√™u t·∫£ h√†nh ƒë·ªông c·ª• th·ªÉ: "Chia t·ªß th√†nh hai ph·∫ßn", "L·∫Øp th√™m m√°y l·ªçc n∆∞·ªõc"
            - Nh·∫•n m·∫°nh k·∫øt qu·∫£: "v·ª´a ƒë·∫πp m·∫Øt l·∫°i ti·ªán d·ª•ng", "qu√° ti·ªán l·ª£i lu√¥n"
            - B·∫Øt ƒë·∫ßu tr·ª±c ti·∫øp: "Nhi·ªÅu nh√† ƒë·ªÉ t·ªß gi√†y h·ªü, hai b√™n c√≥ khe th·ª´a kh√≥ x·ª≠ l√Ω..."
            
            === C·∫§U TR√öC K·∫æT QU·∫¢ Y√äU C·∫¶U ===
            
            TI√äU ƒê·ªÄ G·ª¢I √ù (5 ti√™u ƒë·ªÅ, m·ªói √Ω c√°ch nhau 1 d√≤ng):
            1. üéØ "S·∫£nh v√†o nh√† g·ªçn g√†ng th·∫ø n√†y th√¨ ai c≈©ng m√™!"
            2. üí° "B·ªë tr√≠ s·∫£nh chu·∫©n, nh√¨n l√† mu·ªën l√†m ngay!"
            3. üî• "Ai c≈©ng b·ªè l·ª° g√≥c n√†y khi thi·∫øt k·∫ø nh√†!"
            4. ‚≠ê "S·∫£nh nh·ªè nh∆∞ng c√¥ng nƒÉng g·∫•p ƒë√¥i, ƒë√¢y l√† b√≠ quy·∫øt!"
            5. ‚ú® "G·ªçn ‚Äì ƒë·∫πp ‚Äì ti·ªán: S·∫£nh v√†o nh√† ki·ªÉu m·ªõi!"
            
            
            [2 c√¢u d·∫´n d·∫Øt ng·∫Øn g·ªçn, ƒë√∫ng tr·ªçng t√¢m, c√≥ x∆∞ng h√¥ "b√°c", g·ª£i √Ω gi·∫£i ph√°p, d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø]
            
            üëâ ƒê·∫ßu ti√™n [n·ªôi dung chi ti·∫øt v·ªõi timeline]
            
            üëâ B√™n c·∫°nh ƒë√≥ [n·ªôi dung chi ti·∫øt v·ªõi timeline]
            
            üëâ [L·∫ßn l∆∞·ª£t d·ª±a v√†o n·ªôi dung vi·∫øt g√¨, b√™n tr√°i b√™n ph·∫£i, b√™n tr√™n b√™n d∆∞·ªõi, g√≥c n√†y g√≥c kia] [n·ªôi dung chi ti·∫øt v·ªõi timeline]
            
            üëâ B√¢y gi·ªù [C√¢u t·ªïng k·∫øt c·ªßa n·ªôi dung - ƒë√≥ l√† c√¢u trong n·ªôi dung vi·∫øt l·∫°i]
            
            L∆∞u √Ω: M·ªói √Ω trong n·ªôi dung c√°ch nhau 1 d√≤ng, kh√¥ng s√°t qu√°
            
            === PH·∫¶N RI√äNG BI·ªÜT - CH·ªà XU·∫§T HI·ªÜN TRONG C·ªòT G·ª¢I √ù TI√äU ƒê·ªÄ ===
            
            CAPTION G·ª¢I √ù (3 caption, m·ªói √Ω c√°ch nhau 1 d√≤ng):
            B·∫ÆT BU·ªòC VI·∫æT 3 CAPTION C·ª§ TH·ªÇ, KH√îNG ƒê·ªÇ TR·ªêNG []. C√ì TH·ªÇ K√àM ICON V√Ä HASHTAG:
            1. üéØ "Thi·∫øt k·∫ø t·ªß gi√†y √¢m t∆∞·ªùng: Gi·∫£i ph√°p t·ªëi ∆∞u cho kh√¥ng gian hi·ªán ƒë·∫°i! #thietkenoithat #tugiayamtuong #khonggianhiendai"
            2. üí° "T·ªß gi√†y √¢m t∆∞·ªùng: K·∫øt h·ª£p ho√†n h·∫£o gi·ªØa th·∫©m m·ªπ v√† c√¥ng nƒÉng! #noithat #tugiay #thietkechuyennghiep"
            3. üî• "Thi·∫øt k·∫ø t·ªß gi√†y th√¥ng minh: T·ªëi ∆∞u h√≥a kh√¥ng gian s·ªëng! #tugiaythongminh #toiuuhoa #khonggiansong"
            
            CALL TO ACTION (CTA) - T·ªêI ∆ØU N·ªòI DUNG H∆†N 1 CH√öT:
            B·∫ÆT BU·ªòC VI·∫æT 1 CTA C·ª§ TH·ªÇ, KH√îNG ƒê·ªÇ TR·ªêNG []. C√ì TH·ªÇ K√àM ICON:
            üéØ "Thi·∫øt k·∫ø t·ªß gi√†y √¢m t∆∞·ªùng n√†y s·∫Ω n√¢ng t·∫ßm kh√¥ng gian s·ªëng c·ªßa c√°c b√°c! L∆∞u l·∫°i ngay ƒë·ªÉ tham kh·∫£o, chia s·∫ª cho b·∫°n b√® c√πng xem nh√©!"
            
            === L∆ØU √ù ===
            - Text c·∫£i ti·∫øn s·∫Ω ƒë∆∞·ª£c t√°ch th√†nh 2 ph·∫ßn ri√™ng bi·ªát
            - Ph·∫ßn 1: CH·ªà n·ªôi dung ch√≠nh c√≥ timeline (c·ªôt Text c·∫£i ti·∫øn) - KH√îNG IN PH·∫¶N TI√äU ƒê·ªÄ, CAPTION, CTA
            - Ph·∫ßn 2: Ti√™u ƒë·ªÅ + Caption + CTA (c·ªôt G·ª£i √Ω ti√™u ƒë·ªÅ)
            - TUY·ªÜT ƒê·ªêI KH√îNG ƒê·ªÇ CAPTION G·ª¢I √ù V√Ä CTA TRONG C·ªòT TEXT C·∫¢I TI·∫æN
            - CAPTION G·ª¢I √ù V√Ä CTA PH·∫¢I CH·ªà XU·∫§T HI·ªÜN TRONG C·ªòT G·ª¢I √ù TI√äU ƒê·ªÄ
            
            === QUY T·∫ÆC QUAN TR·ªåNG ===
            - Timeline ph·∫£i gi·ªëng h·ªát g·ªëc (s·ªë gi√¢y v√† format)
            - N·ªôi dung b√™n trong timeline ph·∫£i sinh ƒë·ªông, h·∫•p d·∫´n, kh√¥ng nh·∫°t nh·∫Ωo
            - **S√ÅNG T·∫†O HO√ÄN TO√ÄN:** Vi·∫øt m·ªõi ho√†n to√†n, kh√¥ng copy b·∫£n g·ªëc, ph·∫£i hay h∆°n b·∫£n g·ªëc
            - **TH√äM GI√Å TR·ªä:** B·ªï sung th√¥ng tin h·ªØu √≠ch, m·∫πo hay, kinh nghi·ªám th·ª±c t·∫ø m√† b·∫£n g·ªëc kh√¥ng c√≥
            - **T·ª™ NG·ªÆ M·ªöI:** D√πng c√°ch di·ªÖn ƒë·∫°t m·ªõi, t·ª´ ng·ªØ m·ªõi, kh√¥ng l·∫∑p l·∫°i b·∫£n g·ªëc
            - **TUY·ªÜT ƒê·ªêI KH√îNG VI·∫æT Y H·ªÜT:** N·∫øu vi·∫øt y h·ªát b·∫£n g·ªëc th√¨ kh√¥ng c√≥ gi√° tr·ªã
            # - S·ª≠ d·ª•ng x∆∞ng h√¥ "em - b√°c" t·ª± nhi√™n - ƒê√É COMMENT
            - **MI√äU T·∫¢ H√ÄNH ƒê·ªòNG:** T·∫≠p trung v√†o nh·ªØng g√¨ ƒëang di·ªÖn ra trong video, s·ª≠ d·ª•ng ƒë·ªông t·ª´ c·ª• th·ªÉ
            - ƒê·∫£m b·∫£o ho√†n ch·ªânh v√† cu·ªën h√∫t
            - C√ì TH·ªÇ S·ª¨ D·ª§NG ICON H·ª¢P L√ù: C√≥ th·ªÉ d√πng icon ph√π h·ª£p nh∆∞ üéØ, üí°, üî•, ‚≠ê, ‚ú® ƒë·ªÉ l√†m n·ªïi b·∫≠t n·ªôi dung
            
            === H∆Ø·ªöNG D·∫™N VI·∫æT TI√äU ƒê·ªÄ HAY ===
            üéØ **TI√äU ƒê·ªÄ PH·∫¢I:**
            - Li√™n quan tr·ª±c ti·∫øp ƒë·∫øn n·ªôi dung ƒë√£ vi·∫øt
            - T·∫°o c·∫£m gi√°c "ph·∫£i xem ngay"
            - **D√ôNG T·ª™ NG·ªÆ NH√ÇN H√ìA** ƒë·ªÉ t·∫°o t√≤ m√≤ v√† h·ª©ng th√∫
            - D√πng t·ª´ m·∫°nh ƒêA D·∫†NG: "b√≠ quy·∫øt", "m·∫πo", "chi√™u", "c√°ch", "tuy·ªát chi√™u", "b√≠ k√≠p", "th·ªß thu·∫≠t", "k·ªπ thu·∫≠t", "ph∆∞∆°ng ph√°p", "gi·∫£i ph√°p"
            - T·∫°o t√≤ m√≤: "99% ng∆∞·ªùi kh√¥ng bi·∫øt", "ch·ªâ 1% l√†m ƒë√∫ng", "b√≠ m·∫≠t", "√≠t ai bi·∫øt", "ch∆∞a ai nghƒ© ƒë·∫øn"
            - Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ: "kh√¥ng c√≤n lo", "d·ª©t ƒëi·ªÉm", "x·ª≠ l√Ω tri·ªát ƒë·ªÉ", "gi·∫£i quy·∫øt ho√†n h·∫£o"
            - PH√ÇN BI·ªÜT R√ï: N·∫øu video v·ªÅ t·ªß gi√†y th√¨ vi·∫øt "t·ªß gi√†y", kh√¥ng vi·∫øt "nh√† kho"
            - CHUY√äN NGHI·ªÜP: D√πng t·ª´ ng·ªØ chuy√™n ng√†nh n·ªôi th·∫•t, ki·∫øn tr√∫c
            
            ‚ùå **TR√ÅNH TI√äU ƒê·ªÄ:**
            - Chung chung, kh√¥ng li√™n quan n·ªôi dung
            - Nh·∫°t nh·∫Ωo, kh√¥ng g√¢y t√≤ m√≤
            - Copy t·ª´ n·ªôi dung m·ªôt c√°ch m√°y m√≥c
            - D√πng sai t·ª´: "t·ªß gi√†y" th√†nh "nh√† kho"
            - L·∫†M D·ª§NG T·ª™ "HACK": Kh√¥ng d√πng "hack" cho m·ªçi th·ª©, thay b·∫±ng t·ª´ kh√°c
            - T·ª™ SU·ªíNG S√É: Kh√¥ng d√πng "x∆∞a r·ªìi di·ªÖm ∆°i", "hot hit", "qu√° ƒë√£", "ghen t·ªã"
            
            === H∆Ø·ªöNG D·∫™N VI·∫æT CAPTION HAY ===
            üéØ **CAPTION PH·∫¢I:**
            - C√≥ hashtag ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ
            - **D·∫™N ƒê·∫æN N·ªòI DUNG CH√çNH:** "H√£y xem b√≠ quy·∫øt l√† g√¨", "Nh·ªù c√°ch n√†y", "ƒê√¢y ch√≠nh l√†", "B√≠ m·∫≠t n·∫±m ·ªü"
            - T·∫°o c·∫£m x√∫c m·∫°nh: "wow", "kh√¥ng th·ªÉ tin ƒë∆∞·ª£c", "tuy·ªát v·ªùi"
            - Khuy·∫øn kh√≠ch t∆∞∆°ng t√°c: "b·∫°n c√≥ l√†m ƒë∆∞·ª£c kh√¥ng?", "th·ª≠ ngay ƒëi"
            - T·∫°o gi√° tr·ªã: "ti·∫øt ki·ªám ti·ªÅn", "ti·∫øt ki·ªám th·ªùi gian", "hi·ªáu qu·∫£"
            
            ‚ùå **TR√ÅNH CAPTION:**
            - Nh·∫°t nh·∫Ωo, kh√¥ng c√≥ c·∫£m x√∫c
            - Kh√¥ng khuy·∫øn kh√≠ch t∆∞∆°ng t√°c
            - Hashtag kh√¥ng li√™n quan
            
            === H∆Ø·ªöNG D·∫™N VI·∫æT CTA M·ªöI ===
            üéØ **CTA PH·∫¢I:**
            - D·ª±a tr√™n phong c√°ch m·∫´u CTA trong prompt template
            - S√°ng t·∫°o m·ªõi, kh√¥ng copy nguy√™n vƒÉn
            - Ph√π h·ª£p v·ªõi n·ªôi dung c·ª• th·ªÉ n√†y
            - C√≥ y·∫øu t·ªë: l∆∞u l·∫°i, chia s·∫ª, b√¨nh lu·∫≠n, k·∫øt n·ªëi, t∆∞ v·∫•n
            # - Gi·ªçng ƒëi·ªáu th√¢n thi·ªán "em - b√°c" - ƒê√É COMMENT
            - ƒêA D·∫†NG T·ª™ NG·ªÆ: Kh√¥ng l·∫°m d·ª•ng t·ª´ "hack", d√πng "b√≠ quy·∫øt", "m·∫πo", "c√°ch", "ph∆∞∆°ng ph√°p"
            - **XIN T∆Ø∆†NG T√ÅC:** Th√™m √Ω nh·∫Øn xin 1 tim, 1 chia s·∫ª, 1 b√¨nh lu·∫≠n ƒë·ªÉ t·∫°o ƒë·ªông l·ª±c
            
            ‚ùå **TR√ÅNH CTA:**
            - Copy nguy√™n vƒÉn t·ª´ m·∫´u
            - Kh√¥ng li√™n quan ƒë·∫øn n·ªôi dung
            - Gi·ªçng ƒëi·ªáu kh√¥ khan
            - L·∫†M D·ª§NG T·ª™ "HACK": Kh√¥ng d√πng "hack" cho m·ªçi th·ª©
            """
            
            # Tham s·ªë t·ªëi ∆∞u cho vi·ªác vi·∫øt l·∫°i
            data = {
                "contents": [
                    {
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.6,  # S√°ng t·∫°o v·ª´a ph·∫£i
                    "topP": 0.9,         # ƒêa d·∫°ng t·ª´ v·ª±ng
                    "topK": 60,          # L·ª±a ch·ªçn phong ph√∫
                    "maxOutputTokens": 3000
                }
            }
            
            # Rate limiting cho Gemini API
            self._wait_for_api_rate_limit('gemini')
            
            # G·ª≠i request ƒë·∫øn Gemini API
            logger.info("ƒêang g·ª≠i request ƒë·∫øn Gemini API ƒë·ªÉ vi·∫øt l·∫°i n·ªôi dung...")
            response = requests.post(url, json=data, timeout=360)
            
            # Ki·ªÉm tra response
            if response.status_code == 200:
                result = response.json()
                
                # L·∫•y text ƒë√£ vi·∫øt l·∫°i t·ª´ k·∫øt qu·∫£ Gemini
                rewritten_text = result['candidates'][0]['content']['parts'][0]['text']
                
                # L·ªçc t·ª´ c·∫•m trong n·ªôi dung ƒë√£ vi·∫øt l·∫°i
                rewritten_text = self._filter_forbidden_words(rewritten_text)
                
                # L∆∞u text m·ªõi v√†o file
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(rewritten_text)
                
                # Track token usage cho rewrite
                self.token_calculator.track_api_call(
                    operation="rewrite_text",
                    input_text=original_text,
                    output_text=rewritten_text,
                    api_type="gemini"
                )
                
                logger.info(f"‚úÖ Vi·∫øt l·∫°i text th√†nh c√¥ng (n·ªôi dung m·ªõi)!")
                logger.info(f"üìÅ File: {output_path}")
                logger.info(f"üìù ƒê·ªô d√†i text: {len(rewritten_text)} k√Ω t·ª±")
                logger.info(f"üìÑ N·ªôi dung m·ªõi: {rewritten_text[:200]}...")
                
                return output_path
            else:
                # N·∫øu API tr·∫£ v·ªÅ l·ªói
                error_msg = f"Gemini API l·ªói: {response.status_code} - {response.text}"
                logger.error(error_msg)
                
                # Log chi ti·∫øt h∆°n ƒë·ªÉ debug
                if response.status_code == 429:
                    logger.error("‚ùå QUOTA EXCEEDED - ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n API")
                elif response.status_code == 403:
                    logger.error("‚ùå FORBIDDEN - API key kh√¥ng h·ª£p l·ªá ho·∫∑c b·ªã disable")
                elif response.status_code == 400:
                    logger.error("‚ùå BAD REQUEST - L·ªói trong request format")
                
                logger.error(f"üìÑ Full response: {response.text}")
                raise Exception(error_msg)
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói vi·∫øt l·∫°i text: {str(e)}")
            raise

    def get_prompt_from_sheets(self) -> str:
        """
        ƒê·ªçc prompt template t·ª´ Google Sheets
        
        Returns:
            N·ªôi dung prompt template t·ª´ sheet "Prompt"
        """
        try:
            logger.info("üìä ƒêang ƒë·ªçc prompt template t·ª´ Google Sheets (c·∫≠p nh·∫≠t m·ªõi)...")
            
            # ƒê·ªçc d·ªØ li·ªáu t·ª´ sheet "Prompt" (d√≤ng 1-200 ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªçc h·∫øt prompt m·ªõi)
            # Th·ª≠ v·ªõi t√™n sheet kh√°c n·∫øu l·ªói
            range_name = 'Prompt!A1:Z200'
            
            # Th·ª±c hi·ªán request ƒë·ªÉ ƒë·ªçc prompt
            try:
                result = self.sheets_service.spreadsheets().values().get(
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name
                ).execute()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói v·ªõi t√™n sheet 'Prompt', th·ª≠ v·ªõi t√™n kh√°c: {str(e)}")
                # Th·ª≠ v·ªõi t√™n sheet kh√°c
                alternative_names = ['prompt', 'Prompt Template', 'PROMPT']
                for alt_name in alternative_names:
                    try:
                        range_name = f'{alt_name}!A1:Z200'
                        result = self.sheets_service.spreadsheets().values().get(
                            spreadsheetId=self.spreadsheet_id,
                            range=range_name
                        ).execute()
                        logger.info(f"‚úÖ Th√†nh c√¥ng v·ªõi t√™n sheet: {alt_name}")
                        break
                    except Exception as e2:
                        logger.warning(f"‚ö†Ô∏è L·ªói v·ªõi t√™n sheet '{alt_name}': {str(e2)}")
                        continue
                else:
                    # N·∫øu t·∫•t c·∫£ ƒë·ªÅu l·ªói, raise exception
                    raise e
            
            values = result.get('values', [])
            
            if not values:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu trong sheet Prompt")
                return self._get_fallback_prompt()
            
            # Gh√©p t·∫•t c·∫£ n·ªôi dung th√†nh m·ªôt chu·ªói
            sheet_prompt = ""
            for row in values:
                if row:  # Ki·ªÉm tra row kh√¥ng r·ªóng
                    sheet_prompt += " ".join(row) + "\n"
            
            logger.info(f"‚úÖ ƒê√£ ƒë·ªçc prompt template t·ª´ Google Sheets ({len(sheet_prompt)} k√Ω t·ª±)")
            logger.info(f"üìÑ Prompt preview: {sheet_prompt[:300]}...")
            
            # Ki·ªÉm tra xem prompt c√≥ ƒë·∫ßy ƒë·ªß kh√¥ng
            if len(sheet_prompt.strip()) < 100:
                logger.warning("‚ö†Ô∏è Prompt qu√° ng·∫Øn, c√≥ th·ªÉ ch∆∞a ƒë·ªçc h·∫øt. S·ª≠ d·ª•ng fallback...")
                return self._get_fallback_prompt()
            
            # Ki·ªÉm tra xem c√≥ ch·ª©a c√°c t·ª´ kh√≥a quan tr·ªçng kh√¥ng
            important_keywords = ['ti√™u ƒë·ªÅ', 'caption', 'cta', 'timeline', 'n·ªôi dung', 'g·ª£i √Ω 5 ti√™u ƒë·ªÅ', 'g·ª£i √Ω 3 caption', 'n·ªôi dung ch√≠nh']
            found_keywords = sum(1 for keyword in important_keywords if keyword in sheet_prompt.lower())
            
            if found_keywords < 3:
                logger.warning(f"‚ö†Ô∏è Prompt thi·∫øu t·ª´ kh√≥a quan tr·ªçng (ch·ªâ c√≥ {found_keywords}/5). S·ª≠ d·ª•ng fallback...")
                return self._get_fallback_prompt()
            
            logger.info(f"‚úÖ Prompt ƒë·∫ßy ƒë·ªß v√† h·ª£p l·ªá ({found_keywords}/5 t·ª´ kh√≥a quan tr·ªçng)")
            return sheet_prompt.strip()
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒë·ªçc prompt t·ª´ Google Sheets: {str(e)}")
            logger.info("üîÑ S·ª≠ d·ª•ng prompt fallback...")
            return self._get_fallback_prompt()

    def _get_fallback_prompt(self) -> str:
        """
        Prompt fallback khi kh√¥ng ƒë·ªçc ƒë∆∞·ª£c t·ª´ Google Sheets
        
        Returns:
            Prompt template m·∫∑c ƒë·ªãnh
        """
        return """
        B·∫°n l√† m·ªôt chuy√™n gia vi·∫øt n·ªôi dung TikTok chuy√™n nghi·ªáp. Nhi·ªám v·ª• c·ªßa b·∫°n l√† vi·∫øt l·∫°i n·ªôi dung text t·ª´ video/audio g·ªëc theo phong c√°ch TikTok h·∫•p d·∫´n.

        ## üìã Y√äU C·∫¶U CH√çNH:

        ### üéØ **B√ÅM CH·∫∂T TIMELINE - KH√îNG THAY ƒê·ªîI:**
        - **TIMELINE PH·∫¢I GI·ªÆ NGUY√äN 100%:** N·∫øu g·ªëc "(Gi√¢y 1-3) xin ch√†o" th√¨ m·ªõi ph·∫£i "(Gi√¢y 1-3) [n·ªôi dung m·ªõi]"
        - **KH√îNG THAY ƒê·ªîI TH·ªúI GIAN:** Gi·ªØ nguy√™n s·ªë gi√¢y, kh√¥ng th√™m/b·ªõt
        - **KH√îNG THAY ƒê·ªîI C·∫§U TR√öC:** Gi·ªØ nguy√™n format "(Gi√¢y X-Y) n·ªôi dung"
        - **CH·ªà VI·∫æT L·∫†I N·ªòI DUNG:** Thay ƒë·ªïi n·ªôi dung b√™n trong timeline, kh√¥ng ƒë·ª•ng ƒë·∫øn timeline
        - **√ù nghƒ©a t∆∞∆°ng ƒë∆∞∆°ng:** Kh√¥ng t·ª± s√°ng t·∫°o qu√° ƒë√†, ch·ªâ vi·∫øt l·∫°i theo c√°ch t·ª± nhi√™n h∆°n

        ### üìù **B·ªê C·ª§C VI·∫æT L·∫†I:**

        #### **1. TI√äU ƒê·ªÄ G·ª¢I √ù** (5 ti√™u ƒë·ªÅ h·∫•p d·∫´n, m·ªói √Ω c√°ch nhau 1 d√≤ng)
        - C√≥ th·ªÉ k√®m v√†i icon h·ª£p l√Ω (üéØ, üí°, üî•, ‚≠ê, ‚ú®)
        - N·ªôi dung ti√™u ƒë·ªÅ g·ª£i √Ω ph·∫£i hay v√† h·∫•p d·∫´n h∆°n
        - M·ªói ti√™u ƒë·ªÅ ng·∫Øn g·ªçn, b·∫Øt tai, g·ª£i t√≤ m√≤
        - Tr√°nh ti√™u ƒë·ªÅ nh·∫°t nh·∫Ωo, chung chung

        #### **2. N·ªòI DUNG CH√çNH** (B√ÅM CH·∫∂T TIMELINE)
        
        **D·∫´n d·∫Øt:**
        - Vi·∫øt 2-3 c√¢u d·∫´n d·∫Øt t·ª± nhi√™n, cu·ªën h√∫t
        - D·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø c·ªßa video
        - T·∫°o s·ª± t√≤ m√≤ v·ªÅ gi·∫£i ph√°p s·∫Ω chia s·∫ª
        - Tr√°nh c√¢u d·∫´n chung chung, kh√¥ng li√™n quan
        - Tr√°nh t·ª´ s√°o r·ªóng: "chia s·∫ª", "t·ª± h√†o", "c·∫£ th·∫ø gi·ªõi", "tuy·ªát v·ªùi", "ƒë·ªôc ƒë√°o"
        - C√¢u d·∫´n ph·∫£i n√™u ƒë√∫ng m·ª•c ƒë√≠ch v√† gi√° tr·ªã th·ª±c t·∫ø c·ªßa n·ªôi dung
        - N·ªôi dung ch√≠nh d√πng gi·ªçng ·∫©n danh trung t√≠nh, kh√¥ng x∆∞ng h√¥ "em", "b√°c", "m√¨nh"
        - C√¢u d·∫´n ch·ªâ 2 c√¢u ng·∫Øn g·ªçn, c√≥ x∆∞ng h√¥ "b√°c", ƒë√∫ng tr·ªçng t√¢m v√† g·ª£i √Ω gi·∫£i ph√°p

        **N·ªôi dung ch√≠nh:**
        [2 c√¢u d·∫´n d·∫Øt ng·∫Øn g·ªçn, ƒë√∫ng tr·ªçng t√¢m, c√≥ x∆∞ng h√¥ "b√°c", g·ª£i √Ω gi·∫£i ph√°p, d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø]
        
        üëâ ƒê·∫ßu ti√™n [n·ªôi dung chi ti·∫øt]
        
        üëâ B√™n c·∫°nh ƒë√≥ [n·ªôi dung chi ti·∫øt]
        
        üëâ [L·∫ßn l∆∞·ª£t d·ª±a v√†o n·ªôi dung vi·∫øt g√¨, b√™n tr√°i b√™n ph·∫£i, b√™n tr√™n b√™n d∆∞·ªõi, g√≥c n√†y g√≥c kia] [n·ªôi dung chi ti·∫øt]
        
        üëâ B√¢y gi·ªù [C√¢u t·ªïng k·∫øt c·ªßa n·ªôi dung - ƒë√≥ l√† c√¢u trong n·ªôi dung vi·∫øt l·∫°i]
        
        **L∆∞u √Ω:** M·ªói √Ω trong n·ªôi dung c√°ch nhau 1 d√≤ng, kh√¥ng s√°t qu√°

        #### **3. CAPTION G·ª¢I √ù** (3 caption, m·ªói √Ω c√°ch nhau 1 d√≤ng)
        - T∆∞∆°ng t·ª± nh∆∞ ti√™u ƒë·ªÅ, k√®m hashtag #
        - C√≥ th·ªÉ s·ª≠ d·ª•ng icon h·ª£p l√Ω
        - N·ªôi dung caption ph·∫£i h·∫•p d·∫´n, g·ª£i c·∫£m x√∫c
        - Hashtag ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ

        #### **4. CALL TO ACTION (CTA)** (T·ªëi ∆∞u n·ªôi dung h∆°n 1 ch√∫t)
        - Vi·∫øt CTA m·ªõi, s√°ng t·∫°o, kh√¥ng copy m·∫´u c≈©
        - N·ªôi dung ph·∫£i h·∫•p d·∫´n, th√∫c ƒë·∫©y h√†nh ƒë·ªông
        - C√≥ th·ªÉ k√®m icon ph√π h·ª£p
        - T·∫°o c·∫£m gi√°c kh·∫©n c·∫•p ho·∫∑c gi√° tr·ªã cao

        ## üîπ **QUY T·∫ÆC VI·∫æT N·ªòI DUNG:**

        ### **üéØ GI·ªÆ VƒÇN PHONG T·ª∞ NHI√äN HAY H∆†N:**
        - Kh√¥ng vi·∫øt ki·ªÉu "em l√†m c√°i n√†y, em l√†m c√°i kia" 
                    # - Chuy·ªÉn th√†nh l·ªëi chia s·∫ª tr·ª±c ti·∫øp "em s·∫Ω ch·ªâ b√°c c√°ch...", "b√°c th·ª≠ xem..." - ƒê√É COMMENT
                    # - D√πng x∆∞ng h√¥ th√¢n thi·ªán: "em - b√°c" ƒë·ªÉ t·∫°o s·ª± g·∫ßn g≈©i, tin c·∫≠y - ƒê√É COMMENT
        - T·ª´ ng·ªØ sinh ƒë·ªông: "m·∫πo hay ho", "tuy·ªát v·ªùi", "ch·∫Øc ch·∫Øn", "c·ª±c k·ª≥ hi·ªáu qu·∫£"
        - T·ª´ n·ªëi t·ª± nhi√™n: "m√†", "ƒë·∫•y", "n√®", "·∫°", "nh·ªâ", "th·∫ø", "ƒê·ª´ng qu√™n", "ƒê·∫∑c bi·ªát l√†", "B√™n c·∫°nh ƒë√≥", "Ngo√†i ra", "B√¢y gi·ªù"
        - T·ª™ N·ªêI LINH HO·∫†T: D√πng t·ª´ n·ªëi ph·∫£i linh ho·∫°t, kh√¥ng l·∫∑p l·∫°i t·ª´ ƒë√£ c√≥ trong n·ªôi dung, b·ªè d·∫•u ph·∫©y ƒë·ªÉ k·∫øt h·ª£p t·ª± nhi√™n
        - TR√ÅNH L·∫∂P T·ª™: Kh√¥ng d√πng t·ª´ n·ªëi c√≥ ch·ª©a t·ª´ ƒë√£ c√≥ trong n·ªôi dung (v√≠ d·ª•: n·ªôi dung c√≥ "B√™n ph·∫£i" th√¨ kh√¥ng d√πng "B√™n c·∫°nh ƒë√≥")
        - Bi·ªÉu c·∫£m cu·ªën h√∫t: "si√™u tuy·ªát", "hay ho", "ƒë·∫£m b·∫£o", "ch·∫Øc ch·∫Øn"
        
        ### **üìã C√ÅCH TR√åNH B√ÄY & NH·ªäP VƒÇN:**
        - **D√πng bullet point, icon:** üëâ, üîπ, üí° ƒë·ªÉ chia √Ω r√µ r√†ng, d·ªÖ l∆∞·ªõt
        - **C√¢u ng·∫Øn g·ªçn:** M·ªói c√¢u 1 √Ω duy nh·∫•t, tr√°nh c√¢u d√†i ph·ª©c t·∫°p
        - **C√≥ c√¥ng th·ª©c/con s·ªë c·ª• th·ªÉ:** K√≠ch th∆∞·ªõc, ƒë·ªô cao, kho·∫£ng c√°ch thay v√¨ n√≥i chung chung
        - **Xen k√Ω hi·ªáu nh·∫•n m·∫°nh:** ‚Üí, in hoa t·ª´ kh√≥a: TUY·ªÜT ƒê·ªêI, NH·ªö, SAI L√Ä...
        
        ### **üé≠ GI·ªåNG VƒÇN & TH·∫¶N TH√ÅI:**
        - **Th√¢n thi·ªán ‚Äì g·∫ßn g≈©i:** Nh∆∞ ƒëang n√≥i chuy·ªán tr·ª±c ti·∫øp, d√πng "b√°c / anh / nh√† m√¨nh / gi√∫p em..."
        - **Pha tr·ªôn ng√¥n ng·ªØ:** K·ªπ thu·∫≠t (s·ªë li·ªáu, quy chu·∫©n) + ƒë·ªùi th∆∞·ªùng ("t·ªën ti·ªÅn", "d·ªÖ h·ªèng", "ƒë·ª´ng ham...")
        - **C√≥ c·∫£m x√∫c:** C·∫£nh b√°o r·ªßi ro n·∫øu sai + an t√¢m khi l√†m ƒë√∫ng
        - **Th·∫ßn th√°i v·ª´a ng∆∞·ªùi th·∫≠t vi·ªác th·∫≠t:** K·ªÉ case study + chuy√™n gia
        
        ### **üìù K·ª∏ THU·∫¨T VI·∫æT & TRI·ªÇN KHAI √ù:**
        - **M·ªü ƒë·∫ßu √Ω:** N√™u v·∫•n ƒë·ªÅ + r·ªßi ro khi l√†m sai
        - **Tri·ªÉn khai:** ƒê∆∞a v√≠ d·ª• th·ª±c t·∫ø (nh√† anh A, nhi·ªÅu gia ƒë√¨nh m·∫Øc l·ªói n√†y...)
        - **K·∫øt th√∫c √Ω:** Khuy·∫øn ngh·ªã h√†nh ƒë·ªông ng·∫Øn g·ªçn, ch·∫Øc n·ªãch
        - **Lu√¥n c√≥ s·ª± ƒë·ªëi l·∫≠p:** L√†m sai ‚Üí h·∫≠u qu·∫£ / l√†m ƒë√∫ng ‚Üí l·ª£i √≠ch
        
        ### **üéØ T√ÇM L√ù NG∆Ø·ªúI ƒê·ªåC & M·ª§C TI√äU N·ªòI DUNG:**
        - **ƒê·ªôc gi·∫£ ch√≠nh l√† gia ch·ªß:** C·∫ßn d·ªÖ hi·ªÉu, tr·ª±c quan, tr√°nh thu·∫≠t ng·ªØ qu√° chuy√™n ng√†nh
        - **N·ªôi dung ph·∫£i khi·∫øn ng∆∞·ªùi ƒë·ªçc:** Th·∫•y tin t∆∞·ªüng, d·ªÖ √°p d·ª•ng, ti·∫øt ki·ªám chi ph√≠, tr√°nh r·ªßi ro
        - **K·∫øt th√∫c to√†n b√†i:** B·∫±ng 1 c√¢u kh·∫≥ng ƒë·ªãnh m·∫°nh ‚Üí t·∫°o c·∫£m gi√°c y√™n t√¢m: "Ch·ªâ c·∫ßn nh·ªõ nh·ªØng ƒëi·ªÉm n√†y l√† ƒë·ªß b·ªÅn ‚Äì ƒë·∫πp ‚Äì an to√†n."

        ### **‚è∞ TIMELINE B·∫ÆT BU·ªòC GI·ªÆ NGUY√äN:**
        - **TIMELINE PH·∫¢I GI·ªÆ NGUY√äN 100%:** N·∫øu g·ªëc c√≥ "(Gi√¢y 1-3) xin ch√†o" th√¨ m·ªõi ph·∫£i c√≥ "(Gi√¢y 1-3) [n·ªôi dung m·ªõi]"
        - **KH√îNG THAY ƒê·ªîI TH·ªúI GIAN:** Gi·ªØ nguy√™n s·ªë gi√¢y, kh√¥ng th√™m/b·ªõt
        - **KH√îNG THAY ƒê·ªîI C·∫§U TR√öC:** Gi·ªØ nguy√™n format "(Gi√¢y X-Y) n·ªôi dung"
        - **CH·ªà VI·∫æT L·∫†I N·ªòI DUNG:** Thay ƒë·ªïi n·ªôi dung b√™n trong timeline, kh√¥ng ƒë·ª•ng ƒë·∫øn timeline
        - **KH√îNG S·ª¨ D·ª§NG D·∫§U () "":** Ch·ªâ d√πng c√°c d·∫•u c√¢u b√¨nh th∆∞·ªùng, kh√¥ng d√πng d·∫•u ngo·∫∑c ƒë∆°n, ngo·∫∑c k√©p
        - **B·ªé D·∫§U ...:** Vi·∫øt li·ªÅn m·∫°ch, kh√¥ng d√πng d·∫•u ba ch·∫•m
        - **CHIA √ù R√ï R√ÄNG:** N·ªôi dung vi·∫øt l·∫°i chia √Ω r√µ r√†ng h∆°n k√®m icon
        - **ICON üëâ K·∫æT H·ª¢P N·ªòI DUNG:** Icon üëâ ph·∫£i k·∫øt h·ª£p tr·ª±c ti·∫øp v·ªõi n·ªôi dung, kh√¥ng ph·∫£i ch·ªâ l√† ƒë·ªÅ m·ª•c ri√™ng bi·ªát
        - **V√ç D·ª§ ƒê√öNG:** "üëâ B√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng ƒë·ªÉ treo qu·∫ßn √°o..."
        - **V√ç D·ª§ SAI:** "üëâ B√™n ph·∫£i\nB√™n ph·∫£i t·ªß, m√¨nh l√†m hai t·∫ßng..." (b·ªã th·ª´a)
        - **T√ÅCH BI·ªÜT N·ªòI DUNG:** CAPTION G·ª¢I √ù V√Ä CTA KH√îNG ƒê∆Ø·ª¢C XU·∫§T HI·ªÜN TRONG N·ªòI DUNG CH√çNH
        - **CH·ªà N·ªòI DUNG TIMELINE:** C·ªôt Text c·∫£i ti·∫øn ch·ªâ ch·ª©a n·ªôi dung ch√≠nh v·ªõi timeline, kh√¥ng c√≥ caption, CTA

        ### **üìù C√ÅCH VI·∫æT HAY H∆†N:**
                    # - Chuy·ªÉn ƒëo·∫°n b·∫±ng c√°c t·ª´ n·ªëi t·ª± nhi√™n: "C√≤n n·ªØa n√® b√°c", "ƒê·∫∑c bi·ªát l√†...", "Quan tr·ªçng nh·∫•t l√†...", "Em ch·ªâ th√™m cho b√°c..." - ƒê√É COMMENT
        - D√πng t·ª´ sinh ƒë·ªông thay t·ª´ kh√¥ khan: "m·∫πo hay ho" thay "ph∆∞∆°ng ph√°p", "c·ª±c k·ª≥ hi·ªáu qu·∫£" thay "hi·ªáu qu·∫£"
        - Chia nh·ªè t·ª´ng √Ω r√µ r√†ng, t·∫°o ƒëi·ªÉm nh·∫•n b·∫±ng t·ª´ c·∫£m x√∫c
        - Tr√°nh gi·ªçng k·ªÉ chuy·ªán: vi·∫øt nh∆∞ ƒëang t∆∞ v·∫•n tr·ª±c ti·∫øp
        - T·∫°o s·ª± t·ª± tin: "ch·∫Øc ch·∫Øn", "ƒë·∫£m b·∫£o", "100%" thay v√¨ "c√≥ th·ªÉ", "ch·∫Øc l√†"
        
        ### **üí° V√ç D·ª§ C√ÅCH VI·∫æT M·ªöI:**
        - **Thay v√¨:** "Ph∆∞∆°ng ph√°p n√†y hi·ªáu qu·∫£" ‚Üí **Vi·∫øt:** "üëâ M·∫πo n√†y c·ª±c k·ª≥ hi·ªáu qu·∫£ b√°c ·∫°!"
        - **Thay v√¨:** "C√≥ th·ªÉ √°p d·ª•ng" ‚Üí **Vi·∫øt:** "üí° B√°c √°p d·ª•ng ch·∫Øc ch·∫Øn th√†nh c√¥ng!"
        - **Thay v√¨:** "K·∫øt qu·∫£ t·ªët" ‚Üí **Vi·∫øt:** "üîπ K·∫øt qu·∫£ SI√äU TUY·ªÜT lu√¥n!"
        - **Thay v√¨:** "Nhi·ªÅu ng∆∞·ªùi l√†m sai" ‚Üí **Vi·∫øt:** "‚ùå Nhi·ªÅu gia ƒë√¨nh m·∫Øc l·ªói n√†y ‚Üí t·ªën ti·ªÅn oan!"
        - **Thay v√¨:** "L√†m ƒë√∫ng s·∫Ω t·ªët" ‚Üí **Vi·∫øt:** "‚úÖ L√†m ƒë√∫ng ‚Üí ti·∫øt ki·ªám 50% chi ph√≠!"
        
        ### **üî• TR√ÅNH VƒÇN NH·∫†T NH·∫ºO:**
        - ‚ùå "ƒêi·ªÅu n√†y t·ªët" ‚Üí ‚úÖ "üëâ C√°i n√†y tuy·ªát v·ªùi lu√¥n b√°c ·∫°!"
        - ‚ùå "C√≥ th·ªÉ √°p d·ª•ng" ‚Üí ‚úÖ "üí° B√°c √°p d·ª•ng ch·∫Øc ch·∫Øn hi·ªáu qu·∫£!"
        - ‚ùå "Ph∆∞∆°ng ph√°p n√†y" ‚Üí ‚úÖ "üîπ M·∫πo hay ho n√†y"
        - ‚ùå "K·∫øt qu·∫£ kh√° t·ªët" ‚Üí ‚úÖ "üéØ K·∫øt qu·∫£ SI√äU TUY·ªÜT v·ªùi!"
        - ‚ùå "Nhi·ªÅu ng∆∞·ªùi l√†m sai" ‚Üí ‚úÖ "‚ùå Nhi·ªÅu gia ƒë√¨nh m·∫Øc l·ªói n√†y ‚Üí t·ªën ti·ªÅn oan!"
        - ‚ùå "L√†m ƒë√∫ng s·∫Ω t·ªët" ‚Üí ‚úÖ "‚úÖ L√†m ƒë√∫ng ‚Üí ti·∫øt ki·ªám chi ph√≠!"

        ## üìã **H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:**

        1. **ƒê·ªçc text g·ªëc t·ª´ video/audio** (c√≥ timeline)
        2. **Ph√¢n t√≠ch timeline:** X√°c ƒë·ªãnh c√°c ƒëo·∫°n th·ªùi gian v√† n·ªôi dung t∆∞∆°ng ·ª©ng
        3. **Vi·∫øt l·∫°i theo timeline:** M·ªói ƒëo·∫°n th·ªùi gian ph·∫£i c√≥ n·ªôi dung m·ªõi t∆∞∆°ng ƒë∆∞∆°ng
        4. **√Åp d·ª•ng b·ªë c·ª•c:** M·ªû ƒê·∫¶U - TH√ÇN - K·∫æT
        5. **Ki·ªÉm tra:** ƒê·∫£m b·∫£o timeline ch√≠nh x√°c v√† √Ω nghƒ©a t∆∞∆°ng ƒë∆∞∆°ng

        ## ‚ö†Ô∏è **L∆ØU √ù QUAN TR·ªåNG:**

        - **KH√îNG t·ª± s√°ng t·∫°o qu√° ƒë√†:** Ch·ªâ vi·∫øt l·∫°i theo c√°ch t·ª± nhi√™n hay h∆°n
        - **B·∫ÆT BU·ªòC gi·ªØ timeline:** Timeline ph·∫£i gi·ªëng h·ªát g·ªëc (s·ªë gi√¢y v√† format)
        - **CH·ªà VI·∫æT L·∫†I N·ªòI DUNG:** Thay ƒë·ªïi n·ªôi dung b√™n trong timeline th√†nh sinh ƒë·ªông h∆°n
        - **KI·ªÇM TRA:** ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng timeline v√† th·ªùi gian gi·ªëng h·ªát g·ªëc
        - **SINH ƒê·ªòNG H∆†N:** D√πng t·ª´ c√≥ c·∫£m x√∫c, t·∫°o s·ª± cu·ªën h√∫t thay v√¨ nh·∫°t nh·∫Ωo
        - **S√ÅNG T·∫†O HO√ÄN TO√ÄN:** Vi·∫øt m·ªõi ho√†n to√†n, kh√¥ng copy b·∫£n g·ªëc, ph·∫£i hay h∆°n b·∫£n g·ªëc
        - **TH√äM GI√Å TR·ªä M·ªöI:** B·ªï sung th√¥ng tin h·ªØu √≠ch, m·∫πo hay, kinh nghi·ªám th·ª±c t·∫ø
        - **T·ª™ NG·ªÆ M·ªöI:** D√πng c√°ch di·ªÖn ƒë·∫°t m·ªõi, kh√¥ng l·∫∑p l·∫°i b·∫£n g·ªëc
        - **TUY·ªÜT ƒê·ªêI KH√îNG VI·∫æT Y H·ªÜT:** N·∫øu vi·∫øt y h·ªát b·∫£n g·ªëc th√¨ kh√¥ng c√≥ gi√° tr·ªã
        - **T·ª∞ NHI√äN H∆†N:** Vi·∫øt nh∆∞ ƒëang chia s·∫ª th·ª±c t·∫ø, kh√¥ng qu√° ti√™u chu·∫©n, c√¢u d·ªÖ hi·ªÉu
        - **S·ª¨ D·ª§NG ICON ƒê·ªÇ NH·∫§N M·∫†NH:** üëâ, üîπ, üí°, ‚ùå, ‚úÖ, üéØ ƒë·ªÉ chia √Ω r√µ r√†ng, d·ªÖ l∆∞·ªõt

        ## üéØ **H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU D·∫™N CH√çNH X√ÅC:**

        ### **üìã QUY TR√åNH T·∫†O C√ÇU D·∫™N:**
        1. **ƒê·ªåC TO√ÄN B·ªò N·ªòI DUNG:** ƒê·ªçc k·ªπ t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi ƒë·ªÉ hi·ªÉu ch·ªß ƒë·ªÅ ch√≠nh
        2. **X√ÅC ƒê·ªäNH CH·ª¶ ƒê·ªÄ CH√çNH:** T√¨m ra v·∫•n ƒë·ªÅ/√Ω t∆∞·ªüng ch√≠nh m√† video gi·∫£i quy·∫øt
        3. **T·∫†O C√ÇU D·∫™N PH√ô H·ª¢P:** Vi·∫øt c√¢u d·∫´n li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ch·ªß ƒë·ªÅ ƒë√≥
        4. **KI·ªÇM TRA T√çNH LI√äN QUAN:** ƒê·∫£m b·∫£o c√¢u d·∫´n kh√¥ng l·∫°c ƒë·ªÅ

        ### **‚úÖ V√ç D·ª§ C√ÇU D·∫™N ƒê√öNG:**
        - **Video v·ªÅ thi·∫øt k·∫ø nh√†:** "Nhi·ªÅu b√°c c·ª© nghƒ© thi·∫øt k·∫ø nh√† l√† chuy·ªán c·ªßa ki·∫øn tr√∫c s∆∞..."
        - **Video v·ªÅ n·∫•u ƒÉn:** "Nhi·ªÅu b√°c c·ª© nghƒ© n·∫•u ƒÉn ngon l√† chuy·ªán c·ªßa ƒë·∫ßu b·∫øp..."
        - **Video v·ªÅ t√†i ch√≠nh:** "Nhi·ªÅu b√°c c·ª© nghƒ© ƒë·∫ßu t∆∞ l√† chuy·ªán c·ªßa chuy√™n gia..."
        - **Video v·ªÅ s·ª©c kh·ªèe:** "Nhi·ªÅu b√°c c·ª© nghƒ© t·∫≠p th·ªÉ d·ª•c l√† chuy·ªán c·ªßa v·∫≠n ƒë·ªông vi√™n..."
        - **Video v·ªÅ khu v·ª±c l·ªëi v√†o:** "Nhi·ªÅu b√°c c·ª© nghƒ© khu v·ª±c l·ªëi v√†o nh√† ch·ªâ c·∫ßn ƒë∆°n gi·∫£n..."
        - **Video v·ªÅ t·ªß gi√†y:** "Nhi·ªÅu b√°c c·ª© nghƒ© t·ªß gi√†y ch·ªâ c·∫ßn c√≥ ch·ªó ƒë·ªÉ gi√†y l√† ƒë·ªß..."

        ### **‚ùå V√ç D·ª§ C√ÇU D·∫™N SAI:**
        - **Video v·ªÅ qu·∫ßn √°o:** "Nhi·ªÅu b√°c c·ª© nghƒ© gi√†y l√† chuy·ªán c·ªßa th·ª£..." (SAI - kh√¥ng li√™n quan)
        - **Video v·ªÅ nh√† c·ª≠a:** "ƒê·ª´ng b·ªè l·ª° qu·∫ßn quan tr·ªçng n√†y..." (SAI - kh√¥ng li√™n quan)
        - **Video v·ªÅ t·ªß qu·∫ßn √°o:** "Alo alo, xin ch√†o c√°c b√°c!" (SAI - c·ª•t nghƒ©a, kh√¥ng c√≥ √Ω nghƒ©a)
        - **Video v·ªÅ ph√≤ng kh√°ch:** "Yo c√°c b√°c! Ph√≤ng kh√°ch nh√† b√°c n√†o..." (SAI - t·ª´ su·ªìng s√£)
        - **Video v·ªÅ n·∫•u ƒÉn:** "Alo alo! C√°c b√°c ∆°i, h√¥m nay em s·∫Ω ph√° ƒë·∫£o..." (SAI - t·ª´ kh√¥ng chuy√™n nghi·ªáp)
        - **Video v·ªÅ khu v·ª±c l·ªëi v√†o:** "ƒê·ª´ng b·ªè l·ª° ti·ªán quan tr·ªçng n√†y..." (SAI - kh√¥ng r√µ r√†ng, kh√¥ng c√≥ √Ω nghƒ©a)
        - **Video v·ªÅ thi·∫øt k·∫ø nh√†:** "Xem ti·∫øp ƒë·ªÉ em ch·ªâ b√°c..." (SAI - c·ª•t nghƒ©a, kh√¥ng t·∫°o s·ª± t√≤ m√≤)

        ### **üîç C√ÅCH KI·ªÇM TRA:**
        - C√¢u d·∫´n c√≥ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ch·ªß ƒë·ªÅ ch√≠nh c·ªßa video kh√¥ng?
        - C√≥ t·ª´ kh√≥a ch√≠nh xu·∫•t hi·ªán trong n·ªôi dung video kh√¥ng?
        - C√≥ t·∫°o ƒë∆∞·ª£c s·ª± t√≤ m√≤ v·ªÅ v·∫•n ƒë·ªÅ m√† video s·∫Ω gi·∫£i quy·∫øt kh√¥ng?
        - C√¢u d·∫´n c√≥ √Ω nghƒ©a r√µ r√†ng, kh√¥ng c·ª•t nghƒ©a kh√¥ng?
        - C√≥ s·ª≠ d·ª•ng t·ª´ ng·ªØ chuy√™n nghi·ªáp, kh√¥ng su·ªìng s√£ kh√¥ng?

        === C·∫§U TR√öC K·∫æT QU·∫¢ Y√äU C·∫¶U ===
        
        G·ª¢I √ù 5 TI√äU ƒê·ªÄ 
        1. [Ti√™u ƒë·ªÅ ng·∫Øn g·ªçn, b·∫Øt tai, d√πng t·ª´ ng·ªØ nh√¢n h√≥a ƒë·ªÉ t·∫°o t√≤ m√≤, ph·∫£i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn n·ªôi dung ƒë√£ vi·∫øt]
2. [Ti√™u ƒë·ªÅ g·ª£i t√≤ m√≤, t·∫°o c·∫£m gi√°c "ph·∫£i xem ngay", d√πng t·ª´ ng·ªØ nh√¢n h√≥a, d·ª±a tr√™n √Ω ch√≠nh c·ªßa n·ªôi dung]
3. [Ti√™u ƒë·ªÅ b·∫Øt trend, viral, d√πng t·ª´ ng·ªØ nh√¢n h√≥a, nh∆∞ng ph·∫£i ƒë√∫ng v·ªõi ch·ªß ƒë·ªÅ n·ªôi dung]
4. [Ti√™u ƒë·ªÅ th·ª±c t·∫ø, gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ c·ª• th·ªÉ t·ª´ n·ªôi dung, d√πng t·ª´ ng·ªØ nh√¢n h√≥a]
5. [Ti√™u ƒë·ªÅ c·∫£m x√∫c, t·∫°o c·∫£m x√∫c m·∫°nh, d√πng t·ª´ ng·ªØ nh√¢n h√≥a, d·ª±a tr√™n l·ª£i √≠ch t·ª´ n·ªôi dung]
        
        N·ªòI DUNG CH√çNH (GI·ªÆ NGUY√äN TIMELINE):
        [N·ªôi dung v·ªõi timeline ƒë√£ vi·∫øt l·∫°i - KH√îNG C√ì C√ÇU D·∫™N, B·∫ÆT ƒê·∫¶U TR·ª∞C TI·∫æP V·ªöI TIMELINE]
        **L∆ØU √ù QUAN TR·ªåNG:** 
        - C√¢u d·∫´n ƒë·∫ßu ti√™n PH·∫¢I li√™n quan tr·ª±c ti·∫øp ƒë·∫øn ch·ªß ƒë·ªÅ ch√≠nh c·ªßa video, kh√¥ng ƒë∆∞·ª£c l·∫°c ƒë·ªÅ
        - TUY·ªÜT ƒê·ªêI KH√îNG D√ôNG: "Alo alo", "Yo", "qu·∫©y", "ph√° ƒë·∫£o" - nh·ªØng t·ª´ su·ªìng s√£
        - PH·∫¢I D√ôNG: C√¢u d·∫´n c√≥ √Ω nghƒ©a r√µ r√†ng, t·∫°o s·ª± t√≤ m√≤ v·ªÅ gi·∫£i ph√°p video s·∫Ω cung c·∫•p
        - C√¢u d·∫´n ph·∫£i d·∫´n d·∫Øt t·ª± nhi√™n v√†o n·ªôi dung ch√≠nh, kh√¥ng ƒë∆∞·ª£c c·ª•t nghƒ©a
        - **S·ª¨ D·ª§NG ICON V√Ä FORMAT M·ªöI:** üëâ, üîπ, üí°, ‚ùå, ‚úÖ, üéØ ƒë·ªÉ chia √Ω r√µ r√†ng
        - **C√ì C√îNG TH·ª®C/CON S·ªê C·ª§ TH·ªÇ:** K√≠ch th∆∞·ªõc, ƒë·ªô cao, kho·∫£ng c√°ch thay v√¨ n√≥i chung chung
        - **XEN K√ù HI·ªÜU NH·∫§N M·∫†NH:** ‚Üí, in hoa t·ª´ kh√≥a: TUY·ªÜT ƒê·ªêI, NH·ªö, SAI L√Ä...
        - **K·∫æT TH√öC M·∫†NH M·∫º:** B·∫±ng 1 c√¢u kh·∫≥ng ƒë·ªãnh t·∫°o c·∫£m gi√°c y√™n t√¢m: "Ch·ªâ c·∫ßn nh·ªõ nh·ªØng ƒëi·ªÉm n√†y l√† ƒë·ªß b·ªÅn ‚Äì ƒë·∫πp ‚Äì an to√†n."
        
        G·ª¢I √ù 3 CAPTION TIKTOK :
        1. [Caption v·ªõi hashtag ph√π h·ª£p, g·ª£i c·∫£m x√∫c m·∫°nh, t·∫°o s·ª± t√≤ m√≤ v·ªÅ n·ªôi dung]
        2. [Caption b·∫Øt trend, viral, nh∆∞ng ph·∫£i li√™n quan v√† thu h√∫t ng∆∞·ªùi xem n·ªôi dung n√†y]
        3. [Caption t∆∞∆°ng t√°c cao, khuy·∫øn kh√≠ch comment, share, d·ª±a tr√™n gi√° tr·ªã t·ª´ n·ªôi dung]
        
        CALL TO ACTION (CTA) - VI·∫æT M·ªöI D·ª∞A TR√äN M·∫™U:
        [Vi·∫øt 1 c√¢u CTA m·ªõi ho√†n to√†n, d·ª±a tr√™n phong c√°ch v√† √Ω t∆∞·ªüng t·ª´ c√°c m·∫´u CTA trong prompt template, nh∆∞ng KH√îNG copy nguy√™n vƒÉn, ph·∫£i s√°ng t·∫°o m·ªõi ph√π h·ª£p v·ªõi n·ªôi dung n√†y]
        
        **B√¢y gi·ªù h√£y vi·∫øt l·∫°i n·ªôi dung text g·ªëc theo c·∫•u tr√∫c tr√™n, ƒë·∫£m b·∫£o gi·ªØ nguy√™n timeline v√† sinh ƒë·ªông h∆°n.**
        """
    
    # def text_to_speech(self, text_path: str, output_name: str) -> str:
    #     """
    #     Chuy·ªÉn ƒë·ªïi text ƒë√£ vi·∫øt l·∫°i th√†nh speech b·∫±ng Deepgram TTS API - ƒê√É COMMENT
    #     
    #     Ch·ª©c nƒÉng:
    #     - ƒê·ªçc file text ƒë√£ vi·∫øt l·∫°i (rewritten text t·ª´ Gemini)
    #     - Lo·∫°i b·ªè ph·∫ßn timeline v√† ch·ªâ gi·ªØ n·ªôi dung ch√≠nh c·ªßa text ƒë√£ vi·∫øt l·∫°i
    #     - Chuy·ªÉn ƒë·ªïi th√†nh gi·ªçng n√≥i ti·∫øng Vi·ªát
    #     - L∆∞u file audio MP3
    #     
    #     Args:
    #         text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ vi·∫øt l·∫°i (rewritten text)
    #         output_name: T√™n file output (kh√¥ng c√≥ extension)
    #         
    #     Returns:
    #         ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio ƒë√£ t·∫°o
    #     """
    #     try:
    #         # T·∫°o t√™n file output cho audio
    #         base_name = os.path.splitext(output_name)[0]
    #         output_path = os.path.join(self.temp_dir, f"{base_name}_tts.mp3")
    #         
    #         logger.info(f"üé§ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi text th√†nh speech: {os.path.basename(text_path)}")
    #         
    #         # ƒê·ªçc text t·ª´ file
    #         with open(text_path, 'r', encoding='utf-8') as f:
    #             text_content = f.read()
    #         
    #         # Ki·ªÉm tra text c√≥ n·ªôi dung kh√¥ng
    #         if not text_content.strip():
    #             logger.warning("‚ö†Ô∏è Text r·ªóng, kh√¥ng th·ªÉ chuy·ªÉn th√†nh speech")
    #             raise Exception("Text r·ªóng")
    #         
    #         # Ki·ªÉm tra text c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng
    #         if len(text_content) > 5000:
    #             logger.warning("‚ö†Ô∏è Text qu√° d√†i, c·∫Øt b·ªõt ƒë·ªÉ tr√°nh l·ªói API")
    #             text_content = text_content[:5000]
    #         
    #         # X·ª≠ l√Ω text: Lo·∫°i b·ªè timeline v√† ch·ªâ gi·ªØ n·ªôi dung ch√≠nh c·ªßa text ƒë√£ vi·∫øt l·∫°i
    #         cleaned_text = self._extract_main_content(text_content)
    #         logger.info(f"üßπ ƒê√£ l√†m s·∫°ch text ƒë√£ vi·∫øt l·∫°i, lo·∫°i b·ªè timeline")
    #         logger.info(f"üìù Text g·ªëc: {len(text_content)} k√Ω t·ª±")
    #         logger.info(f"üìù Text ƒë√£ l√†m s·∫°ch: {len(cleaned_text)} k√Ω t·ª±")
    #         logger.info(f"üìÑ Text ƒë√£ l√†m s·∫°ch (100 k√Ω t·ª± ƒë·∫ßu): {cleaned_text[:100]}...")
    #         logger.info(f"üìÑ Text ƒë√£ l√†m s·∫°ch (200 k√Ω t·ª± ƒë·∫ßu): {cleaned_text[:200]}...")
    #         
    #         # Ki·ªÉm tra v√† l√†m s·∫°ch text cu·ªëi c√πng
    #         if len(cleaned_text) > 4000:
    #             logger.warning("‚ö†Ô∏è Text ƒë√£ l√†m s·∫°ch v·∫´n qu√° d√†i, c·∫Øt b·ªõt")
    #             cleaned_text = cleaned_text[:4000]
    #         
    #         # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát c√≥ th·ªÉ g√¢y l·ªói
    #         cleaned_text = re.sub(r'[^\w\s\.,!?;:()\-\'\"]', '', cleaned_text)
    #         cleaned_text = cleaned_text.strip()
    #         
    #         logger.info(f"üìù Text cu·ªëi c√πng: {len(cleaned_text)} k√Ω t·ª±")
    #         logger.info(f"üìÑ Text cu·ªëi c√πng (100 k√Ω t·ª± ƒë·∫ßu): {cleaned_text[:100]}...")
    #         
    #         # Ki·ªÉm tra text cu·ªëi c√πng c√≥ n·ªôi dung kh√¥ng
    #         if not cleaned_text or len(cleaned_text.strip()) < 10:
    #             logger.error("‚ùå Text cu·ªëi c√πng qu√° ng·∫Øn ho·∫∑c r·ªóng")
    #             raise Exception("Text cu·ªëi c√πng kh√¥ng ƒë·ªß n·ªôi dung ƒë·ªÉ chuy·ªÉn th√†nh speech")
    #         
    #         # Chu·∫©n b·ªã request ƒë·∫øn Deepgram TTS API
    #         url = "https://api.deepgram.com/v1/speak"
    #         headers = {
    #             "Authorization": f"Token {self.deepgram_tts_api_key}",
    #             "Content-Type": "application/json"
    #         }
    #         
    #         # Th√™m query parameters cho model v√† voice
    #         params = {
    #             "model": "aura-asteria-en",
    #             "voice": "asteria"
    #         }
    #         
    #         # Tham s·ªë cho TTS (s·ª≠ d·ª•ng voice ti·∫øng Vi·ªát)
    #         data = {
    #             "text": cleaned_text
    #         }
    #         
    #         # Ki·ªÉm tra data tr∆∞·ªõc khi g·ª≠i
    #         logger.info(f"üìã Data s·∫Ω g·ª≠i: {data}")
    #         logger.info(f"üìã JSON data: {json.dumps(data, ensure_ascii=False)}")
    #         
    #         # G·ª≠i request ƒë·∫øn Deepgram TTS API
    #         logger.info("üîÑ ƒêang g·ª≠i request ƒë·∫øn Deepgram TTS API...")
    #         logger.info(f"üìù Text length: {len(cleaned_text)} k√Ω t·ª±")
    #         response = requests.post(url, headers=headers, params=params, json=data, timeout=120)
    #         
    #         # Ki·ªÉm tra response
    #         if response.status_code == 200:
    #             # L∆∞u audio v√†o file
    #             with open(output_path, 'wb') as f:
    #                 f.write(response.content)
    #             
    #             # Ki·ªÉm tra file ƒë√£ t·∫°o
    #             if os.path.exists(output_path):
    #                 file_size = os.path.getsize(output_path)
    #                 logger.info(f"‚úÖ Chuy·ªÉn ƒë·ªïi text th√†nh speech th√†nh c√¥ng!")
    #                 logger.info(f"üìÅ File audio: {output_path}")
    #                 logger.info(f"üìä K√≠ch th∆∞·ªõc: {file_size:,} bytes")
    #                 logger.info(f"üìù Text length: {len(cleaned_text)} k√Ω t·ª±")
    #                 
    #                 return output_path
    #             else:
    #                 raise Exception("Kh√¥ng th·ªÉ t·∫°o file audio")
    #         else:
    #             # N·∫øu API tr·∫£ v·ªÅ l·ªói
    #             error_msg = f"Deepgram TTS API l·ªói: {response.status_code} - {response.text}"
    #             logger.error(error_msg)
    #             raise Exception(error_msg)
    #             
    #     except Exception as e:
    #         logger.error(f"‚ùå L·ªói chuy·ªÉn ƒë·ªïi text th√†nh speech: {str(e)}")
    #         raise
    
    def create_text_without_timeline(self, text_path: str, output_name: str) -> str:
        """
        T·∫°o vƒÉn b·∫£n kh√¥ng c√≥ timeline t·ª´ text g·ªëc ho·∫∑c text ƒë√£ vi·∫øt l·∫°i
        Gi·ªØ nguy√™n format nh∆∞ text c·∫£i ti·∫øn: c√¢u d·∫´n, icon üëâ, format 1 c√¢u c√°ch 1 h√†ng
        
        Args:
            text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text (c√≥ th·ªÉ c√≥ timeline)
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text kh√¥ng c√≥ timeline
        """
        try:
            # T·∫°o t√™n file output cho text kh√¥ng c√≥ timeline
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_no_timeline.txt")
            
            logger.info(f"üìù ƒêang t·∫°o text kh√¥ng c√≥ timeline: {os.path.basename(text_path)}")
            
            # ƒê·ªçc text t·ª´ file
            with open(text_path, 'r', encoding='utf-8') as f:
                original_text = f.read()
            
            # Tr√≠ch xu·∫•t n·ªôi dung ch√≠nh c√≥ timeline
            main_content = self._extract_main_content_with_timeline(original_text)
            
            # B·ªè timeline nh∆∞ng gi·ªØ nguy√™n format: c√¢u d·∫´n + icon üëâ + format 1 c√¢u c√°ch 1 h√†ng
            text_no_timeline = self._remove_timeline_keep_format(main_content)
            
            # L∆∞u text kh√¥ng c√≥ timeline v√†o file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(text_no_timeline)
            
            logger.info(f"‚úÖ T·∫°o text kh√¥ng timeline th√†nh c√¥ng!")
            logger.info(f"üìÅ File: {output_path}")
            logger.info(f"üìù ƒê·ªô d√†i text: {len(text_no_timeline)} k√Ω t·ª±")
            logger.info(f"üìÑ N·ªôi dung: {text_no_timeline[:200]}...")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o text kh√¥ng timeline: {str(e)}")
            raise

    def create_main_content_only(self, text_path: str, output_name: str) -> str:
        """
        T·∫°o file ch·ªâ ch·ª©a n·ªôi dung ch√≠nh c√≥ timeline (cho c·ªôt Text c·∫£i ti·∫øn)
        
        Args:
            text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ vi·∫øt l·∫°i
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ch·ªâ c√≥ n·ªôi dung ch√≠nh v·ªõi timeline
        """
        try:
            # T·∫°o t√™n file output cho n·ªôi dung ch√≠nh
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_main_content.txt")
            
            logger.info(f"üìù ƒêang t·∫°o n·ªôi dung ch√≠nh c√≥ timeline: {os.path.basename(text_path)}")
            
            # ƒê·ªçc text t·ª´ file
            with open(text_path, 'r', encoding='utf-8') as f:
                original_text = f.read()
            
            # Tr√≠ch xu·∫•t ch·ªâ n·ªôi dung ch√≠nh c√≥ timeline
            main_content = self._extract_main_content_with_timeline(original_text)
            
            # B·ªçc theo format y√™u c·∫ßu: C√¢u v√†o ƒë·ªÅ + N·ªôi dung ch√≠nh
            lead_in = self._generate_lead_in_hook(self._format_main_content_only(main_content))
            formatted = []
            # formatted.append("C√ÇU V√ÄO ƒê·ªÄ ->")  # ƒê√É COMMENT - B·ªé C√ÇU V√ÄO ƒê·ªÄ
            # formatted.append(lead_in if lead_in else "...")  # ƒê√É COMMENT - B·ªé C√ÇU V√ÄO ƒê·ªÄ
            formatted.append("N·ªòI DUNG CH√çNH ->")
            formatted.append(main_content.strip())

            # L∆∞u n·ªôi dung ch√≠nh v√†o file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(formatted).strip())
            
            logger.info(f"‚úÖ T·∫°o n·ªôi dung ch√≠nh th√†nh c√¥ng!")
            logger.info(f"üìÅ File: {output_path}")
            logger.info(f"üìù ƒê·ªô d√†i: {len(main_content)} k√Ω t·ª±")
            logger.info(f"üìÑ N·ªôi dung: {main_content[:200]}...")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o n·ªôi dung ch√≠nh: {str(e)}")
            raise

    def create_suggestions_content(self, text_path: str, output_name: str) -> str:
        """
        T·∫°o n·ªôi dung g·ª£i √Ω (ti√™u ƒë·ªÅ, captions, CTA) t·ª´ text ƒë√£ vi·∫øt l·∫°i
        
        Args:
            text_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text ƒë√£ vi·∫øt l·∫°i
            output_name: T√™n file output (kh√¥ng c√≥ extension)
            
        Returns:
            ƒê∆∞·ªùng d·∫´n ƒë·∫øn file g·ª£i √Ω
        """
        try:
            # T·∫°o t√™n file output cho g·ª£i √Ω
            base_name = os.path.splitext(output_name)[0]
            output_path = os.path.join(self.temp_dir, f"{base_name}_suggestions.txt")
            
            logger.info(f"üí° ƒêang t·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA: {os.path.basename(text_path)}")
            
            # ƒê·ªçc text t·ª´ file
            with open(text_path, 'r', encoding='utf-8') as f:
                original_text = f.read()
            
            # T√°ch g·ª£i √Ω t·ª´ text ƒë√£ vi·∫øt l·∫°i
            suggestions_content = self._format_suggestions_content(original_text)
            
            # L∆∞u g·ª£i √Ω v√†o file
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(suggestions_content)
            
            logger.info(f"‚úÖ T·∫°o g·ª£i √Ω th√†nh c√¥ng!")
            logger.info(f"üìÅ File: {output_path}")
            logger.info(f"üìù ƒê·ªô d√†i: {len(suggestions_content)} k√Ω t·ª±")
            logger.info(f"üìÑ N·ªôi dung: {suggestions_content[:200]}...")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o g·ª£i √Ω: {str(e)}")
            raise

    def _extract_main_content(self, text: str) -> str:
        """
        Tr√≠ch xu·∫•t n·ªôi dung ch√≠nh t·ª´ text ƒë√£ vi·∫øt l·∫°i, lo·∫°i b·ªè timeline
        
        Args:
            text: Text ƒë√£ vi·∫øt l·∫°i (rewritten text) c√≥ th·ªÉ ch·ª©a timeline
            
        Returns:
            Text ƒë√£ l√†m s·∫°ch, ch·ªâ ch·ª©a n·ªôi dung ch√≠nh c·ªßa text ƒë√£ vi·∫øt l·∫°i
        """
        try:
            logger.info(f"üîç B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t n·ªôi dung ch√≠nh t·ª´ text ƒë√£ vi·∫øt l·∫°i...")
            logger.info(f"üìÑ Text g·ªëc (200 k√Ω t·ª± ƒë·∫ßu): {text[:200]}...")
            
            # QUAN TR·ªåNG: Text ƒë√£ vi·∫øt l·∫°i th∆∞·ªùng kh√¥ng c√≥ ph·∫ßn "TRANSCRIPT G·ªêC"
            # Ch·ªâ c·∫ßn lo·∫°i b·ªè timeline v√† c√°c ph·∫ßn kh√¥ng c·∫ßn thi·∫øt
            
            # N·∫øu c√≥ ph·∫ßn "=== TRANSCRIPT V·ªöI TIMELINE ===", l·∫•y ph·∫ßn sau ƒë√≥
            if "=== TRANSCRIPT V·ªöI TIMELINE ===" in text:
                parts = text.split("=== TRANSCRIPT V·ªöI TIMELINE ===")
                if len(parts) > 1:
                    # L·∫•y ph·∫ßn sau "TRANSCRIPT V·ªöI TIMELINE"
                    content_after_timeline = parts[1].strip()
                    
                    # N·∫øu c√≥ ph·∫ßn "=== TRANSCRIPT G·ªêC ===", b·ªè qua ph·∫ßn ƒë√≥
                    if "=== TRANSCRIPT G·ªêC ===" in content_after_timeline:
                        parts2 = content_after_timeline.split("=== TRANSCRIPT G·ªêC ===")
                        if len(parts2) > 0:
                            main_content = parts2[0].strip()  # L·∫•y ph·∫ßn tr∆∞·ªõc "TRANSCRIPT G·ªêC"
                            formatted_content = self._format_text_no_timeline(main_content)
                            logger.info("‚úÖ ƒê√£ tr√≠ch xu·∫•t v√† format ph·∫ßn text ƒë√£ vi·∫øt l·∫°i (tr∆∞·ªõc TRANSCRIPT G·ªêC)")
                            logger.info(f"üìÑ N·ªôi dung tr√≠ch xu·∫•t (100 k√Ω t·ª± ƒë·∫ßu): {formatted_content[:100]}...")
                            return formatted_content
                    else:
                        # Kh√¥ng c√≥ TRANSCRIPT G·ªêC, l·∫•y to√†n b·ªô ph·∫ßn sau timeline v√† format l·∫°i
                        formatted_content = self._format_text_no_timeline(content_after_timeline)
                        logger.info("‚úÖ ƒê√£ tr√≠ch xu·∫•t v√† format to√†n b·ªô ph·∫ßn sau TRANSCRIPT V·ªöI TIMELINE")
                        logger.info(f"üìÑ N·ªôi dung tr√≠ch xu·∫•t (100 k√Ω t·ª± ƒë·∫ßu): {formatted_content[:100]}...")
                        return formatted_content
            
            # N·∫øu kh√¥ng c√≥ c·∫•u tr√∫c ƒë·∫∑c bi·ªát, lo·∫°i b·ªè c√°c d√≤ng timeline
            lines = text.split('\n')
            cleaned_lines = []
            
            # Regex ƒë·ªÉ ph√°t hi·ªán timeline pattern
            import re
            timeline_pattern = r'\(Gi√¢y\s+\d+-\d+\)'
            
            for line in lines:
                line = line.strip()
                # B·ªè qua c√°c d√≤ng tr·ªëng v√† header
                if (line.startswith('===') or 
                    line == '' or
                    'TRANSCRIPT V·ªöI TIMELINE' in line or
                    'TRANSCRIPT G·ªêC' in line):
                    continue
                
                # X·ª≠ l√Ω d√≤ng c√≥ timeline: ch·ªâ l·∫•y n·ªôi dung sau timeline
                if re.search(timeline_pattern, line):
                    # T√¨m v·ªã tr√≠ k·∫øt th√∫c c·ªßa pattern timeline
                    match = re.search(timeline_pattern, line)
                    if match:
                        # L·∫•y n·ªôi dung sau timeline pattern
                        content_after_timeline = line[match.end():].strip()
                        if content_after_timeline:
                            cleaned_lines.append(content_after_timeline)
                else:
                    # N·∫øu kh√¥ng c√≥ timeline, gi·ªØ nguy√™n d√≤ng
                    if line:
                        cleaned_lines.append(line)
            
            # Thay v√¨ n·ªëi th√†nh 1 ƒëo·∫°n d√†i, chia th√†nh c√°c ƒëo·∫°n r√µ r√†ng
            if cleaned_lines:
                # Nh√≥m c√°c c√¢u th√†nh ƒëo·∫°n vƒÉn (m·ªói 2-3 c√¢u 1 ƒëo·∫°n)
                paragraphs = []
                current_paragraph = []
                
                for line in cleaned_lines:
                    current_paragraph.append(line)
                    # T·∫°o ƒëo·∫°n m·ªõi khi:
                    # 1. ƒê√£ c√≥ ƒë·ªß 2-3 c√¢u
                    # 2. G·∫∑p t·ª´ k·∫øt th√∫c √Ω
                    # 3. C√¢u qu√° d√†i (>150 k√Ω t·ª±)
                    should_break = (
                        len(current_paragraph) >= 3 or
                        any(end_word in line.lower() for end_word in ['n√™n', 'r·ªìi', 'ƒë·∫•y', 'nh√©', '·∫°', 'th·∫ø', 'lu√¥n', 'ƒë∆∞·ª£c']) or
                        len(' '.join(current_paragraph)) > 150
                    )
                    
                    if should_break:
                        paragraphs.append(' '.join(current_paragraph))
                        current_paragraph = []
                
                # Th√™m ƒëo·∫°n cu·ªëi n·∫øu c√≤n
                if current_paragraph:
                    paragraphs.append(' '.join(current_paragraph))
                
                # N·ªëi c√°c ƒëo·∫°n b·∫±ng xu·ªëng d√≤ng ƒë√¥i ƒë·ªÉ t·∫°o c·∫•u tr√∫c r√µ r√†ng
                cleaned_text = '\n\n'.join(paragraphs).strip()
            else:
                cleaned_text = ''
            
            logger.info("‚úÖ ƒê√£ lo·∫°i b·ªè timeline v√† t·∫°o c·∫•u tr√∫c r√µ r√†ng")
            logger.info(f"üìÑ N·ªôi dung ƒë√£ l√†m s·∫°ch (100 k√Ω t·ª± ƒë·∫ßu): {cleaned_text[:100]}...")
            return cleaned_text
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói tr√≠ch xu·∫•t n·ªôi dung ch√≠nh: {str(e)}")
            return text  # Tr·∫£ v·ªÅ text g·ªëc n·∫øu c√≥ l·ªói
    
    def _extract_main_content_with_timeline(self, text: str) -> str:
        """
        Tr√≠ch xu·∫•t ch·ªâ n·ªôi dung ch√≠nh c√≥ timeline (kh√¥ng c√≥ ti√™u ƒë·ªÅ, caption, CTA)
        
        Args:
            text: Text c·∫ßn tr√≠ch xu·∫•t (c√≥ c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß)
            
        Returns:
            Ch·ªâ n·ªôi dung ch√≠nh c√≥ timeline
        """
        try:
            # Tr√≠ch xu·∫•t n·ªôi dung ch√≠nh (format m·ªõi c√≥ d·∫•u, kh√¥ng icon)
            main_content = ""
            # H·ªó tr·ª£ c·∫£ "N·ªòI DUNG CH√çNH" v√† "N·ªôi dung ch√≠nh"
            if "N·ªòI DUNG CH√çNH" in text or "N·ªôi dung ch√≠nh" in text:
                start_markers = []
                if "N·ªòI DUNG CH√çNH" in text:
                    start_markers.append("N·ªòI DUNG CH√çNH")
                if "N·ªôi dung ch√≠nh" in text:
                    start_markers.append("N·ªôi dung ch√≠nh")

                # C√°c ƒëi·ªÉm k·∫øt th√∫c c√≥ th·ªÉ c√≥ sau ph·∫ßn n·ªôi dung ch√≠nh
                possible_end_markers = [
                    "G·ª¢I √ù 3 CAPTION",
                    "G·ª£i √Ω 3 caption",
                    "**üì± G·ª¢I √ù 3 CAPTION",
                    "CAPTION TIKTOK",
                    "CALL TO ACTION",
                    "CTA:",
                    "CTA"
                ]

                # Th·ª≠ l·∫ßn l∆∞·ª£t v·ªõi c√°c start/end markers ƒë·ªÉ l·∫•y ph·∫ßn n·ªôi dung ch√≠nh ƒë·∫ßu ti√™n h·ª£p l·ªá
                for start_marker in start_markers:
                    section = ""
                    for end_marker in possible_end_markers:
                        section = self._extract_section(text, start_marker, end_marker)
                        if section and len(section.strip()) > 10:
                            break
                    if not section:
                        # N·∫øu kh√¥ng t√¨m th·∫•y end marker, l·∫•y ƒë·∫øn h·∫øt vƒÉn b·∫£n
                        section = self._extract_section(text, start_marker, None)
                    if section and len(section.strip()) > 10:
                        main_content = section
                        break
            # Fallback cho format c≈© c√≥ icon
            elif "**üìù N·ªòI DUNG CH√çNH" in text:
                main_content = self._extract_section(text, "**üìù N·ªòI DUNG CH√çNH", "**üì± G·ª¢I √ù")
            else:
                # Fallback: coi to√†n b·ªô text nh∆∞ n·ªôi dung ch√≠nh
                main_content = text
            
            # L√†m s·∫°ch v√† format n·ªôi dung ch√≠nh (gi·ªØ nguy√™n timeline)
            if main_content:
                # Lo·∫°i b·ªè c√°c d√≤ng tr·ªëng th·ª´a v√† format l·∫°i
                lines = main_content.strip().split('\n')
                cleaned_lines = []
                
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('**') and not line.startswith('==='):
                        # Lo·∫°i b·ªè ƒë·ªÅ m·ª•c "(GI·ªÆ NGUY√äN TIMELINE):"
                        if "(GI·ªÆ NGUY√äN TIMELINE)" in line or "(GIU NGUYEN TIMELINE)" in line:
                            continue
                        # Lo·∫°i b·ªè d·∫•u ngo·∫∑c vu√¥ng n·∫øu c√≥
                        line = re.sub(r'^\[|\]$', '', line)
                        # Lo·∫°i b·ªè t·∫•t c·∫£ d·∫•u ** th·ª´a (ƒë·∫ßu, cu·ªëi, gi·ªØa c√¢u)
                        line = re.sub(r'\*\*', '', line).strip()
                        if line:
                            cleaned_lines.append(line)
                
                return '\n\n'.join(cleaned_lines).strip()
            
            return main_content.strip() if main_content else ""
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói tr√≠ch xu·∫•t n·ªôi dung ch√≠nh c√≥ timeline: {str(e)}")
            return text

    def _extract_only_main_content_from_full_text(self, text: str) -> str:
        """
        Tr√≠ch xu·∫•t ch·ªâ n·ªôi dung ch√≠nh t·ª´ to√†n b·ªô text, lo·∫°i b·ªè t·∫•t c·∫£ g·ª£i √Ω
        
        Args:
            text: Text ƒë·∫ßy ƒë·ªß c√≥ th·ªÉ ch·ª©a g·ª£i √Ω ti√™u ƒë·ªÅ, caption, CTA
            
        Returns:
            Ch·ªâ n·ªôi dung ch√≠nh
        """
        try:
            lines = text.strip().split('\n')
            main_content_lines = []
            skip_section = False
            
            for line in lines:
                line_clean = line.strip()
                
                # B·ªè qua d√≤ng tr·ªëng
                if not line_clean:
                    continue
                
                # KI·ªÇM TRA NGHI√äM NG·∫∂T - B·ªè qua t·∫•t c·∫£ d√≤ng ch·ª©a t·ª´ kh√≥a g·ª£i √Ω
                skip_keywords = [
                    "G·ª¢I √ù", "GOI Y", "TI√äU ƒê·ªÄ", "TIEU DE", "CAPTION", "CALL TO ACTION", "CTA",
                    "TIKTOK", "HASHTAG", "PENTHOUSE", "MOTHAIT", "VIRAL", "MEOHAY",
                    "XAYNHA", "XAYDUNG", "KIENTHUC", "NHADEEP", "THIETKE"
                ]
                
                if any(keyword in line_clean.upper() for keyword in skip_keywords):
                    skip_section = True
                    continue
                
                # B·ªè qua c√°c d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng s·ªë (1., 2., 3., ...)
                if re.match(r'^\d+\.', line_clean):
                    continue
                    
                # B·ªè qua c√°c d√≤ng c√≥ icon, hashtag, ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
                if any(char in line_clean for char in ['üìã', 'üìù', 'üì±', 'üéØ', 'üòç', '‚ù§Ô∏è', '#', 'üè†', 'üî•', 'üí°']):
                    continue
                
                # B·ªè qua d√≤ng ch·ªâ c√≥ d·∫•u ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
                if line_clean in ['---', '===', '***'] or len(line_clean.replace(' ', '').replace('-', '').replace('=', '').replace('*', '')) < 3:
                    continue
                
                # N·∫øu d√≤ng c√≥ (Gi√¢y ...) th√¨ ƒë√¢y ch·∫Øc ch·∫Øn l√† n·ªôi dung ch√≠nh
                if "(Gi√¢y" in line_clean or "(gi√¢y" in line_clean:
                    skip_section = False
                    main_content_lines.append(line_clean)
                    continue
                
                # Ch·ªâ l·∫•y n·ªôi dung th·∫≠t s·ª± - ph·∫£i c√≥ √≠t nh·∫•t 15 k√Ω t·ª± v√† kh√¥ng trong section g·ª£i √Ω
                if not skip_section and len(line_clean) > 15:
                    # Ki·ªÉm tra th√™m - kh√¥ng ƒë∆∞·ª£c ch·ª©a c√°c t·ª´ nghi ng·ªù
                    suspicious_words = ["hack", "m·∫πo", "b√≠ quy·∫øt", "chi√™u", "tip", "trick", "m√°ch n∆∞·ªõc"]
                    if not any(word in line_clean.lower() for word in suspicious_words):
                        main_content_lines.append(line_clean)
                    elif "(Gi√¢y" in line_clean:  # N·∫øu c√≥ timeline th√¨ v·∫´n l·∫•y
                        main_content_lines.append(line_clean)
            
            return '\n'.join(main_content_lines).strip() if main_content_lines else ""
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói extract only main content: {str(e)}")
            return text

    def _filter_main_content_line_by_line(self, text: str) -> str:
        """
        L·ªçc t·ª´ng d√≤ng ƒë·ªÉ ch·ªâ l·∫•y n·ªôi dung ch√≠nh, lo·∫°i b·ªè ho√†n to√†n g·ª£i √Ω
        
        Args:
            text: Text ƒë·∫ßy ƒë·ªß
            
        Returns:
            Ch·ªâ n·ªôi dung ch√≠nh
        """
        try:
            lines = text.split('\n')
            main_lines = []
            in_suggestion_section = False
            
            for line in lines:
                line_clean = line.strip()
                
                # B·ªè qua d√≤ng tr·ªëng
                if not line_clean:
                    continue
                
                # Ki·ªÉm tra xem c√≥ ph·∫£i d√≤ng b·∫Øt ƒë·∫ßu section g·ª£i √Ω kh√¥ng
                suggestion_starters = [
                    "G·ª¢I √ù", "GOI Y", "TI√äU ƒê·ªÄ", "TIEU DE",
                    "G·ª£i √Ω", "G·ª£i √Ω 5 ti√™u ƒë·ªÅ", "G·ª£i √Ω 3 caption",
                    "CAPTION", "CALL TO ACTION", "CTA"
                ]
                
                if any(starter in line_clean.upper() for starter in suggestion_starters):
                    in_suggestion_section = True
                    continue
                
                # B·ªè qua t·∫•t c·∫£ d√≤ng trong section g·ª£i √Ω
                if in_suggestion_section:
                    # Ch·ªâ tho√°t kh·ªèi suggestion section n·∫øu g·∫∑p timeline m·ªõi
                    if "(Gi√¢y" in line_clean or "(gi√¢y" in line_clean:
                        in_suggestion_section = False
                        main_lines.append(line_clean)
                    continue
                
                # B·ªè qua d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng s·ªë
                if re.match(r'^\d+\.', line_clean):
                    continue
                
                # B·ªè qua d√≤ng c√≥ hashtag ho·∫∑c icon
                if '#' in line_clean or any(icon in line_clean for icon in ['üìã', 'üìù', 'üì±', 'üéØ', 'üòç', '‚ù§Ô∏è']):
                    continue
                
                # B·ªè qua d√≤ng ti√™u ƒë·ªÅ "N·ªòI DUNG CH√çNH"
                if "N·ªòI DUNG CH√çNH" in line_clean.upper():
                    continue
                
                # Ch·ªâ l·∫•y d√≤ng c√≥ n·ªôi dung th·∫≠t s·ª±
                if len(line_clean) > 10:
                    main_lines.append(line_clean)
            
            return '\n'.join(main_lines)
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói filter main content line by line: {str(e)}")
            return text

    def _format_text_no_timeline(self, text: str) -> str:
        """
        Format ch·ªâ n·ªôi dung thu·∫ßn t√∫y kh√¥ng c√≥ timeline, kh√¥ng c√≥ ƒë·ªÅ m·ª•c, kh√¥ng c√≥ g·ª£i √Ω
        S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p l∆∞u t·∫°m v√† x√≥a ƒë·ªÉ ƒë·∫£m b·∫£o lo·∫°i b·ªè ho√†n to√†n g·ª£i √Ω
        
        Args:
            text: Text c·∫ßn format (c√≥ c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß)
            
        Returns:
            Ch·ªâ n·ªôi dung thu·∫ßn t√∫y kh√¥ng timeline
        """
        try:
            # B∆∞·ªõc 1: L∆∞u text g·ªëc v√†o b·ªô nh·ªõ t·∫°m
            temp_text = text
            
            # B∆∞·ªõc 2: Lo·∫°i b·ªè t·∫•t c·∫£ section g·ª£i √Ω b·∫±ng c√°ch c·∫Øt text
            # T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu c·ªßa n·ªôi dung ch√≠nh
            main_content_start = -1
            main_content_end = -1
            
            # T√¨m ƒëi·ªÉm b·∫Øt ƒë·∫ßu n·ªôi dung ch√≠nh
            if "N·ªòI DUNG CH√çNH" in temp_text:
                main_content_start = temp_text.find("N·ªòI DUNG CH√çNH")
            elif "N·ªôi dung ch√≠nh" in temp_text:
                main_content_start = temp_text.find("N·ªôi dung ch√≠nh")
            elif "**üìù N·ªòI DUNG CH√çNH" in temp_text:
                main_content_start = temp_text.find("**üìù N·ªòI DUNG CH√çNH")
            
            if main_content_start != -1:
                # T√¨m ƒëi·ªÉm k·∫øt th√∫c (tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu g·ª£i √Ω)
                end_markers = [
                    "G·ª¢I √ù", "GOI Y", "G·ª£i √Ω", "G·ª£i √Ω 3 caption",
                    "CAPTION", "CALL TO ACTION", "CTA"
                ]
                
                for marker in end_markers:
                    marker_pos = temp_text.find(marker, main_content_start + 20)  # T√¨m sau v·ªã tr√≠ b·∫Øt ƒë·∫ßu
                    if marker_pos != -1:
                        if main_content_end == -1 or marker_pos < main_content_end:
                            main_content_end = marker_pos
                
                # C·∫Øt l·∫•y ch·ªâ ph·∫ßn n·ªôi dung ch√≠nh
                if main_content_end != -1:
                    main_content = temp_text[main_content_start:main_content_end]
                else:
                    main_content = temp_text[main_content_start:]
            else:
                # Fallback: L·ªçc t·ª´ng d√≤ng
                main_content = self._filter_main_content_line_by_line(temp_text)
            
            # B∆∞·ªõc 3: X√≥a b·ªô nh·ªõ t·∫°m
            temp_text = None
            
            # B∆∞·ªõc 4: Format n·ªôi dung ch√≠nh v√† lo·∫°i b·ªè d√≤ng ti√™u ƒë·ªÅ
            if main_content:
                # Lo·∫°i b·ªè d√≤ng ti√™u ƒë·ªÅ "N·ªòI DUNG CH√çNH"/"N·ªôi dung ch√≠nh" n·∫øu c√≤n
                lines = main_content.split('\n')
                cleaned_lines = []
                for line in lines:
                    line_clean = line.strip()
                    if line_clean and ("N·ªòI DUNG CH√çNH" not in line_clean.upper()) and ("N·ªôi dung ch√≠nh" not in line_clean):
                        cleaned_lines.append(line)
                
                main_content_cleaned = '\n'.join(cleaned_lines)
                formatted_content = self._format_main_content_only(main_content_cleaned)
                return formatted_content.strip()
            
            return "(Kh√¥ng c√≥ n·ªôi dung)"
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format text no timeline: {str(e)}")
            return text
    
    def _remove_timeline_keep_format(self, text: str) -> str:
        """
        B·ªè timeline nh∆∞ng gi·ªØ nguy√™n format: c√¢u d·∫´n, icon üëâ, format 1 c√¢u c√°ch 1 h√†ng
        
        Args:
            text: Text c√≥ timeline c·∫ßn x·ª≠ l√Ω
            
        Returns:
            Text kh√¥ng c√≥ timeline nh∆∞ng gi·ªØ nguy√™n format
        """
        try:
            if not text:
                return text
            
            lines = text.split('\n')
            formatted_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # B·ªè timeline nh∆∞ng gi·ªØ nguy√™n n·ªôi dung v√† format
                # T√¨m v√† lo·∫°i b·ªè pattern "(Gi√¢y X-Y)" ho·∫∑c "(Gi√¢y X-Y:)"
                import re
                
                # Lo·∫°i b·ªè timeline pattern
                line_no_timeline = re.sub(r'\(Gi√¢y\s+\d+-\d+\)\s*:?\s*', '', line)
                line_no_timeline = re.sub(r'\(Gi√¢y\s+\d+-\d+\)', '', line_no_timeline)
                
                # Gi·ªØ nguy√™n icon üëâ v√† format
                if line_no_timeline.strip():
                    formatted_lines.append(line_no_timeline.strip())
            
            # Format 1 c√¢u c√°ch 1 h√†ng cho d·ªÖ ƒë·ªçc
            result = '\n\n'.join(formatted_lines)
            
            return result.strip()
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói remove timeline keep format: {str(e)}")
            return text

    def _format_suggestions_content(self, text: str) -> str:
        """
        Format ch·ªâ 3 ph·∫ßn: G·ª£i √Ω ti√™u ƒë·ªÅ + Caption + CTA (r√µ r√†ng t·ª´ng ph·∫ßn)
        
        Args:
            text: Text c·∫ßn format (c√≥ c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß)
            
        Returns:
            Text ch·ª©a 3 ph·∫ßn r√µ r√†ng: ti√™u ƒë·ªÅ + captions + CTA
        """
        try:
            formatted_parts = []
            
            # 1. G·ª¢I √ù 5 TI√äU ƒê·ªÄ - C·∫¢I THI·ªÜN T√åM KI·∫æM
            titles_content = ""
            
            # Debug: Log ƒë·ªÉ ki·ªÉm tra ti√™u ƒë·ªÅ
            logger.info(f"üîç ƒêang t√¨m ti√™u ƒë·ªÅ trong text")
            
            # Th·ª≠ nhi·ªÅu c√°ch t√¨m ti√™u ƒë·ªÅ
            title_markers = [
                "G·ª¢I √ù 5 TI√äU ƒê·ªÄ:",
                "**üìã G·ª¢I √ù 5 TI√äU ƒê·ªÄ:**",
                "G·ª¢I √ù 5 TI√äU ƒê·ªÄ",
                "G·ª£i √Ω 5 ti√™u ƒë·ªÅ",
                "5 TI√äU ƒê·ªÄ"
            ]
            
            for marker in title_markers:
                if marker in text:
                    # T√¨m end marker ph√π h·ª£p - CH·ªà L·∫§Y ƒê·∫æN CAPTION, KH√îNG L·∫§Y N·ªòI DUNG CH√çNH
                    end_markers = [
                        "G·ª¢I √ù 3 CAPTION",
                        "G·ª£i √Ω 3 caption",
                        "**üì± G·ª¢I √ù 3 CAPTION",
                        "CAPTION TIKTOK",
                        "CALL TO ACTION",
                        "CTA:",
                        "CTA",
                        "==="
                    ]
                    titles_section = ""
                    
                    for end_marker in end_markers:
                        titles_section = self._extract_section(text, marker, end_marker)
                        if titles_section and len(titles_section.strip()) > 10:
                            break
                    
                    if titles_section:
                        titles_content = self._format_titles_section(titles_section)
                        logger.info(f"‚úÖ T√¨m th·∫•y ti√™u ƒë·ªÅ v·ªõi marker: {marker}")
                        logger.info(f"‚úÖ Titles content: {titles_content[:100]}...")
                        break
            
            if titles_content:
                formatted_parts.append("****G·ª£i √Ω 5 ti√™u ƒë·ªÅ")
                formatted_parts.append(titles_content)
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ti√™u ƒë·ªÅ, t·∫°o ti√™u ƒë·ªÅ m·∫∑c ƒë·ªãnh")
                default_titles = """1. "Thi·∫øt k·∫ø t·ªß gi√†y √¢m t∆∞·ªùng: Gi·∫£i ph√°p t·ªëi ∆∞u cho kh√¥ng gian hi·ªán ƒë·∫°i!"
2. "T·ªß gi√†y √¢m t∆∞·ªùng: K·∫øt h·ª£p ho√†n h·∫£o gi·ªØa th·∫©m m·ªπ v√† c√¥ng nƒÉng!"
3. "Thi·∫øt k·∫ø t·ªß gi√†y th√¥ng minh: T·ªëi ∆∞u h√≥a kh√¥ng gian s·ªëng!"
4. "T·ªß gi√†y √¢m t∆∞·ªùng ƒëa nƒÉng: Gi·∫£i ph√°p thi·∫øt k·∫ø ti√™n ti·∫øn!"
5. "T·ªß gi√†y √¢m t∆∞·ªùng: N√¢ng t·∫ßm kh√¥ng gian s·ªëng v·ªõi thi·∫øt k·∫ø chuy√™n nghi·ªáp!" """
                formatted_parts.append("****G·ª£i √Ω 5 ti√™u ƒë·ªÅ")
                formatted_parts.append(default_titles)
            
            # 2. G·ª¢I √ù 3 CAPTION TIKTOK - C·∫¢I THI·ªÜN T√åM KI·∫æM
            captions_content = ""
            
            # Debug: Log ƒë·ªÉ ki·ªÉm tra caption
            logger.info(f"üîç ƒêang t√¨m caption trong text")
            
            # Th·ª≠ nhi·ªÅu c√°ch t√¨m caption
            caption_markers = [
                "G·ª¢I √ù 3 CAPTION TIKTOK:",
                "**üì± G·ª¢I √ù 3 CAPTION TIKTOK:**",
                "G·ª¢I √ù 3 CAPTION",
                "G·ª£i √Ω 3 caption",
                "CAPTION TIKTOK"
            ]
            
            for marker in caption_markers:
                if marker in text:
                    # T√¨m end marker ph√π h·ª£p - CH·ªà L·∫§Y ƒê·∫æN CTA, KH√îNG L·∫§Y N·ªòI DUNG CH√çNH
                    end_markers = [
                        "CALL TO ACTION",
                        "**üéØ CALL TO ACTION",
                        "CTA:",
                        "CTA",
                        "==="
                    ]
                    captions_section = ""
                    
                    for end_marker in end_markers:
                        captions_section = self._extract_section(text, marker, end_marker)
                        if captions_section and len(captions_section.strip()) > 10:
                            break
                    
                    if captions_section:
                        captions_content = self._format_captions_section(captions_section)
                        logger.info(f"‚úÖ T√¨m th·∫•y caption v·ªõi marker: {marker}")
                        logger.info(f"‚úÖ Caption content: {captions_content[:100]}...")
                        break
            
            if captions_content:
                formatted_parts.append("****G·ª£i √Ω 3 caption")
                formatted_parts.append(captions_content)
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y caption, t·∫°o caption m·∫∑c ƒë·ªãnh")
                default_captions = """1. "Thi·∫øt k·∫ø t·ªß gi√†y √¢m t∆∞·ªùng: Gi·∫£i ph√°p t·ªëi ∆∞u cho kh√¥ng gian hi·ªán ƒë·∫°i! #thietkenoithat #tugiayamtuong #khonggianhiendai"
2. "T·ªß gi√†y √¢m t∆∞·ªùng: K·∫øt h·ª£p ho√†n h·∫£o gi·ªØa th·∫©m m·ªπ v√† c√¥ng nƒÉng! #noithat #tugiay #thietkechuyennghiep"
3. "Thi·∫øt k·∫ø t·ªß gi√†y th√¥ng minh: T·ªëi ∆∞u h√≥a kh√¥ng gian s·ªëng! #tugiaythongminh #toiuuhoa #khonggiansong" """
                formatted_parts.append("****G·ª£i √Ω 3 caption")
                formatted_parts.append(default_captions)
            
            # 3. CALL TO ACTION - C·∫¢I THI·ªÜN T√åM KI·∫æM LINH HO·∫†T
            cta_content = ""
            
            # Debug: Log to√†n b·ªô text ƒë·ªÉ ki·ªÉm tra
            logger.info(f"üîç ƒêang t√¨m CTA trong text ({len(text)} k√Ω t·ª±)")
            logger.info(f"üîç Text preview: {text[:500]}...")
            
            # Th·ª≠ nhi·ªÅu c√°ch t√¨m CTA
            cta_markers = [
                "CALL TO ACTION (CTA) - VI·∫æT M·ªöI D·ª∞A TR√äN M·∫™U:",
                "CALL TO ACTION (CTA):",
                "CALL TO ACTION:",
                "**üéØ CALL TO ACTION**",
                "**üéØ CALL TO ACTION:**",
                "CTA:",
                "CTA",
                "Call to action:"
            ]
            
            for marker in cta_markers:
                if marker in text:
                    cta_section = self._extract_section(text, marker, None)
                    if cta_section:
                        cta_content = self._format_cta_section(cta_section)
                        logger.info(f"‚úÖ T√¨m th·∫•y CTA v·ªõi marker: {marker}")
                        logger.info(f"‚úÖ CTA content: {cta_content[:100]}...")
                        break
            
            # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m d√≤ng c√≥ ch·ª©a CTA
            if not cta_content:
                lines = text.split('\n')
                for i, line in enumerate(lines):
                    if any(keyword in line.lower() for keyword in ['call to action', 'cta', 'l∆∞u l·∫°i', 'chia s·∫ª', 'b√¨nh lu·∫≠n']):
                        # L·∫•y d√≤ng ƒë√≥ v√† v√†i d√≤ng ti·∫øp theo
                        cta_lines = []
                        for j in range(i, min(i + 3, len(lines))):
                            if lines[j].strip():
                                cta_lines.append(lines[j].strip())
                        if cta_lines:
                            cta_content = ' '.join(cta_lines)
                            logger.info(f"‚úÖ T√¨m th·∫•y CTA trong d√≤ng: {line[:50]}...")
                            break
            
            if cta_content:
                formatted_parts.append("****CTA")
                formatted_parts.append(cta_content)
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y CTA trong text")
                # T·∫°o CTA m·∫∑c ƒë·ªãnh
                default_cta = "Thi·∫øt k·∫ø n√†y s·∫Ω n√¢ng t·∫ßm kh√¥ng gian s·ªëng c·ªßa c√°c b√°c! L∆∞u l·∫°i ngay ƒë·ªÉ tham kh·∫£o, chia s·∫ª cho b·∫°n b√® c√πng xem nh√©!"
                formatted_parts.append("****CTA")
                formatted_parts.append(default_cta)
            
            # N·ªëi 3 ph·∫ßn v·ªõi xu·ªëng d√≤ng ƒë√¥i ƒë·ªÉ r√µ r√†ng, lo·∫°i b·ªè kho·∫£ng tr·ªëng ƒë·∫ßu cu·ªëi
            result = '\n\n'.join(formatted_parts).strip()
            
            # KI·ªÇM TRA CU·ªêI C√ôNG: ƒê·∫£m b·∫£o kh√¥ng c√≥ n·ªôi dung ch√≠nh n√†o b·ªã l·ªçt v√†o
            if ("N·ªòI DUNG CH√çNH" in result or "N·ªôi dung ch√≠nh" in result or "Gi√¢y" in result):
                logger.warning("‚ö†Ô∏è Ph√°t hi·ªán n·ªôi dung ch√≠nh trong k·∫øt qu·∫£, ƒëang l·ªçc l·∫°i...")
                # L·ªçc l·∫°i t·ª´ng d√≤ng ƒë·ªÉ lo·∫°i b·ªè n·ªôi dung ch√≠nh
                lines = result.split('\n')
                filtered_lines = []
                for line in lines:
                    line_clean = line.strip()
                    if (line_clean and 
                        ("N·ªòI DUNG CH√çNH" not in line_clean.upper()) and ("N·ªôi dung ch√≠nh" not in line_clean) and
                        not line_clean.startswith("Gi√¢y") and
                        not "Gi√¢y" in line_clean):
                        filtered_lines.append(line)
                result = '\n'.join(filtered_lines).strip()
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format suggestions content: {str(e)}")
            return ""
    
    def _format_full_structure_with_newlines(self, text: str) -> str:
        """
        Format c·∫•u tr√∫c ƒë·∫ßy ƒë·ªß v·ªõi xu·ªëng d√≤ng ƒë·∫πp - CH·ªà BAO G·ªíM 3 PH·∫¶N CH√çNH
        """
        try:
            formatted_parts = []
            
            # 1. Tr√≠ch xu·∫•t v√† format 5 ti√™u ƒë·ªÅ
            if "**üìã G·ª¢I √ù 5 TI√äU ƒê·ªÄ:**" in text or "G·ª£i √Ω 5 ti√™u ƒë·ªÅ" in text or "G·ª¢I √ù 5 TI√äU ƒê·ªÄ" in text:
                if "**üìã G·ª¢I √ù 5 TI√äU ƒê·ªÄ:**" in text:
                    titles_section = self._extract_section(text, "**üìã G·ª¢I √ù 5 TI√äU ƒê·ªÄ:**", "**üì± G·ª¢I √ù 3 CAPTION")
                elif "G·ª£i √Ω 5 ti√™u ƒë·ªÅ" in text:
                    titles_section = self._extract_section(text, "G·ª£i √Ω 5 ti√™u ƒë·ªÅ", "G·ª£i √Ω 3 caption")
                    if not titles_section:
                        titles_section = self._extract_section(text, "G·ª£i √Ω 5 ti√™u ƒë·ªÅ", "G·ª¢I √ù 3 CAPTION")
                else:
                    titles_section = self._extract_section(text, "G·ª¢I √ù 5 TI√äU ƒê·ªÄ", "G·ª¢I √ù 3 CAPTION")
                if titles_section:
                    formatted_titles = self._format_titles_section(titles_section)
                    if formatted_titles:
                        formatted_parts.append("*G·ª£i √Ω 5 ti√™u ƒë·ªÅ")
                        formatted_parts.append(formatted_titles)
            
            # 2. Tr√≠ch xu·∫•t v√† format captions
            if ("**üì± G·ª¢I √ù 3 CAPTION TIKTOK:**" in text) or ("G·ª£i √Ω 3 caption" in text) or ("G·ª¢I √ù 3 CAPTION" in text):
                if "**üì± G·ª¢I √ù 3 CAPTION TIKTOK:**" in text:
                    captions_section = self._extract_section(text, "**üì± G·ª¢I √ù 3 CAPTION TIKTOK:**", "**üéØ CALL TO ACTION")
                elif "G·ª£i √Ω 3 caption" in text:
                    captions_section = self._extract_section(text, "G·ª£i √Ω 3 caption", "CTA")
                    if not captions_section:
                        captions_section = self._extract_section(text, "G·ª£i √Ω 3 caption", "CALL TO ACTION")
                else:
                    captions_section = self._extract_section(text, "G·ª¢I √ù 3 CAPTION", "CALL TO ACTION")
                if captions_section:
                    formatted_captions = self._format_captions_section(captions_section)
                    if formatted_captions:
                        formatted_parts.append("*G·ª£i √Ω 3 caption")
                        formatted_parts.append(formatted_captions)
            
            # 3. Tr√≠ch xu·∫•t v√† format CTA
            if ("**üéØ CALL TO ACTION" in text) or ("CTA" in text):
                if "**üéØ CALL TO ACTION" in text:
                    cta_section = self._extract_section(text, "**üéØ CALL TO ACTION", None)
                else:
                    cta_section = self._extract_section(text, "CTA", None)
                if cta_section:
                    formatted_cta = self._format_cta_section(cta_section)
                    if formatted_cta:
                        formatted_parts.append("*CTA")
                        formatted_parts.append(formatted_cta)
            
            # N·ªëi t·∫•t c·∫£ v·ªõi xu·ªëng d√≤ng ƒë√¥i
            return '\n\n'.join(formatted_parts).strip()
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format full structure: {str(e)}")
            return text
    
    def _extract_section(self, text: str, start_marker: str, end_marker: str = None) -> str:
        """Tr√≠ch xu·∫•t m·ªôt section t·ª´ text"""
        try:
            if start_marker not in text:
                return ""
            
            parts = text.split(start_marker)
            if len(parts) < 2:
                return ""
            
            content = parts[1]
            
            if end_marker and end_marker in content:
                content = content.split(end_marker)[0]
            
            return content.strip()
        except:
            return ""
    
    def _format_titles_section(self, titles_text: str) -> str:
        """Format section ti√™u ƒë·ªÅ v·ªõi s·ªë th·ª© t·ª± r√µ r√†ng"""
        try:
            lines = titles_text.split('\n')
            formatted_titles = []
            counter = 1
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith('**') and not line.startswith('['):
                    # Lo·∫°i b·ªè s·ªë th·ª© t·ª± c≈© v√† th√™m s·ªë th·ª© t·ª± m·ªõi
                    if line.startswith(('1.', '2.', '3.', '4.', '5.')):
                        title_content = line.split('.', 1)[1].strip()
                        if title_content and not title_content.startswith('['):
                            # Lo·∫°i b·ªè d·∫•u ngo·∫∑c vu√¥ng n·∫øu c√≥
                            title_content = re.sub(r'^\[|\]$', '', title_content).strip()
                            formatted_titles.append(f"{counter}. {title_content}")
                            counter += 1
                    elif not line.startswith(('G·ª¢I √ù', 'GOI Y')) and len(line) > 5:
                        # D√≤ng kh√¥ng c√≥ s·ªë th·ª© t·ª± nh∆∞ng l√† ti√™u ƒë·ªÅ
                        title_content = re.sub(r'^\[|\]$', '', line).strip()
                        if title_content:
                            formatted_titles.append(f"{counter}. {title_content}")
                            counter += 1
            
            return '\n'.join(formatted_titles).strip() if formatted_titles else ""
        except:
            return ""

    def _format_titles_section_no_diacritics(self, titles_text: str) -> str:
        """Format section ti√™u ƒë·ªÅ kh√¥ng c√≥ d·∫•u v·ªõi xu·ªëng d√≤ng ƒë·∫πp"""
        try:
            lines = titles_text.split('\n')
            formatted_titles = []
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith('**') and not line.startswith('['):
                    # Lo·∫°i b·ªè s·ªë th·ª© t·ª± v√† format l·∫°i
                    if line.startswith(('1.', '2.', '3.', '4.', '5.')):
                        title_content = line.split('.', 1)[1].strip()
                        if title_content and not title_content.startswith('['):
                            # Chuy·ªÉn th√†nh kh√¥ng d·∫•u
                            no_diacritics = self._remove_diacritics(title_content)
                            formatted_titles.append(no_diacritics)
            
            return '\n'.join(formatted_titles) if formatted_titles else ""
        except:
            return ""
    
    def _format_captions_section(self, captions_text: str) -> str:
        """Format section captions v·ªõi s·ªë th·ª© t·ª± r√µ r√†ng"""
        try:
            lines = captions_text.split('\n')
            formatted_captions = []
            counter = 1
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith('**') and not line.startswith('['):
                    # Lo·∫°i b·ªè s·ªë th·ª© t·ª± c≈© v√† th√™m s·ªë th·ª© t·ª± m·ªõi
                    if line.startswith(('1.', '2.', '3.')):
                        caption_content = line.split('.', 1)[1].strip()
                        if caption_content and not caption_content.startswith('['):
                            # Lo·∫°i b·ªè d·∫•u ngo·∫∑c vu√¥ng n·∫øu c√≥
                            caption_content = re.sub(r'^\[|\]$', '', caption_content).strip()
                            formatted_captions.append(f"{counter}. {caption_content}")
                            counter += 1
                    elif not line.startswith(('G·ª¢I √ù', 'GOI Y')) and len(line) > 10:
                        # D√≤ng kh√¥ng c√≥ s·ªë th·ª© t·ª± nh∆∞ng l√† caption
                        caption_content = re.sub(r'^\[|\]$', '', line).strip()
                        if caption_content:
                            formatted_captions.append(f"{counter}. {caption_content}")
                            counter += 1
            
            return '\n'.join(formatted_captions).strip() if formatted_captions else ""
        except:
            return ""

    def _format_captions_section_no_diacritics(self, captions_text: str) -> str:
        """Format section captions kh√¥ng c√≥ d·∫•u v·ªõi xu·ªëng d√≤ng ƒë·∫πp"""
        try:
            lines = captions_text.split('\n')
            formatted_captions = []
            
            for line in lines:
                line = line.strip()
                if line and not line.startswith('**') and not line.startswith('['):
                    # Lo·∫°i b·ªè s·ªë th·ª© t·ª± v√† format l·∫°i
                    if line.startswith(('1.', '2.', '3.')):
                        caption_content = line.split('.', 1)[1].strip()
                        if caption_content and not caption_content.startswith('['):
                            # Chuy·ªÉn th√†nh kh√¥ng d·∫•u
                            no_diacritics = self._remove_diacritics(caption_content)
                            formatted_captions.append(no_diacritics)
            
            return '\n'.join(formatted_captions) if formatted_captions else ""
        except:
            return ""
    
    def _format_cta_section(self, cta_text: str) -> str:
        """Format section CTA - C·∫¢I THI·ªÜN"""
        try:
            lines = cta_text.split('\n')
            cta_lines = []
            
            for line in lines:
                line = line.strip()
                # B·ªè qua d√≤ng r·ªóng, marker, v√† d·∫•u ngo·∫∑c vu√¥ng
                if (line and 
                    not line.startswith('**') and 
                    not line.startswith('[') and 
                    not line.startswith('===') and
                    not line.lower().startswith('call to action') and
                    not line.lower().startswith('cta')):
                    
                    # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
                    line = line.strip('"').strip("'").strip()
                    if line:
                        cta_lines.append(line)
            
            # N·∫øu c√≥ nhi·ªÅu d√≤ng, gh√©p l·∫°i
            if cta_lines:
                cta_result = ' '.join(cta_lines)
                logger.info(f"‚úÖ ƒê√£ format CTA: {cta_result[:100]}...")
                return cta_result
            
            # N·∫øu kh√¥ng t√¨m th·∫•y, t·∫°o CTA m·∫∑c ƒë·ªãnh
            logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y CTA h·ª£p l·ªá, t·∫°o CTA m·∫∑c ƒë·ªãnh")
            return "Thi·∫øt k·∫ø n√†y s·∫Ω n√¢ng t·∫ßm kh√¥ng gian s·ªëng c·ªßa c√°c b√°c! L∆∞u l·∫°i ngay ƒë·ªÉ tham kh·∫£o, chia s·∫ª cho b·∫°n b√® c√πng xem nh√©!"
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format CTA: {str(e)}")
            return "Thi·∫øt k·∫ø n√†y s·∫Ω n√¢ng t·∫ßm kh√¥ng gian s·ªëng c·ªßa c√°c b√°c! L∆∞u l·∫°i ngay ƒë·ªÉ tham kh·∫£o, chia s·∫ª cho b·∫°n b√® c√πng xem nh√©!"

    def _format_cta_section_no_diacritics(self, cta_text: str) -> str:
        """Format section CTA kh√¥ng c√≥ d·∫•u"""
        try:
            lines = cta_text.split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('**') and not line.startswith('['):
                    # Chuy·ªÉn th√†nh kh√¥ng d·∫•u
                    no_diacritics = self._remove_diacritics(line)
                    return no_diacritics
            return ""
        except:
            return ""
    
    def _remove_diacritics(self, text: str) -> str:
        """Chuy·ªÉn ti·∫øng Vi·ªát c√≥ d·∫•u th√†nh kh√¥ng d·∫•u"""
        try:
            # B·∫£ng chuy·ªÉn ƒë·ªïi ti·∫øng Vi·ªát
            vietnamese_map = {
                '√†': 'a', '√°': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
                '·∫ß': 'a', '·∫•': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
                '·∫±': 'a', '·∫Ø': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
                '√®': 'e', '√©': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
                '·ªÅ': 'e', '·∫ø': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
                '√¨': 'i', '√≠': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
                '√≤': 'o', '√≥': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
                '·ªì': 'o', '·ªë': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
                '·ªù': 'o', '·ªõ': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
                '√π': 'u', '√∫': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
                '·ª´': 'u', '·ª©': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
                '·ª≥': 'y', '√Ω': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y',
                'ƒë': 'd',
                # Ch·ªØ hoa
                '√Ä': 'A', '√Å': 'A', '·∫¢': 'A', '√É': 'A', '·∫†': 'A',
                '·∫¶': 'A', '·∫§': 'A', '·∫®': 'A', '·∫™': 'A', '·∫¨': 'A',
                '·∫∞': 'A', '·∫Æ': 'A', '·∫≤': 'A', '·∫¥': 'A', '·∫∂': 'A',
                '√à': 'E', '√â': 'E', '·∫∫': 'E', '·∫º': 'E', '·∫∏': 'E',
                '·ªÄ': 'E', '·∫æ': 'E', '·ªÇ': 'E', '·ªÑ': 'E', '·ªÜ': 'E',
                '√å': 'I', '√ç': 'I', '·ªà': 'I', 'ƒ®': 'I', '·ªä': 'I',
                '√í': 'O', '√ì': 'O', '·ªé': 'O', '√ï': 'O', '·ªå': 'O',
                '·ªí': 'O', '·ªê': 'O', '·ªî': 'O', '·ªñ': 'O', '·ªò': 'O',
                '·ªú': 'O', '·ªö': 'O', '·ªû': 'O', '·ª†': 'O', '·ª¢': 'O',
                '√ô': 'U', '√ö': 'U', '·ª¶': 'U', '≈®': 'U', '·ª§': 'U',
                '·ª™': 'U', '·ª®': 'U', '·ª¨': 'U', '·ªÆ': 'U', '·ª∞': 'U',
                '·ª≤': 'Y', '√ù': 'Y', '·ª∂': 'Y', '·ª∏': 'Y', '·ª¥': 'Y',
                'ƒê': 'D'
            }
            
            result = ""
            for char in text:
                result += vietnamese_map.get(char, char)
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói remove diacritics: {str(e)}")
            return text

    def _extract_lead_in(self, text: str, max_sentences: int = 2) -> str:
        """Tr√≠ch xu·∫•t 1-2 c√¢u v√†o ƒë·ªÅ ƒë·∫ßu ti√™n t·ª´ text ƒë√£ l√†m s·∫°ch (kh√¥ng timeline)."""
        try:
            import re
            compact = re.sub(r"\s+", " ", text).strip()
            if not compact:
                return ""
            # T√°ch c√¢u theo d·∫•u k·∫øt th√∫c. H·ªó tr·ª£ ., !, ?, ‚Ä¶ v√† ...
            parts = re.split(r"(?<=[\.!\?‚Ä¶])\s+", compact)
            sentences = []
            for part in parts:
                p = part.strip()
                if p:
                    sentences.append(p)
                if len(sentences) >= max_sentences:
                    break
            return " ".join(sentences).strip()
        except Exception:
            return text.strip().split("\n")[0][:200]

    def _generate_lead_in_hook(self, text: str) -> str:
        """
        T·∫°o "C√¢u v√†o ƒë·ªÅ" h·∫•p d·∫´n d·ª±a tr√™n n·ªôi dung ch√≠nh (kh√¥ng d√πng c√¢u ƒë·∫ßu ti√™n).
        Nguy√™n t·∫Øc: ph√¢n t√≠ch n·ªôi dung th·ª±c t·∫ø v√† t·∫°o hook ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ c·ª• th·ªÉ.
        """
        try:
            import re
            # Chu·∫©n h√≥a v√† r√∫t g·ªçn vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung
            normalized = re.sub(r"[\n\r]", " ", text)
            normalized = re.sub(r"\s+", " ", normalized).strip()
            lower = normalized.lower()

            # Danh s√°ch stopwords ti·∫øng Vi·ªát
            stopwords = set([
                'l√†','v√†','c·ªßa','cho','c√°c','b√°c','em','anh','ch·ªã','nh√©','·∫°','th√¨','ƒë·ªÉ','v√¨',
                'khi','n√†y','ƒë√≥','n√™n','kh√¥ng','r·∫•t','nhi·ªÅu','m·ªôt','c√°i','ƒëi','l√†m','trong','ra',
                'v√†o','v·ªõi','ƒë∆∞·ª£c','ƒë·∫øn','n·∫øu','v·∫´n','hay','ƒë√£','s·∫Ω','c√≥','nh∆∞ng','v·∫≠y','th·∫ø','r·ªìi'
            ])

            # T√°ch t·ª´ v√† ph√¢n t√≠ch t·ª´ kh√≥a ch√≠nh
            tokens = re.findall(r"[a-zA-Z√Ä-·ªπ√Ä-·ª∏0-9_]+", lower)
            freq = {}
            for tok in tokens:
                if tok.isdigit():
                    continue
                if len(tok) < 4:
                    continue
                if tok in stopwords:
                    continue
                freq[tok] = freq.get(tok, 0) + 1

            # S·∫Øp x·∫øp t·ª´ kh√≥a theo t·∫ßn su·∫•t v√† ƒë·ªô d√†i
            sorted_keywords = sorted(freq.items(), key=lambda x: (-x[1], -len(x[0]), x[0]))
            top_keywords = [w for w, _ in sorted_keywords[:8]]  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ ph√¢n t√≠ch

            # Ph√¢n t√≠ch ch·ªß ƒë·ªÅ ch√≠nh d·ª±a tr√™n t·ª´ kh√≥a
            construction_words = {'x√¢y', 'nh√†', 'thi·∫øt', 'k·∫ø', 'c√¥ng', 'tr√¨nh', 'th·ª£', 'x√¢y d·ª±ng', 'ki·∫øn tr√∫c'}
            furniture_words = {'t·ªß', 'gi√†y', 'b√†n', 'gh·∫ø', 'sofa', 'gi∆∞·ªùng', 'k·ªá', 'n·ªôi th·∫•t'}
            space_words = {'kh√¥ng gian', 'ph√≤ng', 's·∫£nh', 'nh√† b·∫øp', 'ph√≤ng ng·ªß', 'ph√≤ng kh√°ch'}
            material_words = {'g·ªó', 's·∫Øt', 'th√©p', 'b√™ t√¥ng', 'g·∫°ch', 'xi mƒÉng', 's∆°n'}
            problem_words = {'toang', 'h·ªèng', 'l·ªói', 'sai', 'm·∫•t', 'thi·ªát', 'oan', 'tr·ªÖ', 'n·ª©t', 'r√≤', 'th·∫•m'}
            solution_words = {'b√≠', 'quy·∫øt', 'm·∫πo', 't·ªëi', '∆∞u', 'gi·∫£i', 'ph√°p', 'ti·∫øt', 'ki·ªám', 'hi·ªáu', 'qu·∫£'}

            # X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ ch√≠nh
            topic = "thi·∫øt k·∫ø"
            if any(w in construction_words for w in top_keywords):
                topic = "x√¢y d·ª±ng"
            elif any(w in furniture_words for w in top_keywords):
                topic = "n·ªôi th·∫•t"
            elif any(w in space_words for w in top_keywords):
                topic = "kh√¥ng gian"
            elif any(w in material_words for w in top_keywords):
                topic = "v·∫≠t li·ªáu"

            # Ki·ªÉm tra c√≥ v·∫•n ƒë·ªÅ/r·ªßi ro kh√¥ng
            has_problem = any(w in problem_words for w in top_keywords)
            has_solution = any(w in solution_words for w in top_keywords)

            # L·∫•y 2-3 t·ª´ kh√≥a ch√≠nh ƒë·ªÉ ƒë∆∞a v√†o hook
            main_keywords = top_keywords[:3] if len(top_keywords) >= 3 else top_keywords

            # T·∫°o hook d·ª±a tr√™n ch·ªß ƒë·ªÅ v√† t·ª´ kh√≥a th·ª±c t·∫ø
            if has_problem:
                # Hook c·∫£nh b√°o v·ªÅ v·∫•n ƒë·ªÅ
                kw1 = main_keywords[0] if main_keywords else 'chi ti·∫øt'
                kw2 = main_keywords[1] if len(main_keywords) > 1 else 'c√¥ng tr√¨nh'
                hook = f"ƒê·ª´ng ƒë·ªÉ {kw1} {kw2} l√†m h·ªèng c·∫£ d·ª± √°n. Xem ti·∫øp ƒë·ªÉ em h∆∞·ªõng d·∫´n b√°c c√°ch tr√°nh nh·ªØng l·ªói n√†y."
            elif has_solution:
                # Hook v·ªÅ gi·∫£i ph√°p/l·ª£i √≠ch
                kw1 = main_keywords[0] if main_keywords else 'thi·∫øt k·∫ø'
                kw2 = main_keywords[1] if len(main_keywords) > 1 else 'kh√¥ng gian'
                hook = f"B√≠ quy·∫øt {kw1} {kw2} m√† nhi·ªÅu b√°c hay b·ªè l·ª°. ·ªû ph·∫ßn sau, em chia s·∫ª t·ª´ng b∆∞·ªõc c·ª• th·ªÉ."
            elif topic == "x√¢y d·ª±ng":
                # Hook v·ªÅ x√¢y d·ª±ng
                kw1 = main_keywords[0] if main_keywords else 'c√¥ng tr√¨nh'
                hook = f"Nhi·ªÅu b√°c c·ª© nghƒ© {kw1} l√† chuy·ªán c·ªßa th·ª£, nh∆∞ng ƒë·∫øn khi c√≥ v·∫•n ƒë·ªÅ th√¨ m√¨nh m·ªõi l√† ng∆∞·ªùi s·ª≠a."
            elif topic == "n·ªôi th·∫•t":
                # Hook v·ªÅ n·ªôi th·∫•t
                kw1 = main_keywords[0] if main_keywords else 'thi·∫øt k·∫ø'
                hook = f"B√≠ quy·∫øt {kw1} kh√¥ng gian g·ªçn g√†ng m√† nhi·ªÅu b√°c hay b·ªè l·ª°. Xem ti·∫øp ƒë·ªÉ n·∫Øm chu·∫©n t·ª´ng b∆∞·ªõc."
            else:
                # Hook chung
                kw1 = main_keywords[0] if main_keywords else 'thi·∫øt k·∫ø'
                hook = f"ƒê·ª´ng b·ªè l·ª° {kw1} quan tr·ªçng n√†y. Xem ti·∫øp ƒë·ªÉ em h∆∞·ªõng d·∫´n b√°c c√°ch l√†m ƒë√∫ng ngay l·∫ßn ƒë·∫ßu."

            return hook
        except Exception:
            # Fallback an to√†n
            return "ƒê·ª´ng b·ªè l·ª° th√¥ng tin quan tr·ªçng n√†y. Xem ti·∫øp ƒë·ªÉ n·∫Øm chu·∫©n t·ª´ng b∆∞·ªõc."

    def _filter_forbidden_words(self, text: str) -> str:
        """
        Ki·ªÉm tra v√† thay th·∫ø c√°c t·ª´ c·∫•m trong n·ªôi dung
        
        Args:
            text: N·ªôi dung c·∫ßn ki·ªÉm tra
            
        Returns:
            N·ªôi dung ƒë√£ ƒë∆∞·ª£c l·ªçc t·ª´ c·∫•m
        """
        try:
            # Danh s√°ch t·ª´ c·∫•m v√† t·ª´ thay th·∫ø
            forbidden_words = {
                "m√°ch n∆∞·ªõc": ["chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω"],
                "hack": ["b√≠ quy·∫øt", "m·∫πo", "c√°ch", "ph∆∞∆°ng ph√°p"],
                "t·ª± h√†o": ["hi·ªán ƒë·∫°i", "ti√™n ti·∫øn", "t·ªëi ∆∞u"],
                "c·∫£ th·∫ø gi·ªõi": ["hi·ªáu qu·∫£", "chuy√™n nghi·ªáp"],
                "tuy·ªát v·ªùi": ["xu·∫•t s·∫Øc", "v∆∞·ª£t tr·ªôi"],
                "ƒë·ªôc ƒë√°o": ["ƒë·∫∑c bi·ªát", "n·ªïi b·∫≠t"]
            }
            
            # Thay th·∫ø t·ª´ng t·ª´ c·∫•m
            for forbidden_word, replacements in forbidden_words.items():
                if forbidden_word in text:
                    # Ch·ªçn t·ª´ thay th·∫ø ng·∫´u nhi√™n
                    import random
                    replacement = random.choice(replacements)
                    text = text.replace(forbidden_word, replacement)
                    logger.info(f"üîÑ ƒê√£ thay th·∫ø '{forbidden_word}' b·∫±ng '{replacement}'")
            
            return text
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói filter forbidden words: {str(e)}")
            return text

    def _format_main_content_only(self, text: str) -> str:
        """Format ch·ªâ n·ªôi dung ch√≠nh, lo·∫°i b·ªè timeline"""
        try:
            # Lo·∫°i b·ªè timeline patterns
            import re
            timeline_pattern = r'\(Gi√¢y\s+\d+-\d+\)'
            lines = text.split('\n')
            cleaned_lines = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # X·ª≠ l√Ω d√≤ng c√≥ timeline: ch·ªâ l·∫•y n·ªôi dung sau timeline
                if re.search(timeline_pattern, line):
                    match = re.search(timeline_pattern, line)
                    if match:
                        content_after_timeline = line[match.end():].strip()
                        if content_after_timeline:
                            cleaned_lines.append(content_after_timeline)
                else:
                    # N·∫øu kh√¥ng c√≥ timeline, gi·ªØ nguy√™n d√≤ng
                    if line and not line.startswith('[') and not line.startswith('**'):
                        cleaned_lines.append(line)
            
            # T√°ch t·ª´ng c√¢u ra sau d·∫•u ch·∫•m ƒë·ªÉ format tho√°ng h∆°n
            if cleaned_lines:
                # N·ªëi t·∫•t c·∫£ n·ªôi dung th√†nh m·ªôt chu·ªói
                full_content = ' '.join(cleaned_lines)
                
                # T√°ch th√†nh c√°c c√¢u d·ª±a tr√™n d·∫•u ch·∫•m
                sentences = []
                current_sentence = ""
                
                for char in full_content:
                    current_sentence += char
                    if char in ['.', '!', '?']:
                        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a v√† th√™m c√¢u v√†o danh s√°ch
                        sentence_clean = current_sentence.strip()
                        if sentence_clean:
                            sentences.append(sentence_clean)
                        current_sentence = ""
                
                # Th√™m c√¢u cu·ªëi n·∫øu c√≤n
                if current_sentence.strip():
                    sentences.append(current_sentence.strip())
                
                # N·ªëi c√°c c√¢u b·∫±ng xu·ªëng d√≤ng ƒë·ªÉ t·∫°o format tho√°ng
                return '\n'.join(sentences).strip()
            
            return text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói format main content: {str(e)}")
            return text
    
    def upload_to_drive(self, file_path: str, folder_id: str) -> str:
        """
        Upload file l√™n Google Drive
        
        Args:
            file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫ßn upload
            folder_id: ID c·ªßa folder tr√™n Google Drive
            
        Returns:
            ID c·ªßa file ƒë√£ upload tr√™n Google Drive
        """
        try:
            # X√°c ƒë·ªãnh MIME type d·ª±a tr√™n extension
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext == '.txt':
                mime_type = 'text/plain'
            elif file_ext == '.mp3':
                mime_type = 'audio/mpeg'
            else:
                mime_type = 'application/octet-stream'
            
            # Chu·∫©n b·ªã metadata cho file
            file_metadata = {
                'name': os.path.basename(file_path),
                'mimeType': mime_type,
                'parents': [folder_id]
            }
            
            # T·∫°o media upload object
            media = MediaFileUpload(file_path, mimetype=mime_type, resumable=True)
            
            logger.info(f"üîÑ ƒêang upload: {os.path.basename(file_path)}")
            
            # Upload file l√™n Google Drive
            file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id,name'
            ).execute()
            
            # L·∫•y th√¥ng tin file ƒë√£ upload
            file_id = file.get('id')
            file_name = file.get('name')
            logger.info(f"‚úÖ Upload th√†nh c√¥ng! File: {file_name}, ID: {file_id}")
            
            return file_id
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói upload: {str(e)}")
            raise
    
    def process_all(self, input_folder_id: str, voice_folder_id: str, 
                   text_original_folder_id: str, text_rewritten_folder_id: str, 
                   # text_to_speech_folder_id: str,  # ƒê√É COMMENT
                   video_name: str = "video1.mp4") -> Dict:
        """
        X·ª≠ l√Ω m·ªôt video: Video -> Voice Only -> Text -> Rewrite -> Drive (TTS ƒë√£ comment)
        
        Lu·ªìng x·ª≠ l√Ω ho√†n ch·ªânh:
        1. T√¨m video trong folder input
        2. T·∫£i video t·ª´ Google Drive
        3. T√°ch voice t·ª´ video (lo·∫°i b·ªè background music)
        4. Upload voice only l√™n Google Drive
        5. Chuy·ªÉn ƒë·ªïi voice th√†nh text b·∫±ng Deepgram
        6. Upload text g·ªëc l√™n Google Drive
        7. Vi·∫øt l·∫°i text b·∫±ng Gemini
        8. Upload text ƒë√£ vi·∫øt l·∫°i l√™n Google Drive
        
        Args:
            input_folder_id: ID folder ch·ª©a video input
            voice_folder_id: ID folder ƒë·ªÉ upload voice only
            text_original_folder_id: ID folder ƒë·ªÉ upload text g·ªëc
            text_rewritten_folder_id: ID folder ƒë·ªÉ upload text ƒë√£ vi·∫øt l·∫°i
            video_name: T√™n video c·∫ßn x·ª≠ l√Ω
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ x·ª≠ l√Ω
        """
        try:
            logger.info(f"üöÄ === B·∫ÆT ƒê·∫¶U X·ª¨ L√ù: {video_name} ===")
            
            # B∆∞·ªõc 1: T√¨m video trong folder input
            logger.info("üìÇ B∆∞·ªõc 1: T√¨m video trong folder...")
            video_info = self.find_video_in_folder(input_folder_id, video_name)
            if not video_info:
                return {
                    'status': 'error',
                    'video_name': video_name,
                    'error': f'Kh√¥ng t√¨m th·∫•y video {video_name}'
                }
            
            file_id = video_info['id']
            
            # B∆∞·ªõc 2: T·∫£i video t·ª´ Google Drive
            logger.info("üì• B∆∞·ªõc 2: T·∫£i video t·ª´ Google Drive...")
            video_path = self.download_video(file_id, video_name)
            
            # B∆∞·ªõc 3: T√°ch voice t·ª´ video (lo·∫°i b·ªè background music)
            logger.info("üé§ B∆∞·ªõc 3: T√°ch voice t·ª´ video...")
            voice_path = self.extract_voice_only(video_path, video_name)
            
            # B∆∞·ªõc 4: Upload voice only l√™n Google Drive
            logger.info("‚òÅÔ∏è B∆∞·ªõc 4: Upload voice only l√™n Google Drive...")
            voice_file_id = self.upload_to_drive(voice_path, voice_folder_id)
            
            # B∆∞·ªõc 5: Chuy·ªÉn ƒë·ªïi voice th√†nh text b·∫±ng Deepgram
            logger.info("üìù B∆∞·ªõc 5: Chuy·ªÉn ƒë·ªïi voice th√†nh text...")
            text_path, detected_language, is_chinese = self.extract_text_with_language_detection(voice_path, video_name)
            
            # B∆∞·ªõc 6: D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát n·∫øu c·∫ßn
            if is_chinese:
                logger.info("üåê B∆∞·ªõc 6: D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát...")
                translated_text_path = self.translate_chinese_to_vietnamese(text_path, video_name)
                text_path = translated_text_path # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n file text g·ªëc
            
            # B∆∞·ªõc 7: Upload text g·ªëc l√™n Google Drive
            logger.info("üìÑ B∆∞·ªõc 7: Upload text g·ªëc l√™n Google Drive...")
            text_file_id = self.upload_to_drive(text_path, text_original_folder_id)
            
            # B∆∞·ªõc 8: Vi·∫øt l·∫°i text b·∫±ng Gemini
            logger.info("‚úçÔ∏è B∆∞·ªõc 8: Vi·∫øt l·∫°i text b·∫±ng Gemini...")
            rewritten_text_path = self.rewrite_text(text_path, video_name)
            
            # B∆∞·ªõc 9: Upload text ƒë√£ vi·∫øt l·∫°i l√™n Google Drive
            logger.info("üìÑ B∆∞·ªõc 9: Upload text ƒë√£ vi·∫øt l·∫°i l√™n Google Drive...")
            rewritten_text_file_id = self.upload_to_drive(rewritten_text_path, text_rewritten_folder_id)
            
            # B∆∞·ªõc 10: T·∫°o n·ªôi dung ch√≠nh c√≥ timeline (cho c·ªôt Text c·∫£i ti·∫øn)
            logger.info("üìù B∆∞·ªõc 10: T·∫°o n·ªôi dung ch√≠nh c√≥ timeline...")
            main_content_path = self.create_main_content_only(rewritten_text_path, video_name)
            
            # B∆∞·ªõc 11: T·∫°o text kh√¥ng c√≥ timeline (cho c·ªôt Text no timeline)
            logger.info("üìÑ B∆∞·ªõc 11: T·∫°o text kh√¥ng c√≥ timeline...")
            text_no_timeline_path = self.create_text_without_timeline(rewritten_text_path, video_name)
            
            # B∆∞·ªõc 12: T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA (cho c·ªôt G·ª£i √Ω ti√™u ƒë·ªÅ)
            logger.info("üí° B∆∞·ªõc 12: T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA...")
            suggestions_path = self.create_suggestions_content(rewritten_text_path, video_name)
            
            # B∆∞·ªõc 11: Chuy·ªÉn ƒë·ªïi text ƒë√£ vi·∫øt l·∫°i th√†nh speech - ƒê√É COMMENT
            # logger.info("üé§ B∆∞·ªõc 11: Chuy·ªÉn ƒë·ªïi text th√†nh speech...")
            # tts_audio_path = self.text_to_speech(rewritten_text_path, video_name)
            
            # B∆∞·ªõc 12: Upload audio TTS l√™n Google Drive - ƒê√É COMMENT
            # logger.info("‚òÅÔ∏è B∆∞·ªõc 12: Upload audio TTS l√™n Google Drive...")
            # tts_file_id = self.upload_to_drive(tts_audio_path, text_to_speech_folder_id)
            
            logger.info("‚úÖ === HO√ÄN TH√ÄNH X·ª¨ L√ù ===")
            
            return {
                'status': 'success',
                'video_name': video_name,
                'video_file_id': file_id,  # Th√™m ID c·ªßa file video MP4
                'voice_file_id': voice_file_id,
                'text_file_id': text_file_id,
                'rewritten_text_file_id': rewritten_text_file_id,
                # 'tts_file_id': tts_file_id,  # ƒê√É COMMENT
                'voice_path': voice_path,
                'text_path': text_path,
                'rewritten_text_path': rewritten_text_path,
                'main_content_path': main_content_path,
                'text_no_timeline_path': text_no_timeline_path,
                'suggestions_path': suggestions_path,
                # 'tts_audio_path': tts_audio_path  # ƒê√É COMMENT
            }
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}")
            return {
                'status': 'error',
                'video_name': video_name,
                'error': str(e)
            }
    
    def process_all_videos(self, input_folder_id: str, voice_folder_id: str, 
                          text_original_folder_id: str, text_rewritten_folder_id: str,
                          # text_to_speech_folder_id: str  # ƒê√É COMMENT
                          ) -> List[Dict]:
        """
        X·ª≠ l√Ω t·∫•t c·∫£ video trong folder: Video -> Voice Only -> Text -> Rewrite -> Drive (TTS ƒë√£ comment)
        
        Args:
            input_folder_id: ID folder ch·ª©a video input
            voice_folder_id: ID folder ƒë·ªÉ upload voice only
            text_original_folder_id: ID folder ƒë·ªÉ upload text g·ªëc
            text_rewritten_folder_id: ID folder ƒë·ªÉ upload text ƒë√£ vi·∫øt l·∫°i
            
        Returns:
            List ch·ª©a k·∫øt qu·∫£ x·ª≠ l√Ω t·∫•t c·∫£ video
        """
        try:
            logger.info(f"üöÄ === B·∫ÆT ƒê·∫¶U X·ª¨ L√ù T·∫§T C·∫¢ VIDEO ===")
            
            # B∆Ø·ªöC M·ªöI: Check video status tr∆∞·ªõc khi x·ª≠ l√Ω
            logger.info("üîç B∆∞·ªõc 1: Ki·ªÉm tra tr·∫°ng th√°i video...")
            
            if self.video_checker is None:
                logger.warning("‚ö†Ô∏è VideoStatusChecker kh√¥ng kh·∫£ d·ª•ng, b·ªè qua ki·ªÉm tra tr·∫°ng th√°i")
                # T·∫°o video_status m·∫∑c ƒë·ªãnh ƒë·ªÉ ti·∫øp t·ª•c x·ª≠ l√Ω
                video_status = {
                    'videos_to_process': [{'name': 'video1.mp4', 'id': 'default_id'}],
                    'videos_skipped': [],
                    'total_drive_videos': 1,
                    'total_sheet_videos': 0,
                    'check_timestamp': '2025-08-13T10:00:00'
                }
            else:
                try:
                    video_status = self.video_checker.check_video_status(input_folder_id)
                    
                    # Hi·ªÉn th·ªã summary c·ªßa video checker
                    try:
                        summary = self.video_checker.get_check_summary(video_status)
                        logger.info(summary)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ hi·ªÉn th·ªã summary: {str(e)}")
                except Exception as e:
                    logger.error(f"‚ùå L·ªói ki·ªÉm tra tr·∫°ng th√°i video: {str(e)}")
                    # T·∫°o video_status m·∫∑c ƒë·ªãnh ƒë·ªÉ ti·∫øp t·ª•c x·ª≠ l√Ω
                    video_status = {
                        'videos_to_process': [{'name': 'video1.mp4', 'id': 'default_id'}],
                        'videos_skipped': [],
                        'total_drive_videos': 1,
                        'total_sheet_videos': 0,
                        'check_timestamp': '2025-08-13T10:00:00'
                    }
            
            if not video_status['videos_to_process']:
                logger.info("üéâ T·∫•t c·∫£ video ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω! Kh√¥ng c√≥ g√¨ ƒë·ªÉ l√†m.")
                return []
            
            # Ch·ªâ x·ª≠ l√Ω video m·ªõi
            videos_to_process = video_status['videos_to_process']
            logger.info(f" B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(videos_to_process)} video m·ªõi...")
            
            # Hi·ªÉn th·ªã danh s√°ch video s·∫Ω x·ª≠ l√Ω
            logger.info("üìã DANH S√ÅCH VIDEO S·∫º X·ª¨ L√ù:")
            for i, video in enumerate(videos_to_process, 1):
                logger.info(f"  {i}. {video['name']}")
            
            # B∆∞·ªõc 2: X·ª≠ l√Ω t·ª´ng video
            results = []
            total_videos = len(videos_to_process)
            
            for i, video_info in enumerate(videos_to_process, 1):
                video_name = video_info['name']
                file_id = video_info['id']
                
                logger.info(f"\nüé¨ === X·ª¨ L√ù VIDEO {i}/{total_videos}: {video_name} ===")
                
                # Delay gi·ªØa c√°c video ƒë·ªÉ tr√°nh rate limiting
                if i > 1:  # Kh√¥ng delay cho video ƒë·∫ßu ti√™n
                    logger.info(f"‚è≥ ƒê·ª£i {self.video_delay}s gi·ªØa c√°c video ƒë·ªÉ tr√°nh rate limiting...")
                    time.sleep(self.video_delay)
                
                try:
                    # T·∫£i video t·ª´ Google Drive
                    logger.info("üì• T·∫£i video t·ª´ Google Drive...")
                    video_path = self.download_video(file_id, video_name)
                    
                    # T√°ch voice t·ª´ video
                    logger.info("üé§ T√°ch voice t·ª´ video...")
                    voice_path = self.extract_voice_only(video_path, video_name)
                    
                    # Upload voice only
                    logger.info("‚òÅÔ∏è Upload voice only...")
                    voice_file_id = self.upload_to_drive(voice_path, voice_folder_id)
                    
                    # Chuy·ªÉn ƒë·ªïi voice th√†nh text
                    logger.info("üìù Chuy·ªÉn ƒë·ªïi voice th√†nh text...")
                    text_path, detected_language, is_chinese = self.extract_text_with_language_detection(voice_path, video_name)
                    
                    # D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát n·∫øu c·∫ßn
                    if is_chinese:
                        logger.info("üåê D·ªãch ti·∫øng Trung sang ti·∫øng Vi·ªát...")
                        translated_text_path = self.translate_chinese_to_vietnamese(text_path, video_name)
                        text_path = translated_text_path # C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n file text g·ªëc
                    
                    # Upload text g·ªëc
                    logger.info("üìÑ Upload text g·ªëc...")
                    text_file_id = self.upload_to_drive(text_path, text_original_folder_id)
                    
                    # Vi·∫øt l·∫°i text
                    logger.info("‚úçÔ∏è Vi·∫øt l·∫°i text...")
                    rewritten_text_path = self.rewrite_text(text_path, video_name)
                    
                    # Upload text ƒë√£ vi·∫øt l·∫°i
                    logger.info("üìÑ Upload text ƒë√£ vi·∫øt l·∫°i...")
                    rewritten_text_file_id = self.upload_to_drive(rewritten_text_path, text_rewritten_folder_id)
                    
                    # T·∫°o n·ªôi dung ch√≠nh c√≥ timeline (cho c·ªôt Text c·∫£i ti·∫øn)
                    logger.info("üìù T·∫°o n·ªôi dung ch√≠nh c√≥ timeline...")
                    main_content_path = self.create_main_content_only(rewritten_text_path, video_name)
                    
                    # T·∫°o text kh√¥ng c√≥ timeline (cho c·ªôt Text no timeline)
                    logger.info("üìÑ T·∫°o text kh√¥ng c√≥ timeline...")
                    text_no_timeline_path = self.create_text_without_timeline(rewritten_text_path, video_name)
                    
                    # T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA (cho c·ªôt G·ª£i √Ω ti√™u ƒë·ªÅ)
                    logger.info("üí° T·∫°o g·ª£i √Ω ti√™u ƒë·ªÅ, captions, CTA...")
                    suggestions_path = self.create_suggestions_content(rewritten_text_path, video_name)
                    
                    # Chuy·ªÉn ƒë·ªïi text th√†nh speech - ƒê√É COMMENT
                    # logger.info("üé§ Chuy·ªÉn ƒë·ªïi text th√†nh speech...")
                    # tts_audio_path = self.text_to_speech(rewritten_text_path, video_name)
                    
                    # Upload audio TTS - ƒê√É COMMENT
                    # logger.info("‚òÅÔ∏è Upload audio TTS...")
                    # tts_file_id = self.upload_to_drive(tts_audio_path, text_to_speech_folder_id)
                    
                    # Th√™m k·∫øt qu·∫£ th√†nh c√¥ng
                    results.append({
                        'status': 'success',
                        'video_name': video_name,
                        'video_file_id': file_id,  # Th√™m ID c·ªßa file video MP4
                        'voice_file_id': voice_file_id,
                        'text_file_id': text_file_id,
                        'rewritten_text_file_id': rewritten_text_file_id,
                        # 'tts_file_id': tts_file_id,  # ƒê√É COMMENT
                        'voice_path': voice_path,
                        'text_path': text_path,
                        'rewritten_text_path': rewritten_text_path,
                        'main_content_path': main_content_path,
                        'text_no_timeline_path': text_no_timeline_path,
                        'suggestions_path': suggestions_path,
                        # 'tts_audio_path': tts_audio_path  # ƒê√É COMMENT
                    })
                    
                    logger.info(f"‚úÖ Ho√†n th√†nh video {i}/{total_videos}: {video_name}")
                    
                except Exception as e:
                    logger.error(f"‚ùå L·ªói x·ª≠ l√Ω video {video_name}: {str(e)}")
                    results.append({
                        'status': 'error',
                        'video_name': video_name,
                        'error': str(e)
                    })
            
            logger.info(f"‚úÖ === HO√ÄN TH√ÄNH X·ª¨ L√ù T·∫§T C·∫¢ VIDEO ===")
            logger.info(f"üìä T·ªïng s·ªë video: {total_videos}")
            logger.info(f"‚úÖ Th√†nh c√¥ng: {len([r for r in results if r['status'] == 'success'])}")
            logger.info(f"‚ùå Th·∫•t b·∫°i: {len([r for r in results if r['status'] == 'error'])}")
            
            # B∆∞·ªõc cu·ªëi: C·∫≠p nh·∫≠t Google Sheets
            if results:
                logger.info("üìä B·∫Øt ƒë·∫ßu c·∫≠p nh·∫≠t Google Sheets...")
                sheets_success = self.update_sheets_with_results(results)
                if sheets_success:
                    logger.info("‚úÖ C·∫≠p nh·∫≠t Google Sheets ho√†n t·∫•t!")
                else:
                    logger.warning("‚ö†Ô∏è C·∫≠p nh·∫≠t Google Sheets th·∫•t b·∫°i")
            
            # Log API usage summary
            self._log_api_usage()
            
            # Log token usage summary (ƒë·∫£m b·∫£o lu√¥n hi·ªÉn th·ªã)
            try:
                self.token_calculator.log_summary()
                
                # Ki·ªÉm tra quota warnings
                warnings = self.token_calculator.get_quota_warnings()
                if warnings:
                    logger.warning("üö® QUOTA WARNINGS:")
                    for warning in warnings:
                        logger.warning(f"  {warning}")
                        
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ hi·ªÉn th·ªã token summary: {str(e)}")
                # Fallback: hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n
                logger.info("üìä TOKEN USAGE SUMMARY (Basic):")
                logger.info(f"  Total Operations: {len(self.token_calculator.token_usage)}")
                logger.info(f"  Total Cost: ${self.token_calculator.total_cost:.6f}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω t·∫•t c·∫£ video: {str(e)}")
            return []
    
    def get_next_empty_row(self) -> int:
        """
        L·∫•y s·ªë d√≤ng tr·ªëng ti·∫øp theo trong Google Sheets
        
        Returns:
            S·ªë d√≤ng tr·ªëng ti·∫øp theo (b·∫Øt ƒë·∫ßu t·ª´ 1)
        """
        try:
            # L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu trong sheet s·ª≠ d·ª•ng t√™n sheet
            # Th·ª≠ v·ªõi t√™n sheet kh√°c n·∫øu l·ªói
            range_name = f'{self.sheet_name}!A:A'
            
            try:
                result = self.sheets_service.spreadsheets().values().get(
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name
                ).execute()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói v·ªõi t√™n sheet '{self.sheet_name}', th·ª≠ v·ªõi t√™n kh√°c: {str(e)}")
                # Th·ª≠ v·ªõi t√™n sheet kh√°c
                alternative_names = ['mp3 to text', 'Mp3 to text', 'MP3 to text', 'Sheet1']
                for alt_name in alternative_names:
                    try:
                        range_name = f'{alt_name}!A:A'
                        result = self.sheets_service.spreadsheets().values().get(
                            spreadsheetId=self.spreadsheet_id,
                            range=range_name
                        ).execute()
                        logger.info(f"‚úÖ Th√†nh c√¥ng v·ªõi t√™n sheet: {alt_name}")
                        break
                    except Exception as e2:
                        logger.warning(f"‚ö†Ô∏è L·ªói v·ªõi t√™n sheet '{alt_name}': {str(e2)}")
                        continue
                else:
                    # N·∫øu t·∫•t c·∫£ ƒë·ªÅu l·ªói, raise exception
                    raise e
            
            values = result.get('values', [])
            
            # T√¨m d√≤ng tr·ªëng ƒë·∫ßu ti√™n (b·ªè qua header)
            for i, row in enumerate(values, 1):
                if not row or all(cell.strip() == '' for cell in row):
                    logger.info(f"‚úÖ D√≤ng tr·ªëng ti·∫øp theo: {i}")
                    return i
            
            # N·∫øu kh√¥ng c√≥ d√≤ng tr·ªëng, tr·∫£ v·ªÅ d√≤ng ti·∫øp theo
            next_row = len(values) + 1
            logger.info(f"‚úÖ D√≤ng tr·ªëng ti·∫øp theo: {next_row}")
            return next_row
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói l·∫•y d√≤ng tr·ªëng: {str(e)}")
            return 2  # M·∫∑c ƒë·ªãnh b·∫Øt ƒë·∫ßu t·ª´ d√≤ng 2 (sau header)
    
    def read_text_file_content(self, file_path: str) -> str:
        """
        ƒê·ªçc n·ªôi dung file text
        
        Args:
            file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file text
            
        Returns:
            N·ªôi dung file text
        """
        try:
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                return content
            else:
                return "File kh√¥ng t·ªìn t·∫°i"
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒë·ªçc file text: {str(e)}")
            return f"L·ªói ƒë·ªçc file: {str(e)}"
    
    def update_sheets_with_results(self, results: List[Dict]) -> bool:
        """
        C·∫≠p nh·∫≠t Google Sheets v·ªõi k·∫øt qu·∫£ x·ª≠ l√Ω
        
        Args:
            results: Danh s√°ch k·∫øt qu·∫£ x·ª≠ l√Ω video
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu th·∫•t b·∫°i
        """
        try:
            logger.info("üìä B·∫Øt ƒë·∫ßu c·∫≠p nh·∫≠t Google Sheets...")
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t
            update_data = []
            
            for result in results:
                if result['status'] == 'success':
                    # L·∫•y th√¥ng tin file
                    video_name = result['video_name']
                    video_file_id = result['video_file_id']  # Th√™m ID c·ªßa file video MP4
                    voice_file_id = result['voice_file_id']
                    text_file_id = result['text_file_id']
                    rewritten_text_file_id = result['rewritten_text_file_id']
                    # tts_file_id = result.get('tts_file_id', '')  # ƒê√É COMMENT
                    
                    # T·∫°o link Google Drive
                    video_link = f"https://drive.google.com/file/d/{video_file_id}/view"  # Link MP4
                    voice_link = f"https://drive.google.com/file/d/{voice_file_id}/view"
                    text_link = f"https://drive.google.com/file/d/{text_file_id}/view"
                    rewritten_link = f"https://drive.google.com/file/d/{rewritten_text_file_id}/view"
                    # tts_link = f"https://drive.google.com/file/d/{tts_file_id}/view" if tts_file_id else ""  # ƒê√É COMMENT
                    
                    # ƒê·ªçc n·ªôi dung text
                    original_text = self.read_text_file_content(result['text_path'])
                    
                    # ƒê·ªçc n·ªôi dung text c·∫£i ti·∫øn (ch·ªâ n·ªôi dung ch√≠nh c√≥ timeline)
                    rewritten_text = ""
                    if 'main_content_path' in result:
                        rewritten_text = self.read_text_file_content(result['main_content_path'])
                    else:
                        # Fallback cho format c≈©
                        rewritten_text = self.read_text_file_content(result['rewritten_text_path'])
                    
                    # L·∫•y t√™n video t·ª´ file MP4 (lo·∫°i b·ªè ph·∫ßn m·ªü r·ªông)
                    video_name_clean = os.path.splitext(video_name)[0]
                    
                    # ƒê·ªçc n·ªôi dung text kh√¥ng timeline
                    text_no_timeline = ""
                    if 'text_no_timeline_path' in result:
                        text_no_timeline = self.read_text_file_content(result['text_no_timeline_path'])
                    
                    # ƒê·ªçc n·ªôi dung g·ª£i √Ω ti√™u ƒë·ªÅ
                    suggestions_content = ""
                    if 'suggestions_path' in result:
                        suggestions_content = self.read_text_file_content(result['suggestions_path'])
                    
                    # Th√™m d·ªØ li·ªáu v√†o danh s√°ch c·∫≠p nh·∫≠t
                    update_data.append([
                        video_link,           # Link mp4 (c·ªôt A)
                        video_name_clean,     # T√™n Video (t·ª´ file MP4) (c·ªôt B)
                        voice_link,           # Link MP3 (c·ªôt C)
                        text_link,            # Link text g·ªëc (c·ªôt D)
                        original_text,        # Text g·ªëc MP3 (c·ªôt E)
                        rewritten_link,       # Link text c·∫£i ti·∫øn (c·ªôt F)
                        rewritten_text,       # Text c·∫£i ti·∫øn (c·ªôt G)
                        text_no_timeline,     # Text no timeline (ch·ªâ n·ªôi dung ch√≠nh) (c·ªôt H)
                        suggestions_content   # G·ª£i √Ω ti√™u ƒë·ªÅ (ti√™u ƒë·ªÅ + captions + CTA) (c·ªôt I)
                        # tts_link              # Link text to speech - ƒê√É COMMENT
                    ])
                    
                    logger.info(f"üìù ƒê√£ chu·∫©n b·ªã d·ªØ li·ªáu cho video: {video_name}")
            
            if not update_data:
                logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ c·∫≠p nh·∫≠t")
                return False
            
            # L·∫•y d√≤ng tr·ªëng ti·∫øp theo
            next_row = self.get_next_empty_row()
            range_name = f'{self.sheet_name}!A{next_row}:I{next_row + len(update_data) - 1}'  # A-I: Link mp4, T√™n Video, Link MP3, Link text g·ªëc, Text g·ªëc, Link text c·∫£i ti·∫øn, Text c·∫£i ti·∫øn, Text no timeline, G·ª£i √Ω ti√™u ƒë·ªÅ
            
            # C·∫≠p nh·∫≠t Google Sheets
            body = {
                'values': update_data
            }
            
            try:
                result = self.sheets_service.spreadsheets().values().update(
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name,
                    valueInputOption='RAW',
                    body=body
                ).execute()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói update v·ªõi t√™n sheet '{self.sheet_name}', th·ª≠ v·ªõi t√™n kh√°c: {str(e)}")
                # Th·ª≠ v·ªõi t√™n sheet kh√°c
                alternative_names = ['mp3 to text', 'Mp3 to text', 'MP3 to text', 'Sheet1']
                for alt_name in alternative_names:
                    try:
                        range_name = f'{alt_name}!A{next_row}:I{next_row + len(update_data) - 1}'
                        result = self.sheets_service.spreadsheets().values().update(
                            spreadsheetId=self.spreadsheet_id,
                            range=range_name,
                            valueInputOption='RAW',
                            body=body
                        ).execute()
                        logger.info(f"‚úÖ Update th√†nh c√¥ng v·ªõi t√™n sheet: {alt_name}")
                        break
                    except Exception as e2:
                        logger.warning(f"‚ö†Ô∏è L·ªói update v·ªõi t√™n sheet '{alt_name}': {str(e2)}")
                        continue
                else:
                    # N·∫øu t·∫•t c·∫£ ƒë·ªÅu l·ªói, raise exception
                    raise e
            
            updated_cells = result.get('updatedCells', 0)
            logger.info(f"‚úÖ C·∫≠p nh·∫≠t Google Sheets th√†nh c√¥ng!")
            logger.info(f"üìä ƒê√£ c·∫≠p nh·∫≠t {updated_cells} √¥")
            logger.info(f"üìÑ D√≤ng b·∫Øt ƒë·∫ßu: {next_row}")
            logger.info(f"üìÑ D√≤ng k·∫øt th√∫c: {next_row + len(update_data) - 1}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói c·∫≠p nh·∫≠t Google Sheets: {str(e)}")
            return False
    
    def _generate_lead_sentence(self, content: str) -> str:
        """
        T·∫°o c√¢u d·∫´n hay d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø c·ªßa video
        
        Args:
            content: N·ªôi dung ch√≠nh c·ªßa video
            
        Returns:
            C√¢u d·∫´n hay, c√≥ √Ω nghƒ©a, d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø
        """
        try:
            # T·∫°o prompt ƒë·ªÉ AI hi·ªÉu c√°ch t·∫°o c√¢u d·∫´n
            prompt = f"""
            D·ª±a v√†o n·ªôi dung video sau, h√£y vi·∫øt 1 c√¢u d·∫´n ng·∫Øn g·ªçn, ƒë·∫∑c s·∫Øc ƒë·ªÉ d·∫´n v√†o ch·ªß ƒë·ªÅ n·ªôi dung.
            
            **Y√äU C·∫¶U:**
            - C√¢u d·∫´n ph·∫£i d·ª±a tr√™n n·ªôi dung th·ª±c t·∫ø c·ªßa video
            - Kh√¥ng copy v√≠ d·ª•, ph·∫£i vi·∫øt m·ªõi d·ª±a tr√™n n·ªôi dung
            - **NG·∫ÆN G·ªåN:** Ch·ªâ 1 c√¢u, t·ªëi ƒëa 15-20 t·ª´
            - **KH√îNG X∆ØNG H√î:** Kh√¥ng d√πng "b√°c", "em", "t√¥i", "m√¨nh", "c√°c b√°c", "b·∫°n"
            - **GI·ªåNG KH√ÅCH QUAN:** Mi√™u t·∫£ tr·ª±c ti·∫øp, kh√¥ng c√≥ ng√¥i th·ª© nh·∫•t hay th·ª© hai
            - **ƒê·∫∂C S·∫ÆC:** S·ª≠ d·ª•ng t·ª´ ng·ªØ m·∫°nh m·∫Ω, g√¢y ·∫•n t∆∞·ª£ng
            - **G√ÇY T√í M√í:** T·∫°o s·ª± th√≠ch th√∫ v·ªÅ gi·∫£i ph√°p video s·∫Ω cung c·∫•p
            - **NH·∫§N M·∫†NH:** D√πng t·ª´ ng·ªØ nh·∫•n m·∫°nh v·∫•n ƒë·ªÅ v√† gi·∫£i ph√°p
            - Kh√¥ng d√πng t·ª´ su·ªìng s√£ nh∆∞ "Alo alo", "Yo", "qu·∫©y", "ph√° ƒë·∫£o"
            - **T·ª™ C·∫§M:** Kh√¥ng d√πng "m√°ch n∆∞·ªõc", "hack", "t·ª± h√†o", "c·∫£ th·∫ø gi·ªõi", "tuy·ªát v·ªùi", "ƒë·ªôc ƒë√°o"
            - **T·ª™ THAY TH·∫æ:** D√πng "chia s·∫ª", "h∆∞·ªõng d·∫´n", "g·ª£i √Ω", "b√≠ quy·∫øt", "m·∫πo", "c√°ch"
            
            **N·ªòI DUNG VIDEO:**
            {content[:500]}...
            
            **V√ç D·ª§ C√ÇU D·∫™N ƒê·∫∂C S·∫ÆC:**
            "T·ªß qu·∫ßn √°o l·ªôn x·ªôn ƒëang 'b√≥p ngh·∫πt' kh√¥ng gian s·ªëng. Gi·∫£i ph√°p n√†y s·∫Ω thay ƒë·ªïi m·ªçi th·ª©."
            
            **C√ÅCH K·∫æT H·ª¢P M·∫™U V·ªöI N·ªòI DUNG:**
            - **PH√ÇN T√çCH N·ªòI DUNG:** ƒê·ªçc k·ªπ n·ªôi dung video ƒë·ªÉ hi·ªÉu ch·ªß ƒë·ªÅ ch√≠nh
            - **CH·ªåN M·∫™U PH√ô H·ª¢P:** D·ª±a v√†o ch·ªß ƒë·ªÅ ƒë·ªÉ ch·ªçn m·∫´u c√¢u d·∫´n t∆∞∆°ng ·ª©ng
            - **ƒêI·ªÄU CH·ªàNH THEO N·ªòI DUNG:** Thay ƒë·ªïi t·ª´ ng·ªØ trong m·∫´u ƒë·ªÉ ph√π h·ª£p v·ªõi n·ªôi dung c·ª• th·ªÉ
            - **GI·ªÆ NGUY√äN PHONG C√ÅCH:** Duy tr√¨ gi·ªçng ƒëi·ªáu, c·∫•u tr√∫c v√† s·ª©c m·∫°nh c·ªßa m·∫´u g·ªëc
            
            **C√ÅC M·∫™U C√ÇU D·∫™N HAY ƒê·ªÇ THAM KH·∫¢O:**
            1. **M·∫´u v·ªÅ v·∫•n ƒë·ªÅ b·ªè qua:** "M·∫•y vi·ªác d∆∞·ªõi ƒë√¢y, nhi·ªÅu nh√† b·ªè qua t·ª´ ƒë·∫ßu ‚Üí sau ph·∫£i 'b√π kh·∫©n c·∫•p', gi√° ƒë·ªôi l√™n g·∫•p v√†i l·∫ßn lu√¥n ƒë√≥!"
            2. **M·∫´u v·ªÅ thi·∫øt k·∫ø ƒë·∫∑c bi·ªát:** "N√†o n√†o, m·ªùi xem th·ª≠ thi·∫øt k·∫ø sau k·ªá TV c√≥ g√¨ ƒë·∫∑c bi·ªát nh√©! Nh√¨n ngo√†i th√¨ t∆∞·ªüng ƒë∆°n gi·∫£n, nh∆∞ng b√™n trong l·∫°i l√† c·∫£ m·ªôt b√≠ m·∫≠t 'ƒë√°ng ti·ªÅn' ƒë·∫•y!"
            3. **M·∫´u v·ªÅ quy tr√¨nh:** "X√¢y nh√† ch∆∞a bao gi·ªù l√† chuy·ªán d·ªÖ. Kh√¥ng thi·∫øu ng∆∞·ªùi l√†m xong r·ªìi m·ªõi ng·ªìi ti·∫øc: 'Bi·∫øt th·∫ø‚Ä¶'. V·∫≠y n√™n t·ªïng h·ª£p l·∫°i 23 b∆∞·ªõc ho√†n thi·ªán nh√†, theo tr√¨nh t·ª± logic!"
            4. **M·∫´u v·ªÅ chia s·∫ª kinh nghi·ªám:** "H√¥m nay chia r√µ mua g√¨ online ƒë∆∞·ª£c ‚Äì v√† kh√¥ng n√™n mua g√¨ online khi l√†m n·ªôi th·∫•t!"
            5. **M·∫´u v·ªÅ sai l·∫ßm ph·ªï bi·∫øn:** "Nhi·ªÅu ng∆∞·ªùi c·ª© b·∫£o 'ƒë·ªÉ th·ª£ lo', nh∆∞ng l√∫c h·ªèng th√¨ m√¨nh m·ªõi l√† ng∆∞·ªùi s·ª≠a. V·∫≠y n√™n x√¢y nh√† ph·∫£i d·∫∑n k·ªπ ‚Äì d·∫∑n t·ª´ng ch√∫t m·ªôt!"
            6. **M·∫´u v·ªÅ khu v·ª±c kh√≥:** "B·∫øp l√† khu v·ª±c kh√≥ x·ª≠ l√Ω nh·∫•t trong c·∫£ qu√° tr√¨nh l√†m nh√† ‚Äì ch·ªâ c·∫ßn sai 1 b∆∞·ªõc nh·ªè l√† ·∫£nh h∆∞·ªüng ƒë·∫øn c·∫£ ch·ª•c nƒÉm s·ª≠ d·ª•ng!"
            7. **M·∫´u v·ªÅ chi ti·∫øt quan tr·ªçng:** "Khi nh√† ƒëang trong giai ƒëo·∫°n thi c√¥ng, ƒë√¢y ch√≠nh l√† l√∫c ph·∫£i ƒë·ªÉ √Ω k·ªπ m·∫•y con s·ªë nh·ªè nh·ªè m√† c·ª±c k·ª≥ quan tr·ªçng n√†y!"
            8. **M·∫´u v·ªÅ quan ni·ªám sai:** "L·∫ßn ƒë·∫ßu l√†m n·ªôi th·∫•t, nhi·ªÅu ng∆∞·ªùi hay nghƒ©: ph√≤ng ng·ªß ph·∫£i th·∫≠t ƒë·∫πp, th·∫≠t ·∫•n t∆∞·ª£ng. Nh∆∞ng th·ª±c ra, ƒë√¢y l√† n∆°i ngh·ªâ ng∆°i m·ªói ng√†y ‚Äì ch·ªâ c·∫ßn y√™n tƒ©nh, d·ªãu m·∫Øt v√† d·ªÖ ch·ªãu l√† ƒë√£ ƒë√∫ng b√†i r·ªìi!"
            9. **M·∫´u v·ªÅ c√¢u h·ªèi ph·ªï bi·∫øn:** "N√≥i th·∫≠t, 90% ng∆∞·ªùi l√†m nh√† h·ªèi v·ªÅ c·ª≠a ph√≤ng ng·ªß th√¨ c√¢u ƒë·∫ßu ti√™n ƒë·ªÅu l√†: 'Ch·ªçn m√†u g√¨ ƒë·∫πp?' M√† n·∫øu ch·ªâ quan t√¢m ƒë·∫øn m√†u, th√¨ xem xong c√¢u ƒë·∫ßu l√† d·ª´ng c≈©ng ƒë∆∞·ª£c r·ªìi ƒë√≥!"
            10. **M·∫´u v·ªÅ k·∫øt qu·∫£ l√¢u d√†i:** "Ph√≤ng kh√°ch n√†y sau khi ho√†n thi·ªán, d√°m ch·∫Øc 3‚Äì5 nƒÉm t·ªõi nh√¨n v·∫´n th·∫•y ƒë·∫πp, v·∫´n th·∫•y sang!"
            11. **M·∫´u v·ªÅ gi·∫£i ph√°p to√†n di·ªán:** "N·∫øu mu·ªën ·ªü cho ti·ªán ‚Äì s·∫°ch ‚Äì l√¢u b·ªÅn, th√¨ d√π thu√™ thi·∫øt k·∫ø hay t·ª± l√†m th√¨ c√πng n√™n l∆∞u √Ω l√†m theo m·∫•y ƒëi·ªÉm n√†y, ƒë·∫£m b·∫£o: b·∫øp nh·ªè c≈©ng h√≥a r·ªông ‚Äì ·ªü l√¢u kh√¥ng th·∫•y phi·ªÅn!"
            12. **M·∫´u v·ªÅ sai l·∫ßm thi·∫øt k·∫ø:** "Khi l√†m t·ªß qu·∫ßn √°o, r·∫•t nhi·ªÅu nh√† ch·ªâ quan t√¢m m·ªói... ch·ªçn m√†u n√†o cho ƒë·∫πp! C√≤n k√≠ch th∆∞·ªõc ‚Äì b·ªë c·ª•c ‚Äì ti·ªán d·ª•ng b√™n trong, th√¨ giao h·∫øt cho b√™n thi·∫øt k·∫ø. Nh∆∞ng th·ª±c t·∫ø: s√¢u sai 1cm ‚Äì m·ªói l·∫ßn ƒë√≥ng m·ªü l√† th·∫•y b·ª±c!"
            13. **M·∫´u v·ªÅ b√≠ m·∫≠t k·ªπ thu·∫≠t:** "Mua t·ªß lavabo cho ph√≤ng t·∫Øm, nhi·ªÅu ng∆∞·ªùi ch·ªâ nh√¨n m·∫∑t ƒë√°, m√†u hay ki·ªÉu d√°ng. Nh∆∞ng th·ª±c t·∫ø: x√†i s∆∞·ªõng hay kh√¥ng n·∫±m ·ªü ph·∫ßn thi·∫øt k·∫ø ‚Äì k·ªπ thu·∫≠t b√™n trong!"
            14. **M·∫´u v·ªÅ v·∫•n ƒë·ªÅ th·ª±c t·∫ø:** "Khi c·ª≠a nh√† v·ªá sinh n·∫±m ngay cu·ªëi h√†nh lang, n∆∞·ªõc tr√†n ra ngo√†i l√† chuy·ªán c·ª±c k·ª≥ ph·ªï bi·∫øn. ·ªû ƒë∆∞·ª£c v√†i nƒÉm th√¨ t∆∞·ªùng b·∫Øt ƒë·∫ßu ·ªë v√†ng, bong tr√≥c, m·ª•c n√°t ‚Äì l√∫c ƒë√≥ s·ª≠a c≈©ng ch·∫≥ng d·ªÖ n·ªØa..."
            15. **M·∫´u v·ªÅ tri·∫øt l√Ω s·ªëng:** "Nh√† l√† ƒë·ªÉ ·ªü ‚Äì kh√¥ng ph·∫£i ƒë·ªÉ tr∆∞ng b√†y, c√†ng kh√¥ng ph·∫£i ƒë·ªÉ so ƒëo v·ªõi thi√™n h·∫°. Nhi·ªÅu ng∆∞·ªùi c·ª© nghƒ©: l√†m c√†ng nhi·ªÅu ‚Äì nh√† c√†ng ƒë·∫πp, nh∆∞ng s·ª± th·∫≠t th√¨ nh√† c√†ng ƒë∆°n gi·∫£n ‚Äì c√†ng d·ªÖ ·ªü ‚Äì c√†ng b·ªÅn ƒë·∫πp l√¢u."
            16. **M·∫´u v·ªÅ gi√° tr·ªã s√¢u s·∫Øc:** "Nh√† kh√¥ng ch·ªâ ƒë·ªÉ ·ªü ‚Äì m√† l√† n∆°i h·ªìi ph·ª•c nƒÉng l∆∞·ª£ng m·ªói ng√†y. Nh·ªØng cƒÉn nh√† th·ª±c s·ª± 'd∆∞·ª°ng ng∆∞·ªùi', ai s·ªëng trong ƒë√≥ kh√≠ s·∫Øc ƒë·ªÅu kh√°c bi·ªát, th∆∞·ªùng c√≥ 4 ƒëi·ªÉm gi·ªëng nhau ƒë·∫øn k·ª≥ l·∫°..."
            
            **QUY TR√åNH T·∫†O C√ÇU D·∫™N:**
            1. **ƒê·ªåC N·ªòI DUNG:** Ph√¢n t√≠ch ch·ªß ƒë·ªÅ ch√≠nh c·ªßa video
            2. **CH·ªåN M·∫™U:** Ch·ªçn m·∫´u c√¢u d·∫´n ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ
            3. **ƒêI·ªÄU CH·ªàNH:** Thay ƒë·ªïi t·ª´ ng·ªØ trong m·∫´u ƒë·ªÉ ph√π h·ª£p v·ªõi n·ªôi dung c·ª• th·ªÉ
            4. **GI·ªÆ PHONG C√ÅCH:** Duy tr√¨ gi·ªçng ƒëi·ªáu v√† s·ª©c m·∫°nh c·ªßa m·∫´u g·ªëc
            5. **S·ª¨ D·ª§NG T·ª™ M·∫†NH:** √Åp d·ª•ng c√°c t·ª´ ng·ªØ m·∫°nh m·∫Ω t·ª´ m·∫´u nh∆∞ "b√≥p ngh·∫πt", "ƒë√°ng ti·ªÅn", "kh√≥ x·ª≠ l√Ω", "quan tr·ªçng", "sai l·∫ßm", "th·ª±c t·∫ø", "b√≠ m·∫≠t"
            
            **V√ç D·ª§ K·∫æT H·ª¢P:**
            - **N·ªôi dung:** T·ªß qu·∫ßn √°o l·ªôn x·ªôn ‚Üí **Ch·ªçn m·∫´u 12** (sai l·∫ßm thi·∫øt k·∫ø)
            - **ƒêi·ªÅu ch·ªânh:** "Khi s·∫Øp x·∫øp t·ªß qu·∫ßn √°o, r·∫•t nhi·ªÅu nh√† ch·ªâ quan t√¢m m·ªói... ch·ªçn m√†u n√†o cho ƒë·∫πp! C√≤n khoa h·ªçc ‚Äì b·ªë c·ª•c ‚Äì ti·ªán d·ª•ng b√™n trong, th√¨ b·ªè qua ho√†n to√†n. Nh∆∞ng th·ª±c t·∫ø: s·∫Øp x·∫øp sai 1 b∆∞·ªõc ‚Äì m·ªói l·∫ßn t√¨m ƒë·ªì l√† th·∫•y b·ª±c!"
            
            **T·ª™ NG·ªÆ M·∫†NH M·∫º C·∫¶N S·ª¨ D·ª§NG:**
            - "b√≥p ngh·∫πt", "nu·ªët ch·ª≠ng", "ƒë√® n√©n" (cho v·∫•n ƒë·ªÅ)
            - "ƒë√°ng ti·ªÅn", "qu√Ω gi√°", "tuy·ªát v·ªùi" (cho gi√° tr·ªã)
            - "kh√≥ x·ª≠ l√Ω", "ph·ª©c t·∫°p", "th√°ch th·ª©c" (cho kh√≥ khƒÉn)
            - "quan tr·ªçng", "thi·∫øt y·∫øu", "c·ªët l√µi" (cho t·∫ßm quan tr·ªçng)
            - "sai l·∫ßm", "th·∫•t b·∫°i", "h·∫≠u qu·∫£" (cho v·∫•n ƒë·ªÅ)
            - "th·ª±c t·∫ø", "s·ª± th·∫≠t", "th·ª±c ch·∫•t" (cho ch√¢n l√Ω)
            - "b√≠ m·∫≠t", "b√≠ quy·∫øt", "m·∫πo" (cho gi·∫£i ph√°p)
            
            **FORMAT C√ÇU D·∫™N:**
            - Th√™m ti√™u ƒë·ªÅ "D·∫´n v√†o n·ªôi dung:" ·ªü ƒë·∫ßu
            - C√≥ kho·∫£ng c√°ch d∆∞·ªõi c√¢u d·∫´n ƒë·ªÉ kh√¥ng s√°t v·ªõi n·ªôi dung ch√≠nh
            - C√¢u d·∫´n ng·∫Øn g·ªçn, ƒë·∫∑c s·∫Øc, g√¢y t√≤ m√≤
            
            **L∆ØU √ù:** Tr·∫£ v·ªÅ theo format: "D·∫´n v√†o n·ªôi dung: [c√¢u d·∫´n]\n\n"
            """
            
            # G·ªçi Gemini API ƒë·ªÉ t·∫°o c√¢u d·∫´n
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.gemini_api_key}"
            
            headers = {
                'Content-Type': 'application/json',
            }
            
            data = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "maxOutputTokens": 100,
                    "temperature": 0.7
                }
            }
            
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                response_text = result['candidates'][0]['content']['parts'][0]['text']
            else:
                response_text = ""
            
            if response_text and response_text.strip():
                # L√†m s·∫°ch response
                lead_sentence = response_text.strip()
                # Lo·∫°i b·ªè d·∫•u ngo·∫∑c k√©p n·∫øu c√≥
                if lead_sentence.startswith('"') and lead_sentence.endswith('"'):
                    lead_sentence = lead_sentence[1:-1]
                
                # Ki·ªÉm tra xem c√≥ format "D·∫´n v√†o n·ªôi dung:" kh√¥ng
                if lead_sentence.startswith("D·∫´n v√†o n·ªôi dung:"):
                    # Gi·ªØ nguy√™n format ƒë√£ c√≥
                    logger.info(f"‚úÖ ƒê√£ t·∫°o c√¢u d·∫´n v·ªõi format: {lead_sentence[:100]}...")
                    return lead_sentence
                else:
                    # Th√™m format n·∫øu ch∆∞a c√≥
                    formatted_lead = f"D·∫´n v√†o n·ªôi dung: {lead_sentence}\n\n"
                    logger.info(f"‚úÖ ƒê√£ t·∫°o c√¢u d·∫´n: {formatted_lead[:100]}...")
                    return formatted_lead
            
            return ""
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói t·∫°o c√¢u d·∫´n: {str(e)}")
            return ""

    def cleanup(self):
        """
        D·ªçn d·∫πp file t·∫°m sau khi x·ª≠ l√Ω xong
        
        X√≥a th∆∞ m·ª•c t·∫°m v√† t·∫•t c·∫£ file trong ƒë√≥ ƒë·ªÉ ti·∫øt ki·ªám dung l∆∞·ª£ng
        """
        if self.temp_dir and os.path.exists(self.temp_dir):
            try:
                shutil.rmtree(self.temp_dir)
                logger.info("‚úÖ ƒê√£ d·ªçn d·∫πp file t·∫°m")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ d·ªçn d·∫πp file t·∫°m: {str(e)}")


def main():
    """
    H√†m ch√≠nh - Entry point c·ªßa ·ª©ng d·ª•ng
    
    Ch·ª©c nƒÉng:
    - C·∫•u h√¨nh c√°c folder IDs
    - Kh·ªüi t·∫°o processor
    - Ch·∫°y to√†n b·ªô workflow v·ªõi h·ªó tr·ª£ ti·∫øng Trung (TTS ƒë√£ comment)
    - Hi·ªÉn th·ªã k·∫øt qu·∫£
    """
    print("üöÄ === All-in-One: MP4 -> Voice Only -> Text (VI/CN) -> Translate -> Rewrite -> Drive ===")
    print("=" * 80)

    # C·∫§U H√åNH T·∫†I ƒê√ÇY - Thay ƒë·ªïi c√°c gi√° tr·ªã b√™n d∆∞·ªõi
    # ===================================================
    
    # ID c·ªßa folder ch·ª©a video (input) - Thay ƒë·ªïi n·∫øu c·∫ßn
    INPUT_FOLDER_ID = "17_ncdjiRI2K4c4OA-sp3Uyi4bskP0CIu"
    # INPUT_FOLDER_ID = "1scX8WQAPMw3zEojFFMlKZd3PmQ2sBsaF"

    
    # ID c·ªßa folder ƒë·ªÉ upload voice only - Thay ƒë·ªïi n·∫øu c·∫ßn
    VOICE_ONLY_FOLDER_ID = "1FUP92ha2uaxPmB3a680eOd7TAqH1SqGT"  # S·ª≠ d·ª•ng folder MP3 c≈© cho voice
    
    # ID c·ªßa folder ƒë·ªÉ upload text g·ªëc - Thay ƒë·ªïi n·∫øu c·∫ßn
    TEXT_ORIGINAL_FOLDER_ID = "1ZswATID5nLDRjap6yvDJYaa435Nrp8eo"
    
    # ID c·ªßa folder ƒë·ªÉ upload text ƒë√£ vi·∫øt l·∫°i - Thay ƒë·ªïi n·∫øu c·∫ßn
    TEXT_REWRITTEN_FOLDER_ID = "18XIdyGd-9ahPLHElJBBwXeATgcFanoQR"
    
    # ID c·ªßa folder ƒë·ªÉ upload text to speech - Thay ƒë·ªïi n·∫øu c·∫ßn - ƒê√É COMMENT
    # TEXT_TO_SPEECH_FOLDER_ID = "1UZkeCdbUk4CGQjwsnYKQ0dNm6g-2bt70"
    
    # T√™n video c·∫ßn x·ª≠ l√Ω - Thay ƒë·ªïi n·∫øu c·∫ßn
    VIDEO_NAME = "video1.mp4"
    
    # ===================================================

    try:
        # Kh·ªüi t·∫°o processor
        print("üîß ƒêang kh·ªüi t·∫°o processor...")
        processor = AllInOneProcessor()

        # Hi·ªÉn th·ªã th√¥ng tin c·∫•u h√¨nh
        print(f"\nüìã TH√îNG TIN C·∫§U H√åNH:")
        print(f"üé¨ Video: {VIDEO_NAME}")
        print(f"üìÅ Input folder: {INPUT_FOLDER_ID}")
        print(f"üé§ Voice only folder: {VOICE_ONLY_FOLDER_ID}")
        print(f"üìÑ Text original folder: {TEXT_ORIGINAL_FOLDER_ID}")
        print(f"‚úçÔ∏è Text rewritten folder: {TEXT_REWRITTEN_FOLDER_ID}")
        # print(f"üé§ Text to speech folder: {TEXT_TO_SPEECH_FOLDER_ID}")  # ƒê√É COMMENT
        print(f"üåê H·ªó tr·ª£ ng√¥n ng·ªØ: Ti·∫øng Vi·ªát v√† Ti·∫øng Trung")

        # X·ª≠ l√Ω t·∫•t c·∫£ video
        print(f"\nüöÄ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù T·∫§T C·∫¢ VIDEO...")
        results = processor.process_all_videos(
            INPUT_FOLDER_ID, 
            VOICE_ONLY_FOLDER_ID,
            TEXT_ORIGINAL_FOLDER_ID,
            TEXT_REWRITTEN_FOLDER_ID
            # TEXT_TO_SPEECH_FOLDER_ID  # ƒê√É COMMENT
        )

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        print(f"\n" + "=" * 80)
        if results:
            success_count = len([r for r in results if r['status'] == 'success'])
            error_count = len([r for r in results if r['status'] == 'error'])
            
            print(f"üéâ === K·∫æT QU·∫¢ X·ª¨ L√ù ===")
            print(f"üìä T·ªïng s·ªë video: {len(results)}")
            print(f"‚úÖ Th√†nh c√¥ng: {success_count}")
            print(f"‚ùå Th·∫•t b·∫°i: {error_count}")
            print(f"üìä Google Sheets ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t t·ª± ƒë·ªông")
            
            if success_count > 0:
                print(f"\nüìã CHI TI·∫æT VIDEO TH√ÄNH C√îNG:")
                for result in results:
                    if result['status'] == 'success':
                        print(f"  üé¨ {result['video_name']}")
                        print(f"    üé§ Voice: {result['voice_file_id']}")
                        print(f"    üìÑ Text: {result['text_file_id']}")
                        print(f"    ‚úçÔ∏è Rewritten: {result['rewritten_text_file_id']}")
                        # print(f"    üé§ TTS: {result.get('tts_file_id', 'N/A')}")  # ƒê√É COMMENT
            
            if error_count > 0:
                print(f"\n‚ùå CHI TI·∫æT VIDEO TH·∫§T B·∫†I:")
                for result in results:
                    if result['status'] == 'error':
                        print(f"  üé¨ {result['video_name']}: {result.get('error', 'Unknown error')}")
            
            print(f"\nüîó LINKS:")
            print(f"üé§ Voice Only Folder: https://drive.google.com/drive/folders/{VOICE_ONLY_FOLDER_ID}")
            print(f"üìÑ Text Original Folder: https://drive.google.com/drive/folders/{TEXT_ORIGINAL_FOLDER_ID}")
            print(f"‚úçÔ∏è Text Rewritten Folder: https://drive.google.com/drive/folders/{TEXT_REWRITTEN_FOLDER_ID}")
            # print(f"üé§ Text to Speech Folder: https://drive.google.com/drive/folders/{TEXT_TO_SPEECH_FOLDER_ID}")  # ƒê√É COMMENT
        else:
            print(f"‚ùå Kh√¥ng c√≥ video n√†o ƒë∆∞·ª£c x·ª≠ l√Ω")

    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        print("\nüîß KI·ªÇM TRA:")
        print("1. File client_secret ƒë√£ c√≥ ch∆∞a?")
        print("2. FFmpeg ƒë√£ c√†i ƒë·∫∑t ch∆∞a?")
        print("3. Google Drive API ƒë√£ b·∫≠t ch∆∞a?")
        print("4. OAuth credentials c√≥ quy·ªÅn truy c·∫≠p folder kh√¥ng?")
        print("5. Deepgram API key c√≥ h·ª£p l·ªá kh√¥ng?")
        print("6. Gemini API key c√≥ h·ª£p l·ªá kh√¥ng?")
    finally:
        # D·ªçn d·∫πp
        if 'processor' in locals():
            processor.cleanup()


if __name__ == "__main__":
    main() 